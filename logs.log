2025-09-09 13:42:29,919:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-09 13:42:29,919:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-09 13:42:29,919:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-09 13:42:29,919:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-09 13:44:25,121:INFO:PyCaret ClassificationExperiment
2025-09-09 13:44:25,122:INFO:Logging name: clf-default-name
2025-09-09 13:44:25,122:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-09-09 13:44:25,123:INFO:version 3.3.2
2025-09-09 13:44:25,123:INFO:Initializing setup()
2025-09-09 13:44:25,123:INFO:self.USI: 0950
2025-09-09 13:44:25,123:INFO:self._variable_keys: {'X_train', 'log_plots_param', 'X_test', 'fold_generator', 'fold_shuffle_param', 'fold_groups_param', 'exp_id', 'y_test', 'gpu_n_jobs_param', 'pipeline', 'is_multiclass', 'idx', 'data', 'y_train', '_ml_usecase', 'html_param', 'seed', 'USI', 'exp_name_log', 'X', 'y', 'gpu_param', 'fix_imbalance', 'memory', 'logging_param', 'target_param', 'n_jobs_param', '_available_plots'}
2025-09-09 13:44:25,123:INFO:Checking environment
2025-09-09 13:44:25,123:INFO:python_version: 3.11.10
2025-09-09 13:44:25,123:INFO:python_build: ('main', 'Oct  3 2024 07:22:26')
2025-09-09 13:44:25,123:INFO:machine: AMD64
2025-09-09 13:44:25,123:INFO:platform: Windows-10-10.0.26100-SP0
2025-09-09 13:44:25,132:INFO:Memory: svmem(total=16837152768, available=2663682048, percent=84.2, used=14173470720, free=2663682048)
2025-09-09 13:44:25,133:INFO:Physical Core: 10
2025-09-09 13:44:25,133:INFO:Logical Core: 12
2025-09-09 13:44:25,133:INFO:Checking libraries
2025-09-09 13:44:25,133:INFO:System:
2025-09-09 13:44:25,133:INFO:    python: 3.11.10 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:26) [MSC v.1929 64 bit (AMD64)]
2025-09-09 13:44:25,133:INFO:executable: c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\python.exe
2025-09-09 13:44:25,133:INFO:   machine: Windows-10-10.0.26100-SP0
2025-09-09 13:44:25,133:INFO:PyCaret required dependencies:
2025-09-09 13:44:25,575:INFO:                 pip: 24.2
2025-09-09 13:44:25,575:INFO:          setuptools: 75.1.0
2025-09-09 13:44:25,575:INFO:             pycaret: 3.3.2
2025-09-09 13:44:25,575:INFO:             IPython: 9.2.0
2025-09-09 13:44:25,575:INFO:          ipywidgets: 8.1.7
2025-09-09 13:44:25,575:INFO:                tqdm: 4.67.1
2025-09-09 13:44:25,575:INFO:               numpy: 1.24.4
2025-09-09 13:44:25,575:INFO:              pandas: 1.5.3
2025-09-09 13:44:25,575:INFO:              jinja2: 3.1.6
2025-09-09 13:44:25,575:INFO:               scipy: 1.11.4
2025-09-09 13:44:25,575:INFO:              joblib: 1.3.2
2025-09-09 13:44:25,575:INFO:             sklearn: 1.4.2
2025-09-09 13:44:25,575:INFO:                pyod: 2.0.5
2025-09-09 13:44:25,575:INFO:            imblearn: 0.13.0
2025-09-09 13:44:25,575:INFO:   category_encoders: 2.7.0
2025-09-09 13:44:25,575:INFO:            lightgbm: 4.6.0
2025-09-09 13:44:25,575:INFO:               numba: 0.61.0
2025-09-09 13:44:25,575:INFO:            requests: 2.32.3
2025-09-09 13:44:25,575:INFO:          matplotlib: 3.7.5
2025-09-09 13:44:25,575:INFO:          scikitplot: 0.3.7
2025-09-09 13:44:25,575:INFO:         yellowbrick: 1.5
2025-09-09 13:44:25,575:INFO:              plotly: 5.24.1
2025-09-09 13:44:25,575:INFO:    plotly-resampler: Not installed
2025-09-09 13:44:25,575:INFO:             kaleido: 0.2.1
2025-09-09 13:44:25,575:INFO:           schemdraw: 0.15
2025-09-09 13:44:25,575:INFO:         statsmodels: 0.14.4
2025-09-09 13:44:25,575:INFO:              sktime: 0.26.0
2025-09-09 13:44:25,575:INFO:               tbats: 1.1.3
2025-09-09 13:44:25,575:INFO:            pmdarima: 2.0.4
2025-09-09 13:44:25,575:INFO:              psutil: 7.0.0
2025-09-09 13:44:25,575:INFO:          markupsafe: 3.0.2
2025-09-09 13:44:25,575:INFO:             pickle5: Not installed
2025-09-09 13:44:25,575:INFO:         cloudpickle: 3.1.1
2025-09-09 13:44:25,577:INFO:         deprecation: 2.1.0
2025-09-09 13:44:25,577:INFO:              xxhash: 3.5.0
2025-09-09 13:44:25,577:INFO:           wurlitzer: Not installed
2025-09-09 13:44:25,577:INFO:PyCaret optional dependencies:
2025-09-09 13:44:28,050:INFO:                shap: 0.44.1
2025-09-09 13:44:28,050:INFO:           interpret: 0.6.11
2025-09-09 13:44:28,050:INFO:                umap: 0.5.7
2025-09-09 13:44:28,050:INFO:     ydata_profiling: 4.16.1
2025-09-09 13:44:28,050:INFO:  explainerdashboard: 0.5.1
2025-09-09 13:44:28,050:INFO:             autoviz: Not installed
2025-09-09 13:44:28,050:INFO:           fairlearn: 0.7.0
2025-09-09 13:44:28,050:INFO:          deepchecks: Not installed
2025-09-09 13:44:28,050:INFO:             xgboost: 3.0.2
2025-09-09 13:44:28,050:INFO:            catboost: 1.2.8
2025-09-09 13:44:28,050:INFO:              kmodes: 0.12.2
2025-09-09 13:44:28,050:INFO:             mlxtend: 0.23.4
2025-09-09 13:44:28,050:INFO:       statsforecast: 1.5.0
2025-09-09 13:44:28,050:INFO:        tune_sklearn: Not installed
2025-09-09 13:44:28,050:INFO:                 ray: Not installed
2025-09-09 13:44:28,050:INFO:            hyperopt: 0.2.7
2025-09-09 13:44:28,050:INFO:              optuna: 4.3.0
2025-09-09 13:44:28,050:INFO:               skopt: 0.10.2
2025-09-09 13:44:28,050:INFO:              mlflow: 3.1.0
2025-09-09 13:44:28,050:INFO:              gradio: 5.33.1
2025-09-09 13:44:28,050:INFO:             fastapi: 0.115.12
2025-09-09 13:44:28,050:INFO:             uvicorn: 0.34.3
2025-09-09 13:44:28,050:INFO:              m2cgen: 0.10.0
2025-09-09 13:44:28,050:INFO:           evidently: 0.4.40
2025-09-09 13:44:28,050:INFO:               fugue: 0.8.7
2025-09-09 13:44:28,050:INFO:           streamlit: 1.45.1
2025-09-09 13:44:28,050:INFO:             prophet: 1.1.7
2025-09-09 13:44:28,050:INFO:None
2025-09-09 13:44:28,050:INFO:Set up data.
2025-09-09 13:44:28,077:INFO:Set up folding strategy.
2025-09-09 13:44:28,078:INFO:Set up train/test split.
2025-09-09 13:44:28,089:INFO:Set up index.
2025-09-09 13:44:28,090:INFO:Assigning column types.
2025-09-09 13:44:28,094:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-09-09 13:44:28,120:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-09 13:44:28,122:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-09 13:44:28,145:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 13:44:28,146:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 13:44:28,195:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-09 13:44:28,195:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-09 13:44:28,212:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 13:44:28,214:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 13:44:28,214:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-09-09 13:44:28,241:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-09 13:44:28,257:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 13:44:28,259:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 13:44:28,285:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-09 13:44:28,302:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 13:44:28,304:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 13:44:28,304:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-09-09 13:44:28,347:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 13:44:28,350:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 13:44:28,391:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 13:44:28,393:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 13:44:28,395:INFO:Preparing preprocessing pipeline...
2025-09-09 13:44:28,396:INFO:Set up date feature engineering.
2025-09-09 13:44:28,396:INFO:Set up simple imputation.
2025-09-09 13:44:28,400:INFO:Set up encoding of ordinal features.
2025-09-09 13:44:28,403:INFO:Set up encoding of categorical features.
2025-09-09 13:44:28,404:INFO:Set up removing outliers.
2025-09-09 13:44:28,404:INFO:Set up imbalanced handling.
2025-09-09 13:44:28,404:INFO:Set up feature normalization.
2025-09-09 13:44:29,698:INFO:Finished creating preprocessing pipeline.
2025-09-09 13:44:29,720:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\SBM_ME~1\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['TimeStart', 'TimeStop',
                                             'ProductionDate', 'ApproveDate',
                                             'CreateDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    inc...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=42,
                                                               threshold=0.05))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-09-09 13:44:29,720:INFO:Creating final display dataframe.
2025-09-09 13:44:31,109:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target              isNC
2                   Target type            Binary
3           Original data shape        (7059, 31)
4        Transformed data shape      (11404, 159)
5   Transformed train set shape       (9286, 159)
6    Transformed test set shape       (2118, 159)
7              Numeric features                 3
8                 Date features                 5
9          Categorical features                22
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16              Remove outliers              True
17           Outliers threshold              0.05
18                Fix imbalance              True
19         Fix imbalance method             SMOTE
20                    Normalize              True
21             Normalize method            zscore
22               Fold Generator   StratifiedKFold
23                  Fold Number                10
24                     CPU Jobs                -1
25                      Use GPU             False
26               Log Experiment             False
27              Experiment Name  clf-default-name
28                          USI              0950
2025-09-09 13:44:31,164:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 13:44:31,165:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 13:44:31,218:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 13:44:31,220:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 13:44:31,221:INFO:setup() successfully completed in 6.12s...............
2025-09-09 13:46:12,036:INFO:PyCaret ClassificationExperiment
2025-09-09 13:46:12,036:INFO:Logging name: clf-default-name
2025-09-09 13:46:12,036:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-09-09 13:46:12,036:INFO:version 3.3.2
2025-09-09 13:46:12,036:INFO:Initializing setup()
2025-09-09 13:46:12,036:INFO:self.USI: 807f
2025-09-09 13:46:12,036:INFO:self._variable_keys: {'X_train', 'log_plots_param', 'X_test', 'fold_generator', 'fold_shuffle_param', 'fold_groups_param', 'exp_id', 'y_test', 'gpu_n_jobs_param', 'pipeline', 'is_multiclass', 'idx', 'data', 'y_train', '_ml_usecase', 'html_param', 'seed', 'USI', 'exp_name_log', 'X', 'y', 'gpu_param', 'fix_imbalance', 'memory', 'logging_param', 'target_param', 'n_jobs_param', '_available_plots'}
2025-09-09 13:46:12,036:INFO:Checking environment
2025-09-09 13:46:12,037:INFO:python_version: 3.11.10
2025-09-09 13:46:12,037:INFO:python_build: ('main', 'Oct  3 2024 07:22:26')
2025-09-09 13:46:12,037:INFO:machine: AMD64
2025-09-09 13:46:12,037:INFO:platform: Windows-10-10.0.26100-SP0
2025-09-09 13:46:12,045:INFO:Memory: svmem(total=16837152768, available=2463850496, percent=85.4, used=14373302272, free=2463850496)
2025-09-09 13:46:12,045:INFO:Physical Core: 10
2025-09-09 13:46:12,045:INFO:Logical Core: 12
2025-09-09 13:46:12,045:INFO:Checking libraries
2025-09-09 13:46:12,045:INFO:System:
2025-09-09 13:46:12,045:INFO:    python: 3.11.10 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:26) [MSC v.1929 64 bit (AMD64)]
2025-09-09 13:46:12,045:INFO:executable: c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\python.exe
2025-09-09 13:46:12,045:INFO:   machine: Windows-10-10.0.26100-SP0
2025-09-09 13:46:12,045:INFO:PyCaret required dependencies:
2025-09-09 13:46:12,046:INFO:                 pip: 24.2
2025-09-09 13:46:12,046:INFO:          setuptools: 75.1.0
2025-09-09 13:46:12,046:INFO:             pycaret: 3.3.2
2025-09-09 13:46:12,046:INFO:             IPython: 9.2.0
2025-09-09 13:46:12,046:INFO:          ipywidgets: 8.1.7
2025-09-09 13:46:12,046:INFO:                tqdm: 4.67.1
2025-09-09 13:46:12,046:INFO:               numpy: 1.24.4
2025-09-09 13:46:12,047:INFO:              pandas: 1.5.3
2025-09-09 13:46:12,047:INFO:              jinja2: 3.1.6
2025-09-09 13:46:12,047:INFO:               scipy: 1.11.4
2025-09-09 13:46:12,047:INFO:              joblib: 1.3.2
2025-09-09 13:46:12,047:INFO:             sklearn: 1.4.2
2025-09-09 13:46:12,047:INFO:                pyod: 2.0.5
2025-09-09 13:46:12,047:INFO:            imblearn: 0.13.0
2025-09-09 13:46:12,047:INFO:   category_encoders: 2.7.0
2025-09-09 13:46:12,047:INFO:            lightgbm: 4.6.0
2025-09-09 13:46:12,047:INFO:               numba: 0.61.0
2025-09-09 13:46:12,047:INFO:            requests: 2.32.3
2025-09-09 13:46:12,047:INFO:          matplotlib: 3.7.5
2025-09-09 13:46:12,047:INFO:          scikitplot: 0.3.7
2025-09-09 13:46:12,047:INFO:         yellowbrick: 1.5
2025-09-09 13:46:12,048:INFO:              plotly: 5.24.1
2025-09-09 13:46:12,048:INFO:    plotly-resampler: Not installed
2025-09-09 13:46:12,048:INFO:             kaleido: 0.2.1
2025-09-09 13:46:12,048:INFO:           schemdraw: 0.15
2025-09-09 13:46:12,048:INFO:         statsmodels: 0.14.4
2025-09-09 13:46:12,048:INFO:              sktime: 0.26.0
2025-09-09 13:46:12,048:INFO:               tbats: 1.1.3
2025-09-09 13:46:12,048:INFO:            pmdarima: 2.0.4
2025-09-09 13:46:12,048:INFO:              psutil: 7.0.0
2025-09-09 13:46:12,048:INFO:          markupsafe: 3.0.2
2025-09-09 13:46:12,048:INFO:             pickle5: Not installed
2025-09-09 13:46:12,048:INFO:         cloudpickle: 3.1.1
2025-09-09 13:46:12,048:INFO:         deprecation: 2.1.0
2025-09-09 13:46:12,049:INFO:              xxhash: 3.5.0
2025-09-09 13:46:12,049:INFO:           wurlitzer: Not installed
2025-09-09 13:46:12,049:INFO:PyCaret optional dependencies:
2025-09-09 13:46:12,049:INFO:                shap: 0.44.1
2025-09-09 13:46:12,049:INFO:           interpret: 0.6.11
2025-09-09 13:46:12,049:INFO:                umap: 0.5.7
2025-09-09 13:46:12,049:INFO:     ydata_profiling: 4.16.1
2025-09-09 13:46:12,049:INFO:  explainerdashboard: 0.5.1
2025-09-09 13:46:12,049:INFO:             autoviz: Not installed
2025-09-09 13:46:12,049:INFO:           fairlearn: 0.7.0
2025-09-09 13:46:12,049:INFO:          deepchecks: Not installed
2025-09-09 13:46:12,049:INFO:             xgboost: 3.0.2
2025-09-09 13:46:12,050:INFO:            catboost: 1.2.8
2025-09-09 13:46:12,050:INFO:              kmodes: 0.12.2
2025-09-09 13:46:12,050:INFO:             mlxtend: 0.23.4
2025-09-09 13:46:12,050:INFO:       statsforecast: 1.5.0
2025-09-09 13:46:12,050:INFO:        tune_sklearn: Not installed
2025-09-09 13:46:12,050:INFO:                 ray: Not installed
2025-09-09 13:46:12,050:INFO:            hyperopt: 0.2.7
2025-09-09 13:46:12,050:INFO:              optuna: 4.3.0
2025-09-09 13:46:12,050:INFO:               skopt: 0.10.2
2025-09-09 13:46:12,050:INFO:              mlflow: 3.1.0
2025-09-09 13:46:12,050:INFO:              gradio: 5.33.1
2025-09-09 13:46:12,050:INFO:             fastapi: 0.115.12
2025-09-09 13:46:12,050:INFO:             uvicorn: 0.34.3
2025-09-09 13:46:12,050:INFO:              m2cgen: 0.10.0
2025-09-09 13:46:12,051:INFO:           evidently: 0.4.40
2025-09-09 13:46:12,051:INFO:               fugue: 0.8.7
2025-09-09 13:46:12,051:INFO:           streamlit: 1.45.1
2025-09-09 13:46:12,051:INFO:             prophet: 1.1.7
2025-09-09 13:46:12,051:INFO:None
2025-09-09 13:46:12,051:INFO:Set up data.
2025-09-09 13:46:12,095:INFO:Set up folding strategy.
2025-09-09 13:46:12,095:INFO:Set up train/test split.
2025-09-09 13:46:12,109:INFO:Set up index.
2025-09-09 13:46:12,109:INFO:Assigning column types.
2025-09-09 13:46:12,113:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-09-09 13:46:12,138:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-09 13:46:12,139:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-09 13:46:12,155:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 13:46:12,156:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 13:46:12,181:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-09 13:46:12,181:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-09 13:46:12,198:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 13:46:12,199:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 13:46:12,199:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-09-09 13:46:12,225:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-09 13:46:12,243:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 13:46:12,245:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 13:46:12,270:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-09 13:46:12,287:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 13:46:12,288:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 13:46:12,289:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-09-09 13:46:12,332:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 13:46:12,334:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 13:46:12,379:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 13:46:12,380:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 13:46:12,381:INFO:Preparing preprocessing pipeline...
2025-09-09 13:46:12,382:INFO:Set up date feature engineering.
2025-09-09 13:46:12,382:INFO:Set up simple imputation.
2025-09-09 13:46:12,389:INFO:Set up encoding of ordinal features.
2025-09-09 13:46:12,393:INFO:Set up encoding of categorical features.
2025-09-09 13:46:12,394:INFO:Set up removing outliers.
2025-09-09 13:46:12,394:INFO:Set up imbalanced handling.
2025-09-09 13:46:12,394:INFO:Set up feature normalization.
2025-09-09 13:46:13,643:INFO:Finished creating preprocessing pipeline.
2025-09-09 13:46:13,673:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\SBM_ME~1\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['TimeStart', 'TimeStop',
                                             'ProductionDate', 'ApproveDate',
                                             'CreateDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    inc...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=42,
                                                               threshold=0.05))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=42,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-09-09 13:46:13,674:INFO:Creating final display dataframe.
2025-09-09 13:46:15,499:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target              isNC
2                   Target type            Binary
3           Original data shape       (13266, 31)
4        Transformed data shape      (13256, 160)
5   Transformed train set shape       (9276, 160)
6    Transformed test set shape       (3980, 160)
7              Numeric features                 3
8                 Date features                 5
9          Categorical features                22
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16              Remove outliers              True
17           Outliers threshold              0.05
18                Fix imbalance              True
19         Fix imbalance method             SMOTE
20                    Normalize              True
21             Normalize method            zscore
22               Fold Generator   StratifiedKFold
23                  Fold Number                10
24                     CPU Jobs                -1
25                      Use GPU             False
26               Log Experiment             False
27              Experiment Name  clf-default-name
28                          USI              807f
2025-09-09 13:46:15,550:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 13:46:15,552:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 13:46:15,603:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 13:46:15,605:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 13:46:15,607:INFO:setup() successfully completed in 3.6s...............
2025-09-09 14:00:32,240:INFO:PyCaret ClassificationExperiment
2025-09-09 14:00:32,241:INFO:Logging name: clf-default-name
2025-09-09 14:00:32,241:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-09-09 14:00:32,241:INFO:version 3.3.2
2025-09-09 14:00:32,241:INFO:Initializing setup()
2025-09-09 14:00:32,241:INFO:self.USI: e451
2025-09-09 14:00:32,241:INFO:self._variable_keys: {'X_train', 'log_plots_param', 'X_test', 'fold_generator', 'fold_shuffle_param', 'fold_groups_param', 'exp_id', 'y_test', 'gpu_n_jobs_param', 'pipeline', 'is_multiclass', 'idx', 'data', 'y_train', '_ml_usecase', 'html_param', 'seed', 'USI', 'exp_name_log', 'X', 'y', 'gpu_param', 'fix_imbalance', 'memory', 'logging_param', 'target_param', 'n_jobs_param', '_available_plots'}
2025-09-09 14:00:32,241:INFO:Checking environment
2025-09-09 14:00:32,241:INFO:python_version: 3.11.10
2025-09-09 14:00:32,241:INFO:python_build: ('main', 'Oct  3 2024 07:22:26')
2025-09-09 14:00:32,241:INFO:machine: AMD64
2025-09-09 14:00:32,241:INFO:platform: Windows-10-10.0.26100-SP0
2025-09-09 14:00:32,249:INFO:Memory: svmem(total=16837152768, available=2385391616, percent=85.8, used=14451761152, free=2385391616)
2025-09-09 14:00:32,249:INFO:Physical Core: 10
2025-09-09 14:00:32,249:INFO:Logical Core: 12
2025-09-09 14:00:32,249:INFO:Checking libraries
2025-09-09 14:00:32,249:INFO:System:
2025-09-09 14:00:32,249:INFO:    python: 3.11.10 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:26) [MSC v.1929 64 bit (AMD64)]
2025-09-09 14:00:32,249:INFO:executable: c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\python.exe
2025-09-09 14:00:32,249:INFO:   machine: Windows-10-10.0.26100-SP0
2025-09-09 14:00:32,249:INFO:PyCaret required dependencies:
2025-09-09 14:00:32,250:INFO:                 pip: 24.2
2025-09-09 14:00:32,250:INFO:          setuptools: 75.1.0
2025-09-09 14:00:32,250:INFO:             pycaret: 3.3.2
2025-09-09 14:00:32,250:INFO:             IPython: 9.2.0
2025-09-09 14:00:32,250:INFO:          ipywidgets: 8.1.7
2025-09-09 14:00:32,250:INFO:                tqdm: 4.67.1
2025-09-09 14:00:32,250:INFO:               numpy: 1.24.4
2025-09-09 14:00:32,250:INFO:              pandas: 1.5.3
2025-09-09 14:00:32,250:INFO:              jinja2: 3.1.6
2025-09-09 14:00:32,250:INFO:               scipy: 1.11.4
2025-09-09 14:00:32,250:INFO:              joblib: 1.3.2
2025-09-09 14:00:32,250:INFO:             sklearn: 1.4.2
2025-09-09 14:00:32,250:INFO:                pyod: 2.0.5
2025-09-09 14:00:32,251:INFO:            imblearn: 0.13.0
2025-09-09 14:00:32,251:INFO:   category_encoders: 2.7.0
2025-09-09 14:00:32,251:INFO:            lightgbm: 4.6.0
2025-09-09 14:00:32,251:INFO:               numba: 0.61.0
2025-09-09 14:00:32,251:INFO:            requests: 2.32.3
2025-09-09 14:00:32,251:INFO:          matplotlib: 3.7.5
2025-09-09 14:00:32,251:INFO:          scikitplot: 0.3.7
2025-09-09 14:00:32,251:INFO:         yellowbrick: 1.5
2025-09-09 14:00:32,251:INFO:              plotly: 5.24.1
2025-09-09 14:00:32,251:INFO:    plotly-resampler: Not installed
2025-09-09 14:00:32,251:INFO:             kaleido: 0.2.1
2025-09-09 14:00:32,251:INFO:           schemdraw: 0.15
2025-09-09 14:00:32,251:INFO:         statsmodels: 0.14.4
2025-09-09 14:00:32,251:INFO:              sktime: 0.26.0
2025-09-09 14:00:32,251:INFO:               tbats: 1.1.3
2025-09-09 14:00:32,251:INFO:            pmdarima: 2.0.4
2025-09-09 14:00:32,251:INFO:              psutil: 7.0.0
2025-09-09 14:00:32,251:INFO:          markupsafe: 3.0.2
2025-09-09 14:00:32,251:INFO:             pickle5: Not installed
2025-09-09 14:00:32,251:INFO:         cloudpickle: 3.1.1
2025-09-09 14:00:32,251:INFO:         deprecation: 2.1.0
2025-09-09 14:00:32,253:INFO:              xxhash: 3.5.0
2025-09-09 14:00:32,253:INFO:           wurlitzer: Not installed
2025-09-09 14:00:32,253:INFO:PyCaret optional dependencies:
2025-09-09 14:00:32,253:INFO:                shap: 0.44.1
2025-09-09 14:00:32,253:INFO:           interpret: 0.6.11
2025-09-09 14:00:32,253:INFO:                umap: 0.5.7
2025-09-09 14:00:32,253:INFO:     ydata_profiling: 4.16.1
2025-09-09 14:00:32,253:INFO:  explainerdashboard: 0.5.1
2025-09-09 14:00:32,253:INFO:             autoviz: Not installed
2025-09-09 14:00:32,253:INFO:           fairlearn: 0.7.0
2025-09-09 14:00:32,253:INFO:          deepchecks: Not installed
2025-09-09 14:00:32,253:INFO:             xgboost: 3.0.2
2025-09-09 14:00:32,253:INFO:            catboost: 1.2.8
2025-09-09 14:00:32,253:INFO:              kmodes: 0.12.2
2025-09-09 14:00:32,253:INFO:             mlxtend: 0.23.4
2025-09-09 14:00:32,253:INFO:       statsforecast: 1.5.0
2025-09-09 14:00:32,253:INFO:        tune_sklearn: Not installed
2025-09-09 14:00:32,253:INFO:                 ray: Not installed
2025-09-09 14:00:32,253:INFO:            hyperopt: 0.2.7
2025-09-09 14:00:32,253:INFO:              optuna: 4.3.0
2025-09-09 14:00:32,253:INFO:               skopt: 0.10.2
2025-09-09 14:00:32,253:INFO:              mlflow: 3.1.0
2025-09-09 14:00:32,253:INFO:              gradio: 5.33.1
2025-09-09 14:00:32,253:INFO:             fastapi: 0.115.12
2025-09-09 14:00:32,253:INFO:             uvicorn: 0.34.3
2025-09-09 14:00:32,253:INFO:              m2cgen: 0.10.0
2025-09-09 14:00:32,253:INFO:           evidently: 0.4.40
2025-09-09 14:00:32,253:INFO:               fugue: 0.8.7
2025-09-09 14:00:32,253:INFO:           streamlit: 1.45.1
2025-09-09 14:00:32,253:INFO:             prophet: 1.1.7
2025-09-09 14:00:32,253:INFO:None
2025-09-09 14:00:32,253:INFO:Set up data.
2025-09-09 14:00:32,291:INFO:Set up folding strategy.
2025-09-09 14:00:32,291:INFO:Set up train/test split.
2025-09-09 14:00:32,306:INFO:Set up index.
2025-09-09 14:00:32,307:INFO:Assigning column types.
2025-09-09 14:00:32,311:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-09-09 14:00:32,347:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-09 14:00:32,347:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-09 14:00:32,367:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 14:00:32,369:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 14:00:32,392:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-09 14:00:32,393:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-09 14:00:32,409:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 14:00:32,410:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 14:00:32,411:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-09-09 14:00:32,435:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-09 14:00:32,452:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 14:00:32,454:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 14:00:32,481:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-09 14:00:32,497:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 14:00:32,498:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 14:00:32,498:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-09-09 14:00:32,556:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 14:00:32,559:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 14:00:32,601:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 14:00:32,603:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 14:00:32,604:INFO:Preparing preprocessing pipeline...
2025-09-09 14:00:32,605:INFO:Set up date feature engineering.
2025-09-09 14:00:32,605:INFO:Set up simple imputation.
2025-09-09 14:00:32,613:INFO:Set up encoding of ordinal features.
2025-09-09 14:00:32,616:INFO:Set up encoding of categorical features.
2025-09-09 14:00:32,616:INFO:Set up feature normalization.
2025-09-09 14:00:33,264:INFO:Finished creating preprocessing pipeline.
2025-09-09 14:00:33,282:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\SBM_ME~1\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['TimeStart', 'TimeStop',
                                             'ProductionDate', 'ApproveDate',
                                             'CreateDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    inc...
                                                                    'LeaderID',
                                                                    'ProdCode',
                                                                    'Lot',
                                                                    'LNCNo',
                                                                    'SessionID2',
                                                                    'FGCode',
                                                                    'LotNo'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-09-09 14:00:33,282:INFO:Creating final display dataframe.
2025-09-09 14:00:34,474:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target              isNC
2                   Target type            Binary
3           Original data shape       (13262, 31)
4        Transformed data shape      (13262, 162)
5   Transformed train set shape       (9283, 162)
6    Transformed test set shape       (3979, 162)
7              Numeric features                 3
8                 Date features                 5
9          Categorical features                22
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                    Normalize              True
17             Normalize method            zscore
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              e451
2025-09-09 14:00:34,530:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 14:00:34,531:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 14:00:34,581:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 14:00:34,583:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 14:00:34,585:INFO:setup() successfully completed in 2.37s...............
2025-09-09 14:08:29,963:INFO:PyCaret ClassificationExperiment
2025-09-09 14:08:29,963:INFO:Logging name: clf-default-name
2025-09-09 14:08:29,963:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-09-09 14:08:29,963:INFO:version 3.3.2
2025-09-09 14:08:29,963:INFO:Initializing setup()
2025-09-09 14:08:29,963:INFO:self.USI: ee58
2025-09-09 14:08:29,963:INFO:self._variable_keys: {'X_train', 'log_plots_param', 'X_test', 'fold_generator', 'fold_shuffle_param', 'fold_groups_param', 'exp_id', 'y_test', 'gpu_n_jobs_param', 'pipeline', 'is_multiclass', 'idx', 'data', 'y_train', '_ml_usecase', 'html_param', 'seed', 'USI', 'exp_name_log', 'X', 'y', 'gpu_param', 'fix_imbalance', 'memory', 'logging_param', 'target_param', 'n_jobs_param', '_available_plots'}
2025-09-09 14:08:29,963:INFO:Checking environment
2025-09-09 14:08:29,963:INFO:python_version: 3.11.10
2025-09-09 14:08:29,963:INFO:python_build: ('main', 'Oct  3 2024 07:22:26')
2025-09-09 14:08:29,963:INFO:machine: AMD64
2025-09-09 14:08:29,963:INFO:platform: Windows-10-10.0.26100-SP0
2025-09-09 14:08:29,968:INFO:Memory: svmem(total=16837152768, available=2545512448, percent=84.9, used=14291640320, free=2545512448)
2025-09-09 14:08:29,968:INFO:Physical Core: 10
2025-09-09 14:08:29,968:INFO:Logical Core: 12
2025-09-09 14:08:29,968:INFO:Checking libraries
2025-09-09 14:08:29,968:INFO:System:
2025-09-09 14:08:29,968:INFO:    python: 3.11.10 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:26) [MSC v.1929 64 bit (AMD64)]
2025-09-09 14:08:29,968:INFO:executable: c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\python.exe
2025-09-09 14:08:29,968:INFO:   machine: Windows-10-10.0.26100-SP0
2025-09-09 14:08:29,968:INFO:PyCaret required dependencies:
2025-09-09 14:08:29,968:INFO:                 pip: 24.2
2025-09-09 14:08:29,968:INFO:          setuptools: 75.1.0
2025-09-09 14:08:29,968:INFO:             pycaret: 3.3.2
2025-09-09 14:08:29,968:INFO:             IPython: 9.2.0
2025-09-09 14:08:29,968:INFO:          ipywidgets: 8.1.7
2025-09-09 14:08:29,968:INFO:                tqdm: 4.67.1
2025-09-09 14:08:29,968:INFO:               numpy: 1.24.4
2025-09-09 14:08:29,968:INFO:              pandas: 1.5.3
2025-09-09 14:08:29,968:INFO:              jinja2: 3.1.6
2025-09-09 14:08:29,968:INFO:               scipy: 1.11.4
2025-09-09 14:08:29,968:INFO:              joblib: 1.3.2
2025-09-09 14:08:29,969:INFO:             sklearn: 1.4.2
2025-09-09 14:08:29,969:INFO:                pyod: 2.0.5
2025-09-09 14:08:29,969:INFO:            imblearn: 0.13.0
2025-09-09 14:08:29,969:INFO:   category_encoders: 2.7.0
2025-09-09 14:08:29,969:INFO:            lightgbm: 4.6.0
2025-09-09 14:08:29,969:INFO:               numba: 0.61.0
2025-09-09 14:08:29,969:INFO:            requests: 2.32.3
2025-09-09 14:08:29,969:INFO:          matplotlib: 3.7.5
2025-09-09 14:08:29,969:INFO:          scikitplot: 0.3.7
2025-09-09 14:08:29,969:INFO:         yellowbrick: 1.5
2025-09-09 14:08:29,969:INFO:              plotly: 5.24.1
2025-09-09 14:08:29,969:INFO:    plotly-resampler: Not installed
2025-09-09 14:08:29,969:INFO:             kaleido: 0.2.1
2025-09-09 14:08:29,969:INFO:           schemdraw: 0.15
2025-09-09 14:08:29,969:INFO:         statsmodels: 0.14.4
2025-09-09 14:08:29,969:INFO:              sktime: 0.26.0
2025-09-09 14:08:29,969:INFO:               tbats: 1.1.3
2025-09-09 14:08:29,969:INFO:            pmdarima: 2.0.4
2025-09-09 14:08:29,969:INFO:              psutil: 7.0.0
2025-09-09 14:08:29,969:INFO:          markupsafe: 3.0.2
2025-09-09 14:08:29,969:INFO:             pickle5: Not installed
2025-09-09 14:08:29,969:INFO:         cloudpickle: 3.1.1
2025-09-09 14:08:29,969:INFO:         deprecation: 2.1.0
2025-09-09 14:08:29,969:INFO:              xxhash: 3.5.0
2025-09-09 14:08:29,969:INFO:           wurlitzer: Not installed
2025-09-09 14:08:29,969:INFO:PyCaret optional dependencies:
2025-09-09 14:08:29,969:INFO:                shap: 0.44.1
2025-09-09 14:08:29,969:INFO:           interpret: 0.6.11
2025-09-09 14:08:29,969:INFO:                umap: 0.5.7
2025-09-09 14:08:29,969:INFO:     ydata_profiling: 4.16.1
2025-09-09 14:08:29,969:INFO:  explainerdashboard: 0.5.1
2025-09-09 14:08:29,969:INFO:             autoviz: Not installed
2025-09-09 14:08:29,969:INFO:           fairlearn: 0.7.0
2025-09-09 14:08:29,969:INFO:          deepchecks: Not installed
2025-09-09 14:08:29,969:INFO:             xgboost: 3.0.2
2025-09-09 14:08:29,969:INFO:            catboost: 1.2.8
2025-09-09 14:08:29,969:INFO:              kmodes: 0.12.2
2025-09-09 14:08:29,969:INFO:             mlxtend: 0.23.4
2025-09-09 14:08:29,969:INFO:       statsforecast: 1.5.0
2025-09-09 14:08:29,969:INFO:        tune_sklearn: Not installed
2025-09-09 14:08:29,969:INFO:                 ray: Not installed
2025-09-09 14:08:29,970:INFO:            hyperopt: 0.2.7
2025-09-09 14:08:29,970:INFO:              optuna: 4.3.0
2025-09-09 14:08:29,970:INFO:               skopt: 0.10.2
2025-09-09 14:08:29,970:INFO:              mlflow: 3.1.0
2025-09-09 14:08:29,970:INFO:              gradio: 5.33.1
2025-09-09 14:08:29,970:INFO:             fastapi: 0.115.12
2025-09-09 14:08:29,970:INFO:             uvicorn: 0.34.3
2025-09-09 14:08:29,970:INFO:              m2cgen: 0.10.0
2025-09-09 14:08:29,970:INFO:           evidently: 0.4.40
2025-09-09 14:08:29,970:INFO:               fugue: 0.8.7
2025-09-09 14:08:29,970:INFO:           streamlit: 1.45.1
2025-09-09 14:08:29,970:INFO:             prophet: 1.1.7
2025-09-09 14:08:29,970:INFO:None
2025-09-09 14:08:29,970:INFO:Set up data.
2025-09-09 14:08:30,140:INFO:Set up folding strategy.
2025-09-09 14:08:30,143:INFO:Set up train/test split.
2025-09-09 14:08:30,161:INFO:Set up index.
2025-09-09 14:08:30,162:INFO:Assigning column types.
2025-09-09 14:08:30,166:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-09-09 14:08:30,194:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-09 14:08:30,194:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-09 14:08:30,210:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 14:08:30,211:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 14:08:30,237:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-09 14:08:30,238:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-09 14:08:30,258:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 14:08:30,259:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 14:08:30,259:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-09-09 14:08:30,285:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-09 14:08:30,302:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 14:08:30,304:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 14:08:30,329:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-09 14:08:30,345:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 14:08:30,346:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 14:08:30,347:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-09-09 14:08:30,390:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 14:08:30,392:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 14:08:30,434:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 14:08:30,435:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 14:08:30,436:INFO:Preparing preprocessing pipeline...
2025-09-09 14:08:30,438:INFO:Set up date feature engineering.
2025-09-09 14:08:30,438:INFO:Set up simple imputation.
2025-09-09 14:08:30,446:INFO:Set up encoding of ordinal features.
2025-09-09 14:08:30,449:INFO:Set up encoding of categorical features.
2025-09-09 14:08:30,449:INFO:Set up feature normalization.
2025-09-09 14:08:31,098:INFO:Finished creating preprocessing pipeline.
2025-09-09 14:08:31,116:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\SBM_ME~1\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['TimeStart', 'TimeStop',
                                             'ProductionDate', 'ApproveDate',
                                             'CreateDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    inc...
                                                                    'LeaderID',
                                                                    'ProdCode',
                                                                    'Lot',
                                                                    'LNCNo',
                                                                    'SessionID2',
                                                                    'FGCode',
                                                                    'LotNo'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-09-09 14:08:31,116:INFO:Creating final display dataframe.
2025-09-09 14:08:32,159:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target              isNC
2                   Target type            Binary
3           Original data shape       (12216, 31)
4        Transformed data shape      (12216, 161)
5   Transformed train set shape       (8551, 161)
6    Transformed test set shape       (3665, 161)
7              Numeric features                 3
8                 Date features                 5
9          Categorical features                22
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                    Normalize              True
17             Normalize method            zscore
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              ee58
2025-09-09 14:08:32,217:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 14:08:32,219:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 14:08:32,262:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 14:08:32,263:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 14:08:32,264:INFO:setup() successfully completed in 2.34s...............
2025-09-09 14:09:30,208:INFO:Initializing compare_models()
2025-09-09 14:09:30,208:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-09-09 14:09:30,208:INFO:Checking exceptions
2025-09-09 14:09:30,219:INFO:Preparing display monitor
2025-09-09 14:09:30,251:INFO:Initializing Logistic Regression
2025-09-09 14:09:30,251:INFO:Total runtime is 0.0 minutes
2025-09-09 14:09:30,258:INFO:SubProcess create_model() called ==================================
2025-09-09 14:09:30,258:INFO:Initializing create_model()
2025-09-09 14:09:30,259:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC55334910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:09:30,259:INFO:Checking exceptions
2025-09-09 14:09:30,259:INFO:Importing libraries
2025-09-09 14:09:30,259:INFO:Copying training dataset
2025-09-09 14:09:30,275:INFO:Defining folds
2025-09-09 14:09:30,275:INFO:Declaring metric variables
2025-09-09 14:09:30,284:INFO:Importing untrained model
2025-09-09 14:09:30,296:INFO:Logistic Regression Imported successfully
2025-09-09 14:09:30,313:INFO:Starting cross validation
2025-09-09 14:09:30,320:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:09:39,241:INFO:Calculating mean and std
2025-09-09 14:09:39,243:INFO:Creating metrics dataframe
2025-09-09 14:09:39,251:INFO:Uploading results into container
2025-09-09 14:09:39,254:INFO:Uploading model into container now
2025-09-09 14:09:39,256:INFO:_master_model_container: 1
2025-09-09 14:09:39,256:INFO:_display_container: 2
2025-09-09 14:09:39,258:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-09-09 14:09:39,258:INFO:create_model() successfully completed......................................
2025-09-09 14:09:39,446:INFO:SubProcess create_model() end ==================================
2025-09-09 14:09:39,447:INFO:Creating metrics dataframe
2025-09-09 14:09:39,453:INFO:Initializing K Neighbors Classifier
2025-09-09 14:09:39,453:INFO:Total runtime is 0.153359854221344 minutes
2025-09-09 14:09:39,456:INFO:SubProcess create_model() called ==================================
2025-09-09 14:09:39,457:INFO:Initializing create_model()
2025-09-09 14:09:39,457:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC55334910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:09:39,457:INFO:Checking exceptions
2025-09-09 14:09:39,457:INFO:Importing libraries
2025-09-09 14:09:39,457:INFO:Copying training dataset
2025-09-09 14:09:39,464:INFO:Defining folds
2025-09-09 14:09:39,465:INFO:Declaring metric variables
2025-09-09 14:09:39,470:INFO:Importing untrained model
2025-09-09 14:09:39,476:INFO:K Neighbors Classifier Imported successfully
2025-09-09 14:09:39,492:INFO:Starting cross validation
2025-09-09 14:09:39,496:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:09:44,100:INFO:Calculating mean and std
2025-09-09 14:09:44,102:INFO:Creating metrics dataframe
2025-09-09 14:09:44,106:INFO:Uploading results into container
2025-09-09 14:09:44,106:INFO:Uploading model into container now
2025-09-09 14:09:44,106:INFO:_master_model_container: 2
2025-09-09 14:09:44,106:INFO:_display_container: 2
2025-09-09 14:09:44,107:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-09-09 14:09:44,107:INFO:create_model() successfully completed......................................
2025-09-09 14:09:44,226:INFO:SubProcess create_model() end ==================================
2025-09-09 14:09:44,226:INFO:Creating metrics dataframe
2025-09-09 14:09:44,242:INFO:Initializing Naive Bayes
2025-09-09 14:09:44,242:INFO:Total runtime is 0.23317113717397053 minutes
2025-09-09 14:09:44,246:INFO:SubProcess create_model() called ==================================
2025-09-09 14:09:44,246:INFO:Initializing create_model()
2025-09-09 14:09:44,246:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC55334910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:09:44,246:INFO:Checking exceptions
2025-09-09 14:09:44,247:INFO:Importing libraries
2025-09-09 14:09:44,247:INFO:Copying training dataset
2025-09-09 14:09:44,253:INFO:Defining folds
2025-09-09 14:09:44,254:INFO:Declaring metric variables
2025-09-09 14:09:44,260:INFO:Importing untrained model
2025-09-09 14:09:44,265:INFO:Naive Bayes Imported successfully
2025-09-09 14:09:44,277:INFO:Starting cross validation
2025-09-09 14:09:44,281:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:09:45,990:INFO:Calculating mean and std
2025-09-09 14:09:45,991:INFO:Creating metrics dataframe
2025-09-09 14:09:45,993:INFO:Uploading results into container
2025-09-09 14:09:45,994:INFO:Uploading model into container now
2025-09-09 14:09:45,994:INFO:_master_model_container: 3
2025-09-09 14:09:45,994:INFO:_display_container: 2
2025-09-09 14:09:45,995:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-09-09 14:09:45,995:INFO:create_model() successfully completed......................................
2025-09-09 14:09:46,113:INFO:SubProcess create_model() end ==================================
2025-09-09 14:09:46,113:INFO:Creating metrics dataframe
2025-09-09 14:09:46,119:INFO:Initializing Decision Tree Classifier
2025-09-09 14:09:46,120:INFO:Total runtime is 0.26447693904240926 minutes
2025-09-09 14:09:46,124:INFO:SubProcess create_model() called ==================================
2025-09-09 14:09:46,124:INFO:Initializing create_model()
2025-09-09 14:09:46,124:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC55334910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:09:46,125:INFO:Checking exceptions
2025-09-09 14:09:46,125:INFO:Importing libraries
2025-09-09 14:09:46,125:INFO:Copying training dataset
2025-09-09 14:09:46,134:INFO:Defining folds
2025-09-09 14:09:46,134:INFO:Declaring metric variables
2025-09-09 14:09:46,138:INFO:Importing untrained model
2025-09-09 14:09:46,145:INFO:Decision Tree Classifier Imported successfully
2025-09-09 14:09:46,161:INFO:Starting cross validation
2025-09-09 14:09:46,165:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:09:47,746:INFO:Calculating mean and std
2025-09-09 14:09:47,747:INFO:Creating metrics dataframe
2025-09-09 14:09:47,749:INFO:Uploading results into container
2025-09-09 14:09:47,749:INFO:Uploading model into container now
2025-09-09 14:09:47,750:INFO:_master_model_container: 4
2025-09-09 14:09:47,750:INFO:_display_container: 2
2025-09-09 14:09:47,751:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-09-09 14:09:47,751:INFO:create_model() successfully completed......................................
2025-09-09 14:09:47,874:INFO:SubProcess create_model() end ==================================
2025-09-09 14:09:47,875:INFO:Creating metrics dataframe
2025-09-09 14:09:47,880:INFO:Initializing SVM - Linear Kernel
2025-09-09 14:09:47,880:INFO:Total runtime is 0.29381637573242186 minutes
2025-09-09 14:09:47,884:INFO:SubProcess create_model() called ==================================
2025-09-09 14:09:47,884:INFO:Initializing create_model()
2025-09-09 14:09:47,884:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC55334910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:09:47,884:INFO:Checking exceptions
2025-09-09 14:09:47,884:INFO:Importing libraries
2025-09-09 14:09:47,884:INFO:Copying training dataset
2025-09-09 14:09:47,893:INFO:Defining folds
2025-09-09 14:09:47,893:INFO:Declaring metric variables
2025-09-09 14:09:47,898:INFO:Importing untrained model
2025-09-09 14:09:47,904:INFO:SVM - Linear Kernel Imported successfully
2025-09-09 14:09:47,916:INFO:Starting cross validation
2025-09-09 14:09:47,921:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:09:49,592:INFO:Calculating mean and std
2025-09-09 14:09:49,593:INFO:Creating metrics dataframe
2025-09-09 14:09:49,595:INFO:Uploading results into container
2025-09-09 14:09:49,595:INFO:Uploading model into container now
2025-09-09 14:09:49,596:INFO:_master_model_container: 5
2025-09-09 14:09:49,596:INFO:_display_container: 2
2025-09-09 14:09:49,596:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-09-09 14:09:49,596:INFO:create_model() successfully completed......................................
2025-09-09 14:09:49,715:INFO:SubProcess create_model() end ==================================
2025-09-09 14:09:49,715:INFO:Creating metrics dataframe
2025-09-09 14:09:49,723:INFO:Initializing Ridge Classifier
2025-09-09 14:09:49,723:INFO:Total runtime is 0.32453349431355794 minutes
2025-09-09 14:09:49,726:INFO:SubProcess create_model() called ==================================
2025-09-09 14:09:49,728:INFO:Initializing create_model()
2025-09-09 14:09:49,728:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC55334910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:09:49,728:INFO:Checking exceptions
2025-09-09 14:09:49,729:INFO:Importing libraries
2025-09-09 14:09:49,729:INFO:Copying training dataset
2025-09-09 14:09:49,736:INFO:Defining folds
2025-09-09 14:09:49,737:INFO:Declaring metric variables
2025-09-09 14:09:49,744:INFO:Importing untrained model
2025-09-09 14:09:49,749:INFO:Ridge Classifier Imported successfully
2025-09-09 14:09:49,764:INFO:Starting cross validation
2025-09-09 14:09:49,767:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:09:51,459:INFO:Calculating mean and std
2025-09-09 14:09:51,460:INFO:Creating metrics dataframe
2025-09-09 14:09:51,462:INFO:Uploading results into container
2025-09-09 14:09:51,462:INFO:Uploading model into container now
2025-09-09 14:09:51,463:INFO:_master_model_container: 6
2025-09-09 14:09:51,463:INFO:_display_container: 2
2025-09-09 14:09:51,463:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-09-09 14:09:51,464:INFO:create_model() successfully completed......................................
2025-09-09 14:09:51,579:INFO:SubProcess create_model() end ==================================
2025-09-09 14:09:51,579:INFO:Creating metrics dataframe
2025-09-09 14:09:51,586:INFO:Initializing Random Forest Classifier
2025-09-09 14:09:51,586:INFO:Total runtime is 0.3555843154589335 minutes
2025-09-09 14:09:51,591:INFO:SubProcess create_model() called ==================================
2025-09-09 14:09:51,592:INFO:Initializing create_model()
2025-09-09 14:09:51,592:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC55334910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:09:51,592:INFO:Checking exceptions
2025-09-09 14:09:51,592:INFO:Importing libraries
2025-09-09 14:09:51,592:INFO:Copying training dataset
2025-09-09 14:09:51,600:INFO:Defining folds
2025-09-09 14:09:51,600:INFO:Declaring metric variables
2025-09-09 14:09:51,607:INFO:Importing untrained model
2025-09-09 14:09:51,612:INFO:Random Forest Classifier Imported successfully
2025-09-09 14:09:51,625:INFO:Starting cross validation
2025-09-09 14:09:51,628:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:09:53,747:INFO:Calculating mean and std
2025-09-09 14:09:53,747:INFO:Creating metrics dataframe
2025-09-09 14:09:53,749:INFO:Uploading results into container
2025-09-09 14:09:53,750:INFO:Uploading model into container now
2025-09-09 14:09:53,750:INFO:_master_model_container: 7
2025-09-09 14:09:53,750:INFO:_display_container: 2
2025-09-09 14:09:53,751:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-09-09 14:09:53,751:INFO:create_model() successfully completed......................................
2025-09-09 14:09:53,871:INFO:SubProcess create_model() end ==================================
2025-09-09 14:09:53,871:INFO:Creating metrics dataframe
2025-09-09 14:09:53,878:INFO:Initializing Quadratic Discriminant Analysis
2025-09-09 14:09:53,878:INFO:Total runtime is 0.39378055334091183 minutes
2025-09-09 14:09:53,883:INFO:SubProcess create_model() called ==================================
2025-09-09 14:09:53,884:INFO:Initializing create_model()
2025-09-09 14:09:53,884:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC55334910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:09:53,884:INFO:Checking exceptions
2025-09-09 14:09:53,884:INFO:Importing libraries
2025-09-09 14:09:53,884:INFO:Copying training dataset
2025-09-09 14:09:53,904:INFO:Defining folds
2025-09-09 14:09:53,904:INFO:Declaring metric variables
2025-09-09 14:09:53,914:INFO:Importing untrained model
2025-09-09 14:09:53,921:INFO:Quadratic Discriminant Analysis Imported successfully
2025-09-09 14:09:53,938:INFO:Starting cross validation
2025-09-09 14:09:53,942:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:09:55,504:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 14:09:55,518:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 14:09:55,519:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 14:09:55,555:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 14:09:55,583:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 14:09:55,605:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 14:09:55,620:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 14:09:55,697:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 14:09:55,717:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 14:09:55,724:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 14:09:56,068:INFO:Calculating mean and std
2025-09-09 14:09:56,070:INFO:Creating metrics dataframe
2025-09-09 14:09:56,073:INFO:Uploading results into container
2025-09-09 14:09:56,073:INFO:Uploading model into container now
2025-09-09 14:09:56,074:INFO:_master_model_container: 8
2025-09-09 14:09:56,074:INFO:_display_container: 2
2025-09-09 14:09:56,074:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-09-09 14:09:56,074:INFO:create_model() successfully completed......................................
2025-09-09 14:09:56,193:INFO:SubProcess create_model() end ==================================
2025-09-09 14:09:56,193:INFO:Creating metrics dataframe
2025-09-09 14:09:56,199:INFO:Initializing Ada Boost Classifier
2025-09-09 14:09:56,200:INFO:Total runtime is 0.4324831247329712 minutes
2025-09-09 14:09:56,204:INFO:SubProcess create_model() called ==================================
2025-09-09 14:09:56,205:INFO:Initializing create_model()
2025-09-09 14:09:56,205:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC55334910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:09:56,205:INFO:Checking exceptions
2025-09-09 14:09:56,205:INFO:Importing libraries
2025-09-09 14:09:56,206:INFO:Copying training dataset
2025-09-09 14:09:56,214:INFO:Defining folds
2025-09-09 14:09:56,214:INFO:Declaring metric variables
2025-09-09 14:09:56,220:INFO:Importing untrained model
2025-09-09 14:09:56,226:INFO:Ada Boost Classifier Imported successfully
2025-09-09 14:09:56,237:INFO:Starting cross validation
2025-09-09 14:09:56,240:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:09:57,497:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 14:09:57,499:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 14:09:57,538:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 14:09:57,553:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 14:09:57,555:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 14:09:57,576:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 14:09:57,610:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 14:09:57,617:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 14:09:57,645:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 14:09:57,674:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 14:09:57,883:INFO:Calculating mean and std
2025-09-09 14:09:57,883:INFO:Creating metrics dataframe
2025-09-09 14:09:57,886:INFO:Uploading results into container
2025-09-09 14:09:57,886:INFO:Uploading model into container now
2025-09-09 14:09:57,886:INFO:_master_model_container: 9
2025-09-09 14:09:57,886:INFO:_display_container: 2
2025-09-09 14:09:57,888:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-09-09 14:09:57,888:INFO:create_model() successfully completed......................................
2025-09-09 14:09:58,009:INFO:SubProcess create_model() end ==================================
2025-09-09 14:09:58,009:INFO:Creating metrics dataframe
2025-09-09 14:09:58,015:INFO:Initializing Gradient Boosting Classifier
2025-09-09 14:09:58,015:INFO:Total runtime is 0.4627233147621155 minutes
2025-09-09 14:09:58,019:INFO:SubProcess create_model() called ==================================
2025-09-09 14:09:58,020:INFO:Initializing create_model()
2025-09-09 14:09:58,020:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC55334910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:09:58,020:INFO:Checking exceptions
2025-09-09 14:09:58,021:INFO:Importing libraries
2025-09-09 14:09:58,021:INFO:Copying training dataset
2025-09-09 14:09:58,029:INFO:Defining folds
2025-09-09 14:09:58,029:INFO:Declaring metric variables
2025-09-09 14:09:58,034:INFO:Importing untrained model
2025-09-09 14:09:58,042:INFO:Gradient Boosting Classifier Imported successfully
2025-09-09 14:09:58,054:INFO:Starting cross validation
2025-09-09 14:09:58,059:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:10:00,837:INFO:Calculating mean and std
2025-09-09 14:10:00,838:INFO:Creating metrics dataframe
2025-09-09 14:10:00,841:INFO:Uploading results into container
2025-09-09 14:10:00,842:INFO:Uploading model into container now
2025-09-09 14:10:00,842:INFO:_master_model_container: 10
2025-09-09 14:10:00,842:INFO:_display_container: 2
2025-09-09 14:10:00,842:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-09-09 14:10:00,842:INFO:create_model() successfully completed......................................
2025-09-09 14:10:00,952:INFO:SubProcess create_model() end ==================================
2025-09-09 14:10:00,952:INFO:Creating metrics dataframe
2025-09-09 14:10:00,962:INFO:Initializing Linear Discriminant Analysis
2025-09-09 14:10:00,962:INFO:Total runtime is 0.5118383049964905 minutes
2025-09-09 14:10:00,966:INFO:SubProcess create_model() called ==================================
2025-09-09 14:10:00,967:INFO:Initializing create_model()
2025-09-09 14:10:00,967:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC55334910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:10:00,967:INFO:Checking exceptions
2025-09-09 14:10:00,967:INFO:Importing libraries
2025-09-09 14:10:00,967:INFO:Copying training dataset
2025-09-09 14:10:00,977:INFO:Defining folds
2025-09-09 14:10:00,978:INFO:Declaring metric variables
2025-09-09 14:10:00,984:INFO:Importing untrained model
2025-09-09 14:10:00,992:INFO:Linear Discriminant Analysis Imported successfully
2025-09-09 14:10:01,005:INFO:Starting cross validation
2025-09-09 14:10:01,008:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:10:03,847:INFO:Calculating mean and std
2025-09-09 14:10:03,847:INFO:Creating metrics dataframe
2025-09-09 14:10:03,849:INFO:Uploading results into container
2025-09-09 14:10:03,850:INFO:Uploading model into container now
2025-09-09 14:10:03,851:INFO:_master_model_container: 11
2025-09-09 14:10:03,851:INFO:_display_container: 2
2025-09-09 14:10:03,851:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-09-09 14:10:03,851:INFO:create_model() successfully completed......................................
2025-09-09 14:10:03,970:INFO:SubProcess create_model() end ==================================
2025-09-09 14:10:03,970:INFO:Creating metrics dataframe
2025-09-09 14:10:03,978:INFO:Initializing Extra Trees Classifier
2025-09-09 14:10:03,978:INFO:Total runtime is 0.5621141950289409 minutes
2025-09-09 14:10:03,983:INFO:SubProcess create_model() called ==================================
2025-09-09 14:10:03,984:INFO:Initializing create_model()
2025-09-09 14:10:03,984:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC55334910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:10:03,984:INFO:Checking exceptions
2025-09-09 14:10:03,984:INFO:Importing libraries
2025-09-09 14:10:03,984:INFO:Copying training dataset
2025-09-09 14:10:03,992:INFO:Defining folds
2025-09-09 14:10:03,992:INFO:Declaring metric variables
2025-09-09 14:10:03,997:INFO:Importing untrained model
2025-09-09 14:10:04,008:INFO:Extra Trees Classifier Imported successfully
2025-09-09 14:10:04,026:INFO:Starting cross validation
2025-09-09 14:10:04,032:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:10:06,076:INFO:Calculating mean and std
2025-09-09 14:10:06,076:INFO:Creating metrics dataframe
2025-09-09 14:10:06,079:INFO:Uploading results into container
2025-09-09 14:10:06,079:INFO:Uploading model into container now
2025-09-09 14:10:06,080:INFO:_master_model_container: 12
2025-09-09 14:10:06,080:INFO:_display_container: 2
2025-09-09 14:10:06,080:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-09-09 14:10:06,080:INFO:create_model() successfully completed......................................
2025-09-09 14:10:06,200:INFO:SubProcess create_model() end ==================================
2025-09-09 14:10:06,201:INFO:Creating metrics dataframe
2025-09-09 14:10:06,210:INFO:Initializing Extreme Gradient Boosting
2025-09-09 14:10:06,210:INFO:Total runtime is 0.5993033488591513 minutes
2025-09-09 14:10:06,214:INFO:SubProcess create_model() called ==================================
2025-09-09 14:10:06,214:INFO:Initializing create_model()
2025-09-09 14:10:06,214:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC55334910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:10:06,214:INFO:Checking exceptions
2025-09-09 14:10:06,214:INFO:Importing libraries
2025-09-09 14:10:06,214:INFO:Copying training dataset
2025-09-09 14:10:06,223:INFO:Defining folds
2025-09-09 14:10:06,223:INFO:Declaring metric variables
2025-09-09 14:10:06,231:INFO:Importing untrained model
2025-09-09 14:10:06,237:INFO:Extreme Gradient Boosting Imported successfully
2025-09-09 14:10:06,249:INFO:Starting cross validation
2025-09-09 14:10:06,253:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:10:08,274:INFO:Calculating mean and std
2025-09-09 14:10:08,275:INFO:Creating metrics dataframe
2025-09-09 14:10:08,277:INFO:Uploading results into container
2025-09-09 14:10:08,277:INFO:Uploading model into container now
2025-09-09 14:10:08,277:INFO:_master_model_container: 13
2025-09-09 14:10:08,277:INFO:_display_container: 2
2025-09-09 14:10:08,278:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-09-09 14:10:08,278:INFO:create_model() successfully completed......................................
2025-09-09 14:10:08,391:INFO:SubProcess create_model() end ==================================
2025-09-09 14:10:08,391:INFO:Creating metrics dataframe
2025-09-09 14:10:08,399:INFO:Initializing Light Gradient Boosting Machine
2025-09-09 14:10:08,400:INFO:Total runtime is 0.6358183860778809 minutes
2025-09-09 14:10:08,407:INFO:SubProcess create_model() called ==================================
2025-09-09 14:10:08,407:INFO:Initializing create_model()
2025-09-09 14:10:08,408:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC55334910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:10:08,408:INFO:Checking exceptions
2025-09-09 14:10:08,408:INFO:Importing libraries
2025-09-09 14:10:08,408:INFO:Copying training dataset
2025-09-09 14:10:08,421:INFO:Defining folds
2025-09-09 14:10:08,421:INFO:Declaring metric variables
2025-09-09 14:10:08,426:INFO:Importing untrained model
2025-09-09 14:10:08,431:INFO:Light Gradient Boosting Machine Imported successfully
2025-09-09 14:10:08,444:INFO:Starting cross validation
2025-09-09 14:10:08,448:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:10:10,778:INFO:Calculating mean and std
2025-09-09 14:10:10,778:INFO:Creating metrics dataframe
2025-09-09 14:10:10,781:INFO:Uploading results into container
2025-09-09 14:10:10,782:INFO:Uploading model into container now
2025-09-09 14:10:10,782:INFO:_master_model_container: 14
2025-09-09 14:10:10,782:INFO:_display_container: 2
2025-09-09 14:10:10,783:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-09-09 14:10:10,783:INFO:create_model() successfully completed......................................
2025-09-09 14:10:10,931:INFO:SubProcess create_model() end ==================================
2025-09-09 14:10:10,932:INFO:Creating metrics dataframe
2025-09-09 14:10:10,942:INFO:Initializing CatBoost Classifier
2025-09-09 14:10:10,942:INFO:Total runtime is 0.6781831542650859 minutes
2025-09-09 14:10:10,949:INFO:SubProcess create_model() called ==================================
2025-09-09 14:10:10,949:INFO:Initializing create_model()
2025-09-09 14:10:10,949:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC55334910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:10:10,949:INFO:Checking exceptions
2025-09-09 14:10:10,950:INFO:Importing libraries
2025-09-09 14:10:10,950:INFO:Copying training dataset
2025-09-09 14:10:10,959:INFO:Defining folds
2025-09-09 14:10:10,959:INFO:Declaring metric variables
2025-09-09 14:10:10,967:INFO:Importing untrained model
2025-09-09 14:10:10,977:INFO:CatBoost Classifier Imported successfully
2025-09-09 14:10:10,992:INFO:Starting cross validation
2025-09-09 14:10:10,995:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:10:20,295:INFO:Calculating mean and std
2025-09-09 14:10:20,295:INFO:Creating metrics dataframe
2025-09-09 14:10:20,297:INFO:Uploading results into container
2025-09-09 14:10:20,297:INFO:Uploading model into container now
2025-09-09 14:10:20,299:INFO:_master_model_container: 15
2025-09-09 14:10:20,299:INFO:_display_container: 2
2025-09-09 14:10:20,299:INFO:<catboost.core.CatBoostClassifier object at 0x000001DC53D5C4D0>
2025-09-09 14:10:20,299:INFO:create_model() successfully completed......................................
2025-09-09 14:10:20,418:INFO:SubProcess create_model() end ==================================
2025-09-09 14:10:20,419:INFO:Creating metrics dataframe
2025-09-09 14:10:20,430:INFO:Initializing Dummy Classifier
2025-09-09 14:10:20,430:INFO:Total runtime is 0.8363073229789735 minutes
2025-09-09 14:10:20,434:INFO:SubProcess create_model() called ==================================
2025-09-09 14:10:20,434:INFO:Initializing create_model()
2025-09-09 14:10:20,434:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC55334910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:10:20,434:INFO:Checking exceptions
2025-09-09 14:10:20,435:INFO:Importing libraries
2025-09-09 14:10:20,435:INFO:Copying training dataset
2025-09-09 14:10:20,444:INFO:Defining folds
2025-09-09 14:10:20,444:INFO:Declaring metric variables
2025-09-09 14:10:20,449:INFO:Importing untrained model
2025-09-09 14:10:20,456:INFO:Dummy Classifier Imported successfully
2025-09-09 14:10:20,467:INFO:Starting cross validation
2025-09-09 14:10:20,471:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:10:22,095:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 14:10:22,114:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 14:10:22,129:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 14:10:22,256:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 14:10:22,275:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 14:10:22,286:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 14:10:22,313:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 14:10:22,339:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 14:10:22,342:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 14:10:22,374:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 14:10:22,386:INFO:Calculating mean and std
2025-09-09 14:10:22,387:INFO:Creating metrics dataframe
2025-09-09 14:10:22,389:INFO:Uploading results into container
2025-09-09 14:10:22,390:INFO:Uploading model into container now
2025-09-09 14:10:22,390:INFO:_master_model_container: 16
2025-09-09 14:10:22,391:INFO:_display_container: 2
2025-09-09 14:10:22,391:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-09-09 14:10:22,391:INFO:create_model() successfully completed......................................
2025-09-09 14:10:22,514:INFO:SubProcess create_model() end ==================================
2025-09-09 14:10:22,514:INFO:Creating metrics dataframe
2025-09-09 14:10:22,535:INFO:Initializing create_model()
2025-09-09 14:10:22,535:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:10:22,535:INFO:Checking exceptions
2025-09-09 14:10:22,538:INFO:Importing libraries
2025-09-09 14:10:22,539:INFO:Copying training dataset
2025-09-09 14:10:22,547:INFO:Defining folds
2025-09-09 14:10:22,547:INFO:Declaring metric variables
2025-09-09 14:10:22,547:INFO:Importing untrained model
2025-09-09 14:10:22,547:INFO:Declaring custom model
2025-09-09 14:10:22,547:INFO:Logistic Regression Imported successfully
2025-09-09 14:10:22,550:INFO:Cross validation set to False
2025-09-09 14:10:22,550:INFO:Fitting Model
2025-09-09 14:10:23,019:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-09-09 14:10:23,019:INFO:create_model() successfully completed......................................
2025-09-09 14:10:23,167:INFO:_master_model_container: 16
2025-09-09 14:10:23,169:INFO:_display_container: 2
2025-09-09 14:10:23,170:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-09-09 14:10:23,170:INFO:compare_models() successfully completed......................................
2025-09-09 14:17:43,445:INFO:Initializing compare_models()
2025-09-09 14:17:43,445:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-09-09 14:17:43,445:INFO:Checking exceptions
2025-09-09 14:17:43,452:INFO:Preparing display monitor
2025-09-09 14:17:43,488:INFO:Initializing Logistic Regression
2025-09-09 14:17:43,490:INFO:Total runtime is 3.336668014526367e-05 minutes
2025-09-09 14:17:43,508:INFO:SubProcess create_model() called ==================================
2025-09-09 14:17:43,509:INFO:Initializing create_model()
2025-09-09 14:17:43,511:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC53CE0A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:17:43,511:INFO:Checking exceptions
2025-09-09 14:17:43,511:INFO:Importing libraries
2025-09-09 14:17:43,511:INFO:Copying training dataset
2025-09-09 14:17:43,529:INFO:Defining folds
2025-09-09 14:17:43,529:INFO:Declaring metric variables
2025-09-09 14:17:43,538:INFO:Importing untrained model
2025-09-09 14:17:43,543:INFO:Logistic Regression Imported successfully
2025-09-09 14:17:43,557:INFO:Starting cross validation
2025-09-09 14:17:43,564:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:17:53,471:INFO:Calculating mean and std
2025-09-09 14:17:53,473:INFO:Creating metrics dataframe
2025-09-09 14:17:53,480:INFO:Uploading results into container
2025-09-09 14:17:53,485:INFO:Uploading model into container now
2025-09-09 14:17:53,487:INFO:_master_model_container: 17
2025-09-09 14:17:53,487:INFO:_display_container: 3
2025-09-09 14:17:53,490:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-09-09 14:17:53,491:INFO:create_model() successfully completed......................................
2025-09-09 14:17:53,668:INFO:SubProcess create_model() end ==================================
2025-09-09 14:17:53,668:INFO:Creating metrics dataframe
2025-09-09 14:17:53,673:INFO:Initializing K Neighbors Classifier
2025-09-09 14:17:53,673:INFO:Total runtime is 0.16975610653559367 minutes
2025-09-09 14:17:53,679:INFO:SubProcess create_model() called ==================================
2025-09-09 14:17:53,679:INFO:Initializing create_model()
2025-09-09 14:17:53,679:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC53CE0A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:17:53,679:INFO:Checking exceptions
2025-09-09 14:17:53,680:INFO:Importing libraries
2025-09-09 14:17:53,680:INFO:Copying training dataset
2025-09-09 14:17:53,687:INFO:Defining folds
2025-09-09 14:17:53,687:INFO:Declaring metric variables
2025-09-09 14:17:53,696:INFO:Importing untrained model
2025-09-09 14:17:53,701:INFO:K Neighbors Classifier Imported successfully
2025-09-09 14:17:53,713:INFO:Starting cross validation
2025-09-09 14:17:53,718:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:17:58,263:INFO:Calculating mean and std
2025-09-09 14:17:58,264:INFO:Creating metrics dataframe
2025-09-09 14:17:58,268:INFO:Uploading results into container
2025-09-09 14:17:58,270:INFO:Uploading model into container now
2025-09-09 14:17:58,271:INFO:_master_model_container: 18
2025-09-09 14:17:58,271:INFO:_display_container: 3
2025-09-09 14:17:58,271:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-09-09 14:17:58,272:INFO:create_model() successfully completed......................................
2025-09-09 14:17:58,398:INFO:SubProcess create_model() end ==================================
2025-09-09 14:17:58,398:INFO:Creating metrics dataframe
2025-09-09 14:17:58,404:INFO:Initializing Naive Bayes
2025-09-09 14:17:58,404:INFO:Total runtime is 0.24860781828562417 minutes
2025-09-09 14:17:58,407:INFO:SubProcess create_model() called ==================================
2025-09-09 14:17:58,408:INFO:Initializing create_model()
2025-09-09 14:17:58,408:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC53CE0A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:17:58,408:INFO:Checking exceptions
2025-09-09 14:17:58,408:INFO:Importing libraries
2025-09-09 14:17:58,409:INFO:Copying training dataset
2025-09-09 14:17:58,419:INFO:Defining folds
2025-09-09 14:17:58,419:INFO:Declaring metric variables
2025-09-09 14:17:58,425:INFO:Importing untrained model
2025-09-09 14:17:58,432:INFO:Naive Bayes Imported successfully
2025-09-09 14:17:58,446:INFO:Starting cross validation
2025-09-09 14:17:58,450:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:18:00,040:INFO:Calculating mean and std
2025-09-09 14:18:00,041:INFO:Creating metrics dataframe
2025-09-09 14:18:00,043:INFO:Uploading results into container
2025-09-09 14:18:00,044:INFO:Uploading model into container now
2025-09-09 14:18:00,044:INFO:_master_model_container: 19
2025-09-09 14:18:00,045:INFO:_display_container: 3
2025-09-09 14:18:00,045:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-09-09 14:18:00,045:INFO:create_model() successfully completed......................................
2025-09-09 14:18:00,165:INFO:SubProcess create_model() end ==================================
2025-09-09 14:18:00,165:INFO:Creating metrics dataframe
2025-09-09 14:18:00,170:INFO:Initializing Decision Tree Classifier
2025-09-09 14:18:00,170:INFO:Total runtime is 0.27804081042607626 minutes
2025-09-09 14:18:00,174:INFO:SubProcess create_model() called ==================================
2025-09-09 14:18:00,176:INFO:Initializing create_model()
2025-09-09 14:18:00,176:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC53CE0A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:18:00,176:INFO:Checking exceptions
2025-09-09 14:18:00,176:INFO:Importing libraries
2025-09-09 14:18:00,176:INFO:Copying training dataset
2025-09-09 14:18:00,184:INFO:Defining folds
2025-09-09 14:18:00,185:INFO:Declaring metric variables
2025-09-09 14:18:00,190:INFO:Importing untrained model
2025-09-09 14:18:00,196:INFO:Decision Tree Classifier Imported successfully
2025-09-09 14:18:00,208:INFO:Starting cross validation
2025-09-09 14:18:00,213:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:18:01,825:INFO:Calculating mean and std
2025-09-09 14:18:01,826:INFO:Creating metrics dataframe
2025-09-09 14:18:01,829:INFO:Uploading results into container
2025-09-09 14:18:01,829:INFO:Uploading model into container now
2025-09-09 14:18:01,830:INFO:_master_model_container: 20
2025-09-09 14:18:01,830:INFO:_display_container: 3
2025-09-09 14:18:01,830:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-09-09 14:18:01,832:INFO:create_model() successfully completed......................................
2025-09-09 14:18:01,967:INFO:SubProcess create_model() end ==================================
2025-09-09 14:18:01,968:INFO:Creating metrics dataframe
2025-09-09 14:18:01,974:INFO:Initializing SVM - Linear Kernel
2025-09-09 14:18:01,974:INFO:Total runtime is 0.3081000844637553 minutes
2025-09-09 14:18:01,979:INFO:SubProcess create_model() called ==================================
2025-09-09 14:18:01,980:INFO:Initializing create_model()
2025-09-09 14:18:01,980:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC53CE0A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:18:01,980:INFO:Checking exceptions
2025-09-09 14:18:01,980:INFO:Importing libraries
2025-09-09 14:18:01,980:INFO:Copying training dataset
2025-09-09 14:18:01,987:INFO:Defining folds
2025-09-09 14:18:01,987:INFO:Declaring metric variables
2025-09-09 14:18:01,993:INFO:Importing untrained model
2025-09-09 14:18:02,000:INFO:SVM - Linear Kernel Imported successfully
2025-09-09 14:18:02,012:INFO:Starting cross validation
2025-09-09 14:18:02,019:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:18:03,752:INFO:Calculating mean and std
2025-09-09 14:18:03,753:INFO:Creating metrics dataframe
2025-09-09 14:18:03,756:INFO:Uploading results into container
2025-09-09 14:18:03,756:INFO:Uploading model into container now
2025-09-09 14:18:03,756:INFO:_master_model_container: 21
2025-09-09 14:18:03,757:INFO:_display_container: 3
2025-09-09 14:18:03,757:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-09-09 14:18:03,757:INFO:create_model() successfully completed......................................
2025-09-09 14:18:03,885:INFO:SubProcess create_model() end ==================================
2025-09-09 14:18:03,885:INFO:Creating metrics dataframe
2025-09-09 14:18:03,891:INFO:Initializing Ridge Classifier
2025-09-09 14:18:03,891:INFO:Total runtime is 0.3400518258412679 minutes
2025-09-09 14:18:03,896:INFO:SubProcess create_model() called ==================================
2025-09-09 14:18:03,898:INFO:Initializing create_model()
2025-09-09 14:18:03,898:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC53CE0A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:18:03,898:INFO:Checking exceptions
2025-09-09 14:18:03,899:INFO:Importing libraries
2025-09-09 14:18:03,899:INFO:Copying training dataset
2025-09-09 14:18:03,906:INFO:Defining folds
2025-09-09 14:18:03,906:INFO:Declaring metric variables
2025-09-09 14:18:03,914:INFO:Importing untrained model
2025-09-09 14:18:03,920:INFO:Ridge Classifier Imported successfully
2025-09-09 14:18:03,935:INFO:Starting cross validation
2025-09-09 14:18:03,939:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:18:05,615:INFO:Calculating mean and std
2025-09-09 14:18:05,615:INFO:Creating metrics dataframe
2025-09-09 14:18:05,617:INFO:Uploading results into container
2025-09-09 14:18:05,618:INFO:Uploading model into container now
2025-09-09 14:18:05,619:INFO:_master_model_container: 22
2025-09-09 14:18:05,619:INFO:_display_container: 3
2025-09-09 14:18:05,619:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-09-09 14:18:05,619:INFO:create_model() successfully completed......................................
2025-09-09 14:18:05,751:INFO:SubProcess create_model() end ==================================
2025-09-09 14:18:05,751:INFO:Creating metrics dataframe
2025-09-09 14:18:05,757:INFO:Initializing Random Forest Classifier
2025-09-09 14:18:05,758:INFO:Total runtime is 0.37116292715072635 minutes
2025-09-09 14:18:05,762:INFO:SubProcess create_model() called ==================================
2025-09-09 14:18:05,763:INFO:Initializing create_model()
2025-09-09 14:18:05,763:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC53CE0A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:18:05,763:INFO:Checking exceptions
2025-09-09 14:18:05,763:INFO:Importing libraries
2025-09-09 14:18:05,763:INFO:Copying training dataset
2025-09-09 14:18:05,770:INFO:Defining folds
2025-09-09 14:18:05,771:INFO:Declaring metric variables
2025-09-09 14:18:05,777:INFO:Importing untrained model
2025-09-09 14:18:05,784:INFO:Random Forest Classifier Imported successfully
2025-09-09 14:18:05,797:INFO:Starting cross validation
2025-09-09 14:18:05,800:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:18:07,996:INFO:Calculating mean and std
2025-09-09 14:18:07,996:INFO:Creating metrics dataframe
2025-09-09 14:18:07,999:INFO:Uploading results into container
2025-09-09 14:18:08,000:INFO:Uploading model into container now
2025-09-09 14:18:08,000:INFO:_master_model_container: 23
2025-09-09 14:18:08,000:INFO:_display_container: 3
2025-09-09 14:18:08,001:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-09-09 14:18:08,001:INFO:create_model() successfully completed......................................
2025-09-09 14:18:08,124:INFO:SubProcess create_model() end ==================================
2025-09-09 14:18:08,124:INFO:Creating metrics dataframe
2025-09-09 14:18:08,132:INFO:Initializing Quadratic Discriminant Analysis
2025-09-09 14:18:08,133:INFO:Total runtime is 0.41074614524841313 minutes
2025-09-09 14:18:08,137:INFO:SubProcess create_model() called ==================================
2025-09-09 14:18:08,137:INFO:Initializing create_model()
2025-09-09 14:18:08,137:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC53CE0A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:18:08,137:INFO:Checking exceptions
2025-09-09 14:18:08,137:INFO:Importing libraries
2025-09-09 14:18:08,138:INFO:Copying training dataset
2025-09-09 14:18:08,147:INFO:Defining folds
2025-09-09 14:18:08,147:INFO:Declaring metric variables
2025-09-09 14:18:08,151:INFO:Importing untrained model
2025-09-09 14:18:08,157:INFO:Quadratic Discriminant Analysis Imported successfully
2025-09-09 14:18:08,170:INFO:Starting cross validation
2025-09-09 14:18:08,174:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:18:09,756:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 14:18:09,820:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 14:18:09,828:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 14:18:09,859:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 14:18:09,937:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 14:18:09,991:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 14:18:09,995:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 14:18:09,995:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 14:18:10,001:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 14:18:10,076:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 14:18:10,428:INFO:Calculating mean and std
2025-09-09 14:18:10,430:INFO:Creating metrics dataframe
2025-09-09 14:18:10,432:INFO:Uploading results into container
2025-09-09 14:18:10,433:INFO:Uploading model into container now
2025-09-09 14:18:10,433:INFO:_master_model_container: 24
2025-09-09 14:18:10,433:INFO:_display_container: 3
2025-09-09 14:18:10,433:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-09-09 14:18:10,433:INFO:create_model() successfully completed......................................
2025-09-09 14:18:10,557:INFO:SubProcess create_model() end ==================================
2025-09-09 14:18:10,557:INFO:Creating metrics dataframe
2025-09-09 14:18:10,566:INFO:Initializing Ada Boost Classifier
2025-09-09 14:18:10,566:INFO:Total runtime is 0.45130363305409754 minutes
2025-09-09 14:18:10,572:INFO:SubProcess create_model() called ==================================
2025-09-09 14:18:10,572:INFO:Initializing create_model()
2025-09-09 14:18:10,572:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC53CE0A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:18:10,573:INFO:Checking exceptions
2025-09-09 14:18:10,573:INFO:Importing libraries
2025-09-09 14:18:10,573:INFO:Copying training dataset
2025-09-09 14:18:10,582:INFO:Defining folds
2025-09-09 14:18:10,582:INFO:Declaring metric variables
2025-09-09 14:18:10,588:INFO:Importing untrained model
2025-09-09 14:18:10,592:INFO:Ada Boost Classifier Imported successfully
2025-09-09 14:18:10,605:INFO:Starting cross validation
2025-09-09 14:18:10,609:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:18:11,731:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 14:18:11,855:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 14:18:11,899:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 14:18:11,914:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 14:18:11,941:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 14:18:11,948:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 14:18:11,955:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 14:18:11,958:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 14:18:11,966:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 14:18:12,005:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 14:18:12,197:INFO:Calculating mean and std
2025-09-09 14:18:12,198:INFO:Creating metrics dataframe
2025-09-09 14:18:12,200:INFO:Uploading results into container
2025-09-09 14:18:12,200:INFO:Uploading model into container now
2025-09-09 14:18:12,201:INFO:_master_model_container: 25
2025-09-09 14:18:12,201:INFO:_display_container: 3
2025-09-09 14:18:12,201:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-09-09 14:18:12,201:INFO:create_model() successfully completed......................................
2025-09-09 14:18:12,340:INFO:SubProcess create_model() end ==================================
2025-09-09 14:18:12,340:INFO:Creating metrics dataframe
2025-09-09 14:18:12,347:INFO:Initializing Gradient Boosting Classifier
2025-09-09 14:18:12,348:INFO:Total runtime is 0.48100779056549076 minutes
2025-09-09 14:18:12,353:INFO:SubProcess create_model() called ==================================
2025-09-09 14:18:12,354:INFO:Initializing create_model()
2025-09-09 14:18:12,354:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC53CE0A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:18:12,354:INFO:Checking exceptions
2025-09-09 14:18:12,354:INFO:Importing libraries
2025-09-09 14:18:12,354:INFO:Copying training dataset
2025-09-09 14:18:12,362:INFO:Defining folds
2025-09-09 14:18:12,362:INFO:Declaring metric variables
2025-09-09 14:18:12,369:INFO:Importing untrained model
2025-09-09 14:18:12,374:INFO:Gradient Boosting Classifier Imported successfully
2025-09-09 14:18:12,388:INFO:Starting cross validation
2025-09-09 14:18:12,392:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:18:15,191:INFO:Calculating mean and std
2025-09-09 14:18:15,192:INFO:Creating metrics dataframe
2025-09-09 14:18:15,195:INFO:Uploading results into container
2025-09-09 14:18:15,195:INFO:Uploading model into container now
2025-09-09 14:18:15,196:INFO:_master_model_container: 26
2025-09-09 14:18:15,196:INFO:_display_container: 3
2025-09-09 14:18:15,196:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-09-09 14:18:15,196:INFO:create_model() successfully completed......................................
2025-09-09 14:18:15,315:INFO:SubProcess create_model() end ==================================
2025-09-09 14:18:15,315:INFO:Creating metrics dataframe
2025-09-09 14:18:15,323:INFO:Initializing Linear Discriminant Analysis
2025-09-09 14:18:15,323:INFO:Total runtime is 0.5305847962697348 minutes
2025-09-09 14:18:15,328:INFO:SubProcess create_model() called ==================================
2025-09-09 14:18:15,329:INFO:Initializing create_model()
2025-09-09 14:18:15,329:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC53CE0A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:18:15,329:INFO:Checking exceptions
2025-09-09 14:18:15,329:INFO:Importing libraries
2025-09-09 14:18:15,329:INFO:Copying training dataset
2025-09-09 14:18:15,337:INFO:Defining folds
2025-09-09 14:18:15,337:INFO:Declaring metric variables
2025-09-09 14:18:15,342:INFO:Importing untrained model
2025-09-09 14:18:15,348:INFO:Linear Discriminant Analysis Imported successfully
2025-09-09 14:18:15,361:INFO:Starting cross validation
2025-09-09 14:18:15,366:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:18:18,374:INFO:Calculating mean and std
2025-09-09 14:18:18,375:INFO:Creating metrics dataframe
2025-09-09 14:18:18,378:INFO:Uploading results into container
2025-09-09 14:18:18,379:INFO:Uploading model into container now
2025-09-09 14:18:18,380:INFO:_master_model_container: 27
2025-09-09 14:18:18,380:INFO:_display_container: 3
2025-09-09 14:18:18,380:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-09-09 14:18:18,381:INFO:create_model() successfully completed......................................
2025-09-09 14:18:18,511:INFO:SubProcess create_model() end ==================================
2025-09-09 14:18:18,512:INFO:Creating metrics dataframe
2025-09-09 14:18:18,520:INFO:Initializing Extra Trees Classifier
2025-09-09 14:18:18,520:INFO:Total runtime is 0.5838648080825807 minutes
2025-09-09 14:18:18,525:INFO:SubProcess create_model() called ==================================
2025-09-09 14:18:18,525:INFO:Initializing create_model()
2025-09-09 14:18:18,525:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC53CE0A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:18:18,525:INFO:Checking exceptions
2025-09-09 14:18:18,525:INFO:Importing libraries
2025-09-09 14:18:18,526:INFO:Copying training dataset
2025-09-09 14:18:18,536:INFO:Defining folds
2025-09-09 14:18:18,536:INFO:Declaring metric variables
2025-09-09 14:18:18,542:INFO:Importing untrained model
2025-09-09 14:18:18,548:INFO:Extra Trees Classifier Imported successfully
2025-09-09 14:18:18,563:INFO:Starting cross validation
2025-09-09 14:18:18,566:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:18:21,088:INFO:Calculating mean and std
2025-09-09 14:18:21,089:INFO:Creating metrics dataframe
2025-09-09 14:18:21,093:INFO:Uploading results into container
2025-09-09 14:18:21,094:INFO:Uploading model into container now
2025-09-09 14:18:21,094:INFO:_master_model_container: 28
2025-09-09 14:18:21,095:INFO:_display_container: 3
2025-09-09 14:18:21,095:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-09-09 14:18:21,095:INFO:create_model() successfully completed......................................
2025-09-09 14:18:21,217:INFO:SubProcess create_model() end ==================================
2025-09-09 14:18:21,218:INFO:Creating metrics dataframe
2025-09-09 14:18:21,225:INFO:Initializing Extreme Gradient Boosting
2025-09-09 14:18:21,225:INFO:Total runtime is 0.6289493918418886 minutes
2025-09-09 14:18:21,231:INFO:SubProcess create_model() called ==================================
2025-09-09 14:18:21,232:INFO:Initializing create_model()
2025-09-09 14:18:21,232:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC53CE0A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:18:21,232:INFO:Checking exceptions
2025-09-09 14:18:21,232:INFO:Importing libraries
2025-09-09 14:18:21,232:INFO:Copying training dataset
2025-09-09 14:18:21,240:INFO:Defining folds
2025-09-09 14:18:21,240:INFO:Declaring metric variables
2025-09-09 14:18:21,249:INFO:Importing untrained model
2025-09-09 14:18:21,255:INFO:Extreme Gradient Boosting Imported successfully
2025-09-09 14:18:21,269:INFO:Starting cross validation
2025-09-09 14:18:21,272:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:18:23,469:INFO:Calculating mean and std
2025-09-09 14:18:23,470:INFO:Creating metrics dataframe
2025-09-09 14:18:23,472:INFO:Uploading results into container
2025-09-09 14:18:23,472:INFO:Uploading model into container now
2025-09-09 14:18:23,473:INFO:_master_model_container: 29
2025-09-09 14:18:23,473:INFO:_display_container: 3
2025-09-09 14:18:23,473:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-09-09 14:18:23,474:INFO:create_model() successfully completed......................................
2025-09-09 14:18:23,605:INFO:SubProcess create_model() end ==================================
2025-09-09 14:18:23,606:INFO:Creating metrics dataframe
2025-09-09 14:18:23,616:INFO:Initializing Light Gradient Boosting Machine
2025-09-09 14:18:23,616:INFO:Total runtime is 0.6687940319379172 minutes
2025-09-09 14:18:23,620:INFO:SubProcess create_model() called ==================================
2025-09-09 14:18:23,621:INFO:Initializing create_model()
2025-09-09 14:18:23,621:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC53CE0A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:18:23,621:INFO:Checking exceptions
2025-09-09 14:18:23,621:INFO:Importing libraries
2025-09-09 14:18:23,621:INFO:Copying training dataset
2025-09-09 14:18:23,630:INFO:Defining folds
2025-09-09 14:18:23,631:INFO:Declaring metric variables
2025-09-09 14:18:23,638:INFO:Importing untrained model
2025-09-09 14:18:23,643:INFO:Light Gradient Boosting Machine Imported successfully
2025-09-09 14:18:23,656:INFO:Starting cross validation
2025-09-09 14:18:23,659:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:18:26,055:INFO:Calculating mean and std
2025-09-09 14:18:26,056:INFO:Creating metrics dataframe
2025-09-09 14:18:26,059:INFO:Uploading results into container
2025-09-09 14:18:26,059:INFO:Uploading model into container now
2025-09-09 14:18:26,060:INFO:_master_model_container: 30
2025-09-09 14:18:26,060:INFO:_display_container: 3
2025-09-09 14:18:26,061:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-09-09 14:18:26,061:INFO:create_model() successfully completed......................................
2025-09-09 14:18:26,207:INFO:SubProcess create_model() end ==================================
2025-09-09 14:18:26,207:INFO:Creating metrics dataframe
2025-09-09 14:18:26,215:INFO:Initializing CatBoost Classifier
2025-09-09 14:18:26,215:INFO:Total runtime is 0.7121219913164776 minutes
2025-09-09 14:18:26,220:INFO:SubProcess create_model() called ==================================
2025-09-09 14:18:26,220:INFO:Initializing create_model()
2025-09-09 14:18:26,221:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC53CE0A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:18:26,221:INFO:Checking exceptions
2025-09-09 14:18:26,221:INFO:Importing libraries
2025-09-09 14:18:26,221:INFO:Copying training dataset
2025-09-09 14:18:26,229:INFO:Defining folds
2025-09-09 14:18:26,229:INFO:Declaring metric variables
2025-09-09 14:18:26,235:INFO:Importing untrained model
2025-09-09 14:18:26,240:INFO:CatBoost Classifier Imported successfully
2025-09-09 14:18:26,252:INFO:Starting cross validation
2025-09-09 14:18:26,256:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:18:43,307:INFO:Calculating mean and std
2025-09-09 14:18:43,308:INFO:Creating metrics dataframe
2025-09-09 14:18:43,312:INFO:Uploading results into container
2025-09-09 14:18:43,312:INFO:Uploading model into container now
2025-09-09 14:18:43,313:INFO:_master_model_container: 31
2025-09-09 14:18:43,313:INFO:_display_container: 3
2025-09-09 14:18:43,313:INFO:<catboost.core.CatBoostClassifier object at 0x000001DC54072690>
2025-09-09 14:18:43,313:INFO:create_model() successfully completed......................................
2025-09-09 14:18:43,445:INFO:SubProcess create_model() end ==================================
2025-09-09 14:18:43,446:INFO:Creating metrics dataframe
2025-09-09 14:18:43,454:INFO:Initializing Dummy Classifier
2025-09-09 14:18:43,454:INFO:Total runtime is 0.999427354335785 minutes
2025-09-09 14:18:43,457:INFO:SubProcess create_model() called ==================================
2025-09-09 14:18:43,458:INFO:Initializing create_model()
2025-09-09 14:18:43,458:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DC53CE0A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:18:43,458:INFO:Checking exceptions
2025-09-09 14:18:43,458:INFO:Importing libraries
2025-09-09 14:18:43,459:INFO:Copying training dataset
2025-09-09 14:18:43,467:INFO:Defining folds
2025-09-09 14:18:43,468:INFO:Declaring metric variables
2025-09-09 14:18:43,475:INFO:Importing untrained model
2025-09-09 14:18:43,482:INFO:Dummy Classifier Imported successfully
2025-09-09 14:18:43,494:INFO:Starting cross validation
2025-09-09 14:18:43,497:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:18:45,114:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 14:18:45,128:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 14:18:45,162:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 14:18:45,168:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 14:18:45,178:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 14:18:45,215:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 14:18:45,451:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 14:18:45,454:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 14:18:45,521:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 14:18:45,529:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 14:18:45,545:INFO:Calculating mean and std
2025-09-09 14:18:45,546:INFO:Creating metrics dataframe
2025-09-09 14:18:45,548:INFO:Uploading results into container
2025-09-09 14:18:45,549:INFO:Uploading model into container now
2025-09-09 14:18:45,550:INFO:_master_model_container: 32
2025-09-09 14:18:45,550:INFO:_display_container: 3
2025-09-09 14:18:45,550:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-09-09 14:18:45,550:INFO:create_model() successfully completed......................................
2025-09-09 14:18:45,678:INFO:SubProcess create_model() end ==================================
2025-09-09 14:18:45,678:INFO:Creating metrics dataframe
2025-09-09 14:18:45,700:INFO:Initializing create_model()
2025-09-09 14:18:45,700:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:18:45,700:INFO:Checking exceptions
2025-09-09 14:18:45,702:INFO:Importing libraries
2025-09-09 14:18:45,702:INFO:Copying training dataset
2025-09-09 14:18:45,712:INFO:Defining folds
2025-09-09 14:18:45,713:INFO:Declaring metric variables
2025-09-09 14:18:45,713:INFO:Importing untrained model
2025-09-09 14:18:45,713:INFO:Declaring custom model
2025-09-09 14:18:45,714:INFO:Logistic Regression Imported successfully
2025-09-09 14:18:45,717:INFO:Cross validation set to False
2025-09-09 14:18:45,717:INFO:Fitting Model
2025-09-09 14:18:46,215:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-09-09 14:18:46,215:INFO:create_model() successfully completed......................................
2025-09-09 14:18:46,338:INFO:Initializing create_model()
2025-09-09 14:18:46,339:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:18:46,339:INFO:Checking exceptions
2025-09-09 14:18:46,341:INFO:Importing libraries
2025-09-09 14:18:46,341:INFO:Copying training dataset
2025-09-09 14:18:46,350:INFO:Defining folds
2025-09-09 14:18:46,350:INFO:Declaring metric variables
2025-09-09 14:18:46,350:INFO:Importing untrained model
2025-09-09 14:18:46,351:INFO:Declaring custom model
2025-09-09 14:18:46,351:INFO:K Neighbors Classifier Imported successfully
2025-09-09 14:18:46,352:INFO:Cross validation set to False
2025-09-09 14:18:46,353:INFO:Fitting Model
2025-09-09 14:18:46,798:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-09-09 14:18:46,798:INFO:create_model() successfully completed......................................
2025-09-09 14:18:46,918:INFO:Initializing create_model()
2025-09-09 14:18:46,919:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:18:46,919:INFO:Checking exceptions
2025-09-09 14:18:46,921:INFO:Importing libraries
2025-09-09 14:18:46,921:INFO:Copying training dataset
2025-09-09 14:18:46,929:INFO:Defining folds
2025-09-09 14:18:46,929:INFO:Declaring metric variables
2025-09-09 14:18:46,929:INFO:Importing untrained model
2025-09-09 14:18:46,929:INFO:Declaring custom model
2025-09-09 14:18:46,930:INFO:Naive Bayes Imported successfully
2025-09-09 14:18:46,932:INFO:Cross validation set to False
2025-09-09 14:18:46,932:INFO:Fitting Model
2025-09-09 14:18:47,408:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-09-09 14:18:47,408:INFO:create_model() successfully completed......................................
2025-09-09 14:18:47,549:INFO:_master_model_container: 32
2025-09-09 14:18:47,549:INFO:_display_container: 3
2025-09-09 14:18:47,550:INFO:[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), GaussianNB(priors=None, var_smoothing=1e-09)]
2025-09-09 14:18:47,550:INFO:compare_models() successfully completed......................................
2025-09-09 14:20:08,737:INFO:Initializing evaluate_model()
2025-09-09 14:20:08,738:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-09-09 14:20:08,753:INFO:Initializing plot_model()
2025-09-09 14:20:08,753:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-09-09 14:20:08,754:INFO:Checking exceptions
2025-09-09 14:20:08,759:INFO:Preloading libraries
2025-09-09 14:20:08,759:INFO:Copying training dataset
2025-09-09 14:20:08,759:INFO:Plot type: pipeline
2025-09-09 14:20:08,915:INFO:Visual Rendered Successfully
2025-09-09 14:20:09,041:INFO:plot_model() successfully completed......................................
2025-09-09 14:20:19,177:INFO:Initializing plot_model()
2025-09-09 14:20:19,177:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=pr, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-09-09 14:20:19,178:INFO:Checking exceptions
2025-09-09 14:20:19,182:INFO:Preloading libraries
2025-09-09 14:20:19,182:INFO:Copying training dataset
2025-09-09 14:20:19,182:INFO:Plot type: pr
2025-09-09 14:20:19,433:INFO:Fitting Model
2025-09-09 14:20:19,434:INFO:Scoring test/hold-out set
2025-09-09 14:20:19,543:INFO:Visual Rendered Successfully
2025-09-09 14:20:19,687:INFO:plot_model() successfully completed......................................
2025-09-09 14:20:23,870:INFO:Initializing plot_model()
2025-09-09 14:20:23,870:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=error, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-09-09 14:20:23,871:INFO:Checking exceptions
2025-09-09 14:20:23,875:INFO:Preloading libraries
2025-09-09 14:20:23,875:INFO:Copying training dataset
2025-09-09 14:20:23,875:INFO:Plot type: error
2025-09-09 14:20:24,095:INFO:Fitting Model
2025-09-09 14:20:24,095:INFO:Scoring test/hold-out set
2025-09-09 14:20:24,205:INFO:Visual Rendered Successfully
2025-09-09 14:20:24,324:INFO:plot_model() successfully completed......................................
2025-09-09 14:20:41,208:INFO:Initializing plot_model()
2025-09-09 14:20:41,210:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=class_report, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-09-09 14:20:41,210:INFO:Checking exceptions
2025-09-09 14:20:41,214:INFO:Preloading libraries
2025-09-09 14:20:41,214:INFO:Copying training dataset
2025-09-09 14:20:41,214:INFO:Plot type: class_report
2025-09-09 14:20:41,447:INFO:Fitting Model
2025-09-09 14:20:41,447:INFO:Scoring test/hold-out set
2025-09-09 14:20:41,598:INFO:Visual Rendered Successfully
2025-09-09 14:20:41,738:INFO:plot_model() successfully completed......................................
2025-09-09 14:20:47,251:INFO:Initializing plot_model()
2025-09-09 14:20:47,251:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001DC53D38C90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=rfe, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-09-09 14:20:47,251:INFO:Checking exceptions
2025-09-09 14:20:47,255:INFO:Preloading libraries
2025-09-09 14:20:47,255:INFO:Copying training dataset
2025-09-09 14:20:47,255:INFO:Plot type: rfe
2025-09-09 14:20:47,497:INFO:Fitting Model
2025-09-09 14:23:26,982:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-09 14:23:26,982:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-09 14:23:26,983:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-09 14:23:26,983:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-09 14:23:31,561:INFO:PyCaret ClassificationExperiment
2025-09-09 14:23:31,562:INFO:Logging name: clf-default-name
2025-09-09 14:23:31,562:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-09-09 14:23:31,562:INFO:version 3.3.2
2025-09-09 14:23:31,562:INFO:Initializing setup()
2025-09-09 14:23:31,562:INFO:self.USI: a931
2025-09-09 14:23:31,562:INFO:self._variable_keys: {'y_test', 'memory', 'log_plots_param', '_available_plots', 'fold_groups_param', 'is_multiclass', 'X_train', 'USI', 'y', 'n_jobs_param', 'fix_imbalance', 'X', '_ml_usecase', 'exp_id', 'exp_name_log', 'idx', 'html_param', 'gpu_n_jobs_param', 'target_param', 'fold_generator', 'X_test', 'gpu_param', 'y_train', 'pipeline', 'fold_shuffle_param', 'data', 'seed', 'logging_param'}
2025-09-09 14:23:31,562:INFO:Checking environment
2025-09-09 14:23:31,562:INFO:python_version: 3.11.10
2025-09-09 14:23:31,562:INFO:python_build: ('main', 'Oct  3 2024 07:22:26')
2025-09-09 14:23:31,562:INFO:machine: AMD64
2025-09-09 14:23:31,562:INFO:platform: Windows-10-10.0.26100-SP0
2025-09-09 14:23:31,566:INFO:Memory: svmem(total=16837152768, available=4776333312, percent=71.6, used=12060819456, free=4776333312)
2025-09-09 14:23:31,566:INFO:Physical Core: 10
2025-09-09 14:23:31,566:INFO:Logical Core: 12
2025-09-09 14:23:31,566:INFO:Checking libraries
2025-09-09 14:23:31,566:INFO:System:
2025-09-09 14:23:31,566:INFO:    python: 3.11.10 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:26) [MSC v.1929 64 bit (AMD64)]
2025-09-09 14:23:31,566:INFO:executable: c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\python.exe
2025-09-09 14:23:31,567:INFO:   machine: Windows-10-10.0.26100-SP0
2025-09-09 14:23:31,567:INFO:PyCaret required dependencies:
2025-09-09 14:23:31,900:INFO:                 pip: 24.2
2025-09-09 14:23:31,900:INFO:          setuptools: 75.1.0
2025-09-09 14:23:31,900:INFO:             pycaret: 3.3.2
2025-09-09 14:23:31,900:INFO:             IPython: 9.2.0
2025-09-09 14:23:31,900:INFO:          ipywidgets: 8.1.7
2025-09-09 14:23:31,900:INFO:                tqdm: 4.67.1
2025-09-09 14:23:31,900:INFO:               numpy: 1.24.4
2025-09-09 14:23:31,900:INFO:              pandas: 1.5.3
2025-09-09 14:23:31,900:INFO:              jinja2: 3.1.6
2025-09-09 14:23:31,900:INFO:               scipy: 1.11.4
2025-09-09 14:23:31,900:INFO:              joblib: 1.3.2
2025-09-09 14:23:31,900:INFO:             sklearn: 1.4.2
2025-09-09 14:23:31,900:INFO:                pyod: 2.0.5
2025-09-09 14:23:31,900:INFO:            imblearn: 0.13.0
2025-09-09 14:23:31,900:INFO:   category_encoders: 2.7.0
2025-09-09 14:23:31,900:INFO:            lightgbm: 4.6.0
2025-09-09 14:23:31,901:INFO:               numba: 0.61.0
2025-09-09 14:23:31,901:INFO:            requests: 2.32.3
2025-09-09 14:23:31,901:INFO:          matplotlib: 3.7.5
2025-09-09 14:23:31,901:INFO:          scikitplot: 0.3.7
2025-09-09 14:23:31,901:INFO:         yellowbrick: 1.5
2025-09-09 14:23:31,901:INFO:              plotly: 5.24.1
2025-09-09 14:23:31,901:INFO:    plotly-resampler: Not installed
2025-09-09 14:23:31,901:INFO:             kaleido: 0.2.1
2025-09-09 14:23:31,901:INFO:           schemdraw: 0.15
2025-09-09 14:23:31,901:INFO:         statsmodels: 0.14.4
2025-09-09 14:23:31,901:INFO:              sktime: 0.26.0
2025-09-09 14:23:31,901:INFO:               tbats: 1.1.3
2025-09-09 14:23:31,901:INFO:            pmdarima: 2.0.4
2025-09-09 14:23:31,901:INFO:              psutil: 7.0.0
2025-09-09 14:23:31,901:INFO:          markupsafe: 3.0.2
2025-09-09 14:23:31,901:INFO:             pickle5: Not installed
2025-09-09 14:23:31,901:INFO:         cloudpickle: 3.1.1
2025-09-09 14:23:31,901:INFO:         deprecation: 2.1.0
2025-09-09 14:23:31,901:INFO:              xxhash: 3.5.0
2025-09-09 14:23:31,901:INFO:           wurlitzer: Not installed
2025-09-09 14:23:31,901:INFO:PyCaret optional dependencies:
2025-09-09 14:23:35,067:INFO:                shap: 0.44.1
2025-09-09 14:23:35,067:INFO:           interpret: 0.6.11
2025-09-09 14:23:35,067:INFO:                umap: 0.5.7
2025-09-09 14:23:35,067:INFO:     ydata_profiling: 4.16.1
2025-09-09 14:23:35,067:INFO:  explainerdashboard: 0.5.1
2025-09-09 14:23:35,067:INFO:             autoviz: Not installed
2025-09-09 14:23:35,067:INFO:           fairlearn: 0.7.0
2025-09-09 14:23:35,067:INFO:          deepchecks: Not installed
2025-09-09 14:23:35,067:INFO:             xgboost: 3.0.2
2025-09-09 14:23:35,067:INFO:            catboost: 1.2.8
2025-09-09 14:23:35,067:INFO:              kmodes: 0.12.2
2025-09-09 14:23:35,068:INFO:             mlxtend: 0.23.4
2025-09-09 14:23:35,068:INFO:       statsforecast: 1.5.0
2025-09-09 14:23:35,068:INFO:        tune_sklearn: Not installed
2025-09-09 14:23:35,068:INFO:                 ray: Not installed
2025-09-09 14:23:35,068:INFO:            hyperopt: 0.2.7
2025-09-09 14:23:35,068:INFO:              optuna: 4.3.0
2025-09-09 14:23:35,068:INFO:               skopt: 0.10.2
2025-09-09 14:23:35,068:INFO:              mlflow: 3.1.0
2025-09-09 14:23:35,068:INFO:              gradio: 5.33.1
2025-09-09 14:23:35,068:INFO:             fastapi: 0.115.12
2025-09-09 14:23:35,068:INFO:             uvicorn: 0.34.3
2025-09-09 14:23:35,068:INFO:              m2cgen: 0.10.0
2025-09-09 14:23:35,068:INFO:           evidently: 0.4.40
2025-09-09 14:23:35,068:INFO:               fugue: 0.8.7
2025-09-09 14:23:35,068:INFO:           streamlit: 1.45.1
2025-09-09 14:23:35,068:INFO:             prophet: 1.1.7
2025-09-09 14:23:35,068:INFO:None
2025-09-09 14:23:35,068:INFO:Set up data.
2025-09-09 14:23:35,101:INFO:Set up folding strategy.
2025-09-09 14:23:35,101:INFO:Set up train/test split.
2025-09-09 14:23:35,116:INFO:Set up index.
2025-09-09 14:23:35,117:INFO:Assigning column types.
2025-09-09 14:23:35,121:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-09-09 14:23:35,146:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-09 14:23:35,148:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-09 14:23:35,177:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 14:23:35,179:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 14:23:35,227:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-09 14:23:35,227:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-09 14:23:35,244:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 14:23:35,245:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 14:23:35,246:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-09-09 14:23:35,273:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-09 14:23:35,290:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 14:23:35,291:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 14:23:35,324:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-09 14:23:35,341:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 14:23:35,343:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 14:23:35,345:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-09-09 14:23:35,396:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 14:23:35,398:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 14:23:35,443:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 14:23:35,445:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 14:23:35,451:INFO:Preparing preprocessing pipeline...
2025-09-09 14:23:35,451:INFO:Set up date feature engineering.
2025-09-09 14:23:35,451:INFO:Set up simple imputation.
2025-09-09 14:23:35,458:INFO:Set up encoding of ordinal features.
2025-09-09 14:23:35,462:INFO:Set up encoding of categorical features.
2025-09-09 14:23:35,462:INFO:Set up feature normalization.
2025-09-09 14:23:36,208:INFO:Finished creating preprocessing pipeline.
2025-09-09 14:23:36,228:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\SBM_ME~1\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['TimeStart', 'TimeStop',
                                             'ProductionDate', 'ApproveDate',
                                             'CreateDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    inc...
                                                                    'LeaderID',
                                                                    'ProdCode',
                                                                    'Lot',
                                                                    'LNCNo',
                                                                    'SessionID2',
                                                                    'FGCode',
                                                                    'LotNo'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-09-09 14:23:36,228:INFO:Creating final display dataframe.
2025-09-09 14:23:36,486:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target              isNC
2                   Target type            Binary
3           Original data shape       (12216, 31)
4        Transformed data shape      (12216, 161)
5   Transformed train set shape       (8551, 161)
6    Transformed test set shape       (3665, 161)
7              Numeric features                 3
8                 Date features                 5
9          Categorical features                22
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                    Normalize              True
17             Normalize method            zscore
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              a931
2025-09-09 14:23:36,546:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 14:23:36,547:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 14:23:36,594:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 14:23:36,595:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 14:23:36,596:INFO:setup() successfully completed in 5.07s...............
2025-09-09 14:23:36,641:INFO:Initializing compare_models()
2025-09-09 14:23:36,641:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178D5EFA510>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000178D5EFA510>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-09-09 14:23:36,642:INFO:Checking exceptions
2025-09-09 14:23:36,653:INFO:Preparing display monitor
2025-09-09 14:23:36,730:INFO:Initializing Logistic Regression
2025-09-09 14:23:36,731:INFO:Total runtime is 1.6681353251139323e-05 minutes
2025-09-09 14:23:36,737:INFO:SubProcess create_model() called ==================================
2025-09-09 14:23:36,738:INFO:Initializing create_model()
2025-09-09 14:23:36,738:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178D5EFA510>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178E0A04590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:23:36,738:INFO:Checking exceptions
2025-09-09 14:23:36,738:INFO:Importing libraries
2025-09-09 14:23:36,738:INFO:Copying training dataset
2025-09-09 14:23:36,758:INFO:Defining folds
2025-09-09 14:23:36,758:INFO:Declaring metric variables
2025-09-09 14:23:36,768:INFO:Importing untrained model
2025-09-09 14:23:36,777:INFO:Logistic Regression Imported successfully
2025-09-09 14:23:36,790:INFO:Starting cross validation
2025-09-09 14:23:36,795:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:23:45,237:INFO:Calculating mean and std
2025-09-09 14:23:45,238:INFO:Creating metrics dataframe
2025-09-09 14:23:45,241:INFO:Uploading results into container
2025-09-09 14:23:45,243:INFO:Uploading model into container now
2025-09-09 14:23:45,243:INFO:_master_model_container: 1
2025-09-09 14:23:45,243:INFO:_display_container: 2
2025-09-09 14:23:45,244:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-09-09 14:23:45,244:INFO:create_model() successfully completed......................................
2025-09-09 14:23:45,379:INFO:SubProcess create_model() end ==================================
2025-09-09 14:23:45,379:INFO:Creating metrics dataframe
2025-09-09 14:23:45,387:INFO:Initializing K Neighbors Classifier
2025-09-09 14:23:45,387:INFO:Total runtime is 0.14428289333979288 minutes
2025-09-09 14:23:45,392:INFO:SubProcess create_model() called ==================================
2025-09-09 14:23:45,392:INFO:Initializing create_model()
2025-09-09 14:23:45,392:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178D5EFA510>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178E0A04590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:23:45,393:INFO:Checking exceptions
2025-09-09 14:23:45,393:INFO:Importing libraries
2025-09-09 14:23:45,393:INFO:Copying training dataset
2025-09-09 14:23:45,401:INFO:Defining folds
2025-09-09 14:23:45,401:INFO:Declaring metric variables
2025-09-09 14:23:45,408:INFO:Importing untrained model
2025-09-09 14:23:45,413:INFO:K Neighbors Classifier Imported successfully
2025-09-09 14:23:45,426:INFO:Starting cross validation
2025-09-09 14:23:45,430:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:23:50,249:INFO:Calculating mean and std
2025-09-09 14:23:50,251:INFO:Creating metrics dataframe
2025-09-09 14:23:50,256:INFO:Uploading results into container
2025-09-09 14:23:50,257:INFO:Uploading model into container now
2025-09-09 14:23:50,257:INFO:_master_model_container: 2
2025-09-09 14:23:50,257:INFO:_display_container: 2
2025-09-09 14:23:50,258:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-09-09 14:23:50,258:INFO:create_model() successfully completed......................................
2025-09-09 14:23:50,384:INFO:SubProcess create_model() end ==================================
2025-09-09 14:23:50,385:INFO:Creating metrics dataframe
2025-09-09 14:23:50,393:INFO:Initializing Naive Bayes
2025-09-09 14:23:50,393:INFO:Total runtime is 0.22771837711334228 minutes
2025-09-09 14:23:50,396:INFO:SubProcess create_model() called ==================================
2025-09-09 14:23:50,397:INFO:Initializing create_model()
2025-09-09 14:23:50,397:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178D5EFA510>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178E0A04590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:23:50,397:INFO:Checking exceptions
2025-09-09 14:23:50,397:INFO:Importing libraries
2025-09-09 14:23:50,397:INFO:Copying training dataset
2025-09-09 14:23:50,406:INFO:Defining folds
2025-09-09 14:23:50,407:INFO:Declaring metric variables
2025-09-09 14:23:50,411:INFO:Importing untrained model
2025-09-09 14:23:50,417:INFO:Naive Bayes Imported successfully
2025-09-09 14:23:50,436:INFO:Starting cross validation
2025-09-09 14:23:50,439:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:23:52,188:INFO:Calculating mean and std
2025-09-09 14:23:52,189:INFO:Creating metrics dataframe
2025-09-09 14:23:52,191:INFO:Uploading results into container
2025-09-09 14:23:52,192:INFO:Uploading model into container now
2025-09-09 14:23:52,192:INFO:_master_model_container: 3
2025-09-09 14:23:52,192:INFO:_display_container: 2
2025-09-09 14:23:52,192:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-09-09 14:23:52,192:INFO:create_model() successfully completed......................................
2025-09-09 14:23:52,307:INFO:SubProcess create_model() end ==================================
2025-09-09 14:23:52,307:INFO:Creating metrics dataframe
2025-09-09 14:23:52,315:INFO:Initializing Decision Tree Classifier
2025-09-09 14:23:52,315:INFO:Total runtime is 0.25975571473439535 minutes
2025-09-09 14:23:52,321:INFO:SubProcess create_model() called ==================================
2025-09-09 14:23:52,321:INFO:Initializing create_model()
2025-09-09 14:23:52,321:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178D5EFA510>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178E0A04590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:23:52,323:INFO:Checking exceptions
2025-09-09 14:23:52,323:INFO:Importing libraries
2025-09-09 14:23:52,323:INFO:Copying training dataset
2025-09-09 14:23:52,330:INFO:Defining folds
2025-09-09 14:23:52,330:INFO:Declaring metric variables
2025-09-09 14:23:52,335:INFO:Importing untrained model
2025-09-09 14:23:52,341:INFO:Decision Tree Classifier Imported successfully
2025-09-09 14:23:52,353:INFO:Starting cross validation
2025-09-09 14:23:52,358:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:23:53,997:INFO:Calculating mean and std
2025-09-09 14:23:53,998:INFO:Creating metrics dataframe
2025-09-09 14:23:54,001:INFO:Uploading results into container
2025-09-09 14:23:54,001:INFO:Uploading model into container now
2025-09-09 14:23:54,002:INFO:_master_model_container: 4
2025-09-09 14:23:54,002:INFO:_display_container: 2
2025-09-09 14:23:54,002:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-09-09 14:23:54,002:INFO:create_model() successfully completed......................................
2025-09-09 14:23:54,117:INFO:SubProcess create_model() end ==================================
2025-09-09 14:23:54,118:INFO:Creating metrics dataframe
2025-09-09 14:23:54,124:INFO:Initializing SVM - Linear Kernel
2025-09-09 14:23:54,124:INFO:Total runtime is 0.28989741404851277 minutes
2025-09-09 14:23:54,129:INFO:SubProcess create_model() called ==================================
2025-09-09 14:23:54,129:INFO:Initializing create_model()
2025-09-09 14:23:54,130:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178D5EFA510>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178E0A04590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:23:54,130:INFO:Checking exceptions
2025-09-09 14:23:54,130:INFO:Importing libraries
2025-09-09 14:23:54,130:INFO:Copying training dataset
2025-09-09 14:23:54,138:INFO:Defining folds
2025-09-09 14:23:54,139:INFO:Declaring metric variables
2025-09-09 14:23:54,144:INFO:Importing untrained model
2025-09-09 14:23:54,151:INFO:SVM - Linear Kernel Imported successfully
2025-09-09 14:23:54,164:INFO:Starting cross validation
2025-09-09 14:23:54,167:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:23:55,960:INFO:Calculating mean and std
2025-09-09 14:23:55,961:INFO:Creating metrics dataframe
2025-09-09 14:23:55,963:INFO:Uploading results into container
2025-09-09 14:23:55,963:INFO:Uploading model into container now
2025-09-09 14:23:55,963:INFO:_master_model_container: 5
2025-09-09 14:23:55,963:INFO:_display_container: 2
2025-09-09 14:23:55,964:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-09-09 14:23:55,964:INFO:create_model() successfully completed......................................
2025-09-09 14:23:56,080:INFO:SubProcess create_model() end ==================================
2025-09-09 14:23:56,081:INFO:Creating metrics dataframe
2025-09-09 14:23:56,089:INFO:Initializing Ridge Classifier
2025-09-09 14:23:56,089:INFO:Total runtime is 0.3226499557495117 minutes
2025-09-09 14:23:56,093:INFO:SubProcess create_model() called ==================================
2025-09-09 14:23:56,093:INFO:Initializing create_model()
2025-09-09 14:23:56,093:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178D5EFA510>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178E0A04590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:23:56,094:INFO:Checking exceptions
2025-09-09 14:23:56,094:INFO:Importing libraries
2025-09-09 14:23:56,094:INFO:Copying training dataset
2025-09-09 14:23:56,103:INFO:Defining folds
2025-09-09 14:23:56,104:INFO:Declaring metric variables
2025-09-09 14:23:56,110:INFO:Importing untrained model
2025-09-09 14:23:56,117:INFO:Ridge Classifier Imported successfully
2025-09-09 14:23:56,131:INFO:Starting cross validation
2025-09-09 14:23:56,134:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:23:57,912:INFO:Calculating mean and std
2025-09-09 14:23:57,912:INFO:Creating metrics dataframe
2025-09-09 14:23:57,914:INFO:Uploading results into container
2025-09-09 14:23:57,916:INFO:Uploading model into container now
2025-09-09 14:23:57,916:INFO:_master_model_container: 6
2025-09-09 14:23:57,916:INFO:_display_container: 2
2025-09-09 14:23:57,916:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-09-09 14:23:57,917:INFO:create_model() successfully completed......................................
2025-09-09 14:23:58,030:INFO:SubProcess create_model() end ==================================
2025-09-09 14:23:58,030:INFO:Creating metrics dataframe
2025-09-09 14:23:58,038:INFO:Initializing Random Forest Classifier
2025-09-09 14:23:58,038:INFO:Total runtime is 0.35513738393783567 minutes
2025-09-09 14:23:58,042:INFO:SubProcess create_model() called ==================================
2025-09-09 14:23:58,043:INFO:Initializing create_model()
2025-09-09 14:23:58,043:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178D5EFA510>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178E0A04590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:23:58,043:INFO:Checking exceptions
2025-09-09 14:23:58,043:INFO:Importing libraries
2025-09-09 14:23:58,043:INFO:Copying training dataset
2025-09-09 14:23:58,052:INFO:Defining folds
2025-09-09 14:23:58,052:INFO:Declaring metric variables
2025-09-09 14:23:58,058:INFO:Importing untrained model
2025-09-09 14:23:58,064:INFO:Random Forest Classifier Imported successfully
2025-09-09 14:23:58,089:INFO:Starting cross validation
2025-09-09 14:23:58,093:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:24:00,294:INFO:Calculating mean and std
2025-09-09 14:24:00,295:INFO:Creating metrics dataframe
2025-09-09 14:24:00,297:INFO:Uploading results into container
2025-09-09 14:24:00,298:INFO:Uploading model into container now
2025-09-09 14:24:00,298:INFO:_master_model_container: 7
2025-09-09 14:24:00,298:INFO:_display_container: 2
2025-09-09 14:24:00,299:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-09-09 14:24:00,299:INFO:create_model() successfully completed......................................
2025-09-09 14:24:00,411:INFO:SubProcess create_model() end ==================================
2025-09-09 14:24:00,413:INFO:Creating metrics dataframe
2025-09-09 14:24:00,420:INFO:Initializing Quadratic Discriminant Analysis
2025-09-09 14:24:00,421:INFO:Total runtime is 0.3948634028434753 minutes
2025-09-09 14:24:00,425:INFO:SubProcess create_model() called ==================================
2025-09-09 14:24:00,425:INFO:Initializing create_model()
2025-09-09 14:24:00,427:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178D5EFA510>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178E0A04590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:24:00,427:INFO:Checking exceptions
2025-09-09 14:24:00,427:INFO:Importing libraries
2025-09-09 14:24:00,427:INFO:Copying training dataset
2025-09-09 14:24:00,435:INFO:Defining folds
2025-09-09 14:24:00,436:INFO:Declaring metric variables
2025-09-09 14:24:00,441:INFO:Importing untrained model
2025-09-09 14:24:00,448:INFO:Quadratic Discriminant Analysis Imported successfully
2025-09-09 14:24:00,461:INFO:Starting cross validation
2025-09-09 14:24:00,465:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:24:02,173:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 14:24:02,227:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 14:24:02,231:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 14:24:02,260:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 14:24:02,291:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 14:24:02,374:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 14:24:02,399:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 14:24:02,452:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 14:24:02,500:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 14:24:02,808:INFO:Calculating mean and std
2025-09-09 14:24:02,809:INFO:Creating metrics dataframe
2025-09-09 14:24:02,811:INFO:Uploading results into container
2025-09-09 14:24:02,811:INFO:Uploading model into container now
2025-09-09 14:24:02,811:INFO:_master_model_container: 8
2025-09-09 14:24:02,812:INFO:_display_container: 2
2025-09-09 14:24:02,812:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-09-09 14:24:02,812:INFO:create_model() successfully completed......................................
2025-09-09 14:24:02,929:INFO:SubProcess create_model() end ==================================
2025-09-09 14:24:02,929:INFO:Creating metrics dataframe
2025-09-09 14:24:02,937:INFO:Initializing Ada Boost Classifier
2025-09-09 14:24:02,937:INFO:Total runtime is 0.4367903312047322 minutes
2025-09-09 14:24:02,941:INFO:SubProcess create_model() called ==================================
2025-09-09 14:24:02,941:INFO:Initializing create_model()
2025-09-09 14:24:02,942:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178D5EFA510>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178E0A04590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:24:02,942:INFO:Checking exceptions
2025-09-09 14:24:02,942:INFO:Importing libraries
2025-09-09 14:24:02,942:INFO:Copying training dataset
2025-09-09 14:24:02,950:INFO:Defining folds
2025-09-09 14:24:02,951:INFO:Declaring metric variables
2025-09-09 14:24:02,957:INFO:Importing untrained model
2025-09-09 14:24:02,963:INFO:Ada Boost Classifier Imported successfully
2025-09-09 14:24:02,977:INFO:Starting cross validation
2025-09-09 14:24:02,980:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:24:04,277:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 14:24:04,339:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 14:24:04,358:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 14:24:04,381:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 14:24:04,385:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 14:24:04,412:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 14:24:04,444:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 14:24:04,476:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 14:24:04,491:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 14:24:04,505:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 14:24:04,702:INFO:Calculating mean and std
2025-09-09 14:24:04,703:INFO:Creating metrics dataframe
2025-09-09 14:24:04,705:INFO:Uploading results into container
2025-09-09 14:24:04,705:INFO:Uploading model into container now
2025-09-09 14:24:04,706:INFO:_master_model_container: 9
2025-09-09 14:24:04,706:INFO:_display_container: 2
2025-09-09 14:24:04,706:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-09-09 14:24:04,707:INFO:create_model() successfully completed......................................
2025-09-09 14:24:04,822:INFO:SubProcess create_model() end ==================================
2025-09-09 14:24:04,822:INFO:Creating metrics dataframe
2025-09-09 14:24:04,830:INFO:Initializing Gradient Boosting Classifier
2025-09-09 14:24:04,830:INFO:Total runtime is 0.4683332165082295 minutes
2025-09-09 14:24:04,833:INFO:SubProcess create_model() called ==================================
2025-09-09 14:24:04,835:INFO:Initializing create_model()
2025-09-09 14:24:04,835:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178D5EFA510>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178E0A04590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:24:04,835:INFO:Checking exceptions
2025-09-09 14:24:04,835:INFO:Importing libraries
2025-09-09 14:24:04,835:INFO:Copying training dataset
2025-09-09 14:24:04,842:INFO:Defining folds
2025-09-09 14:24:04,842:INFO:Declaring metric variables
2025-09-09 14:24:04,846:INFO:Importing untrained model
2025-09-09 14:24:04,854:INFO:Gradient Boosting Classifier Imported successfully
2025-09-09 14:24:04,866:INFO:Starting cross validation
2025-09-09 14:24:04,872:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:24:07,833:INFO:Calculating mean and std
2025-09-09 14:24:07,834:INFO:Creating metrics dataframe
2025-09-09 14:24:07,836:INFO:Uploading results into container
2025-09-09 14:24:07,836:INFO:Uploading model into container now
2025-09-09 14:24:07,837:INFO:_master_model_container: 10
2025-09-09 14:24:07,837:INFO:_display_container: 2
2025-09-09 14:24:07,837:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-09-09 14:24:07,838:INFO:create_model() successfully completed......................................
2025-09-09 14:24:07,947:INFO:SubProcess create_model() end ==================================
2025-09-09 14:24:07,947:INFO:Creating metrics dataframe
2025-09-09 14:24:07,954:INFO:Initializing Linear Discriminant Analysis
2025-09-09 14:24:07,954:INFO:Total runtime is 0.5204129139582315 minutes
2025-09-09 14:24:07,958:INFO:SubProcess create_model() called ==================================
2025-09-09 14:24:07,959:INFO:Initializing create_model()
2025-09-09 14:24:07,959:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178D5EFA510>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178E0A04590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:24:07,959:INFO:Checking exceptions
2025-09-09 14:24:07,959:INFO:Importing libraries
2025-09-09 14:24:07,959:INFO:Copying training dataset
2025-09-09 14:24:07,967:INFO:Defining folds
2025-09-09 14:24:07,967:INFO:Declaring metric variables
2025-09-09 14:24:07,971:INFO:Importing untrained model
2025-09-09 14:24:07,976:INFO:Linear Discriminant Analysis Imported successfully
2025-09-09 14:24:07,988:INFO:Starting cross validation
2025-09-09 14:24:07,992:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:24:10,905:INFO:Calculating mean and std
2025-09-09 14:24:10,905:INFO:Creating metrics dataframe
2025-09-09 14:24:10,907:INFO:Uploading results into container
2025-09-09 14:24:10,908:INFO:Uploading model into container now
2025-09-09 14:24:10,908:INFO:_master_model_container: 11
2025-09-09 14:24:10,908:INFO:_display_container: 2
2025-09-09 14:24:10,909:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-09-09 14:24:10,909:INFO:create_model() successfully completed......................................
2025-09-09 14:24:11,036:INFO:SubProcess create_model() end ==================================
2025-09-09 14:24:11,036:INFO:Creating metrics dataframe
2025-09-09 14:24:11,043:INFO:Initializing Extra Trees Classifier
2025-09-09 14:24:11,043:INFO:Total runtime is 0.5718903342882792 minutes
2025-09-09 14:24:11,047:INFO:SubProcess create_model() called ==================================
2025-09-09 14:24:11,048:INFO:Initializing create_model()
2025-09-09 14:24:11,048:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178D5EFA510>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178E0A04590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:24:11,048:INFO:Checking exceptions
2025-09-09 14:24:11,048:INFO:Importing libraries
2025-09-09 14:24:11,049:INFO:Copying training dataset
2025-09-09 14:24:11,058:INFO:Defining folds
2025-09-09 14:24:11,058:INFO:Declaring metric variables
2025-09-09 14:24:11,062:INFO:Importing untrained model
2025-09-09 14:24:11,069:INFO:Extra Trees Classifier Imported successfully
2025-09-09 14:24:11,083:INFO:Starting cross validation
2025-09-09 14:24:11,086:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:24:13,322:INFO:Calculating mean and std
2025-09-09 14:24:13,323:INFO:Creating metrics dataframe
2025-09-09 14:24:13,327:INFO:Uploading results into container
2025-09-09 14:24:13,328:INFO:Uploading model into container now
2025-09-09 14:24:13,328:INFO:_master_model_container: 12
2025-09-09 14:24:13,328:INFO:_display_container: 2
2025-09-09 14:24:13,329:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-09-09 14:24:13,329:INFO:create_model() successfully completed......................................
2025-09-09 14:24:13,453:INFO:SubProcess create_model() end ==================================
2025-09-09 14:24:13,453:INFO:Creating metrics dataframe
2025-09-09 14:24:13,460:INFO:Initializing Extreme Gradient Boosting
2025-09-09 14:24:13,460:INFO:Total runtime is 0.6121667941411336 minutes
2025-09-09 14:24:13,464:INFO:SubProcess create_model() called ==================================
2025-09-09 14:24:13,464:INFO:Initializing create_model()
2025-09-09 14:24:13,464:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178D5EFA510>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178E0A04590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:24:13,464:INFO:Checking exceptions
2025-09-09 14:24:13,464:INFO:Importing libraries
2025-09-09 14:24:13,465:INFO:Copying training dataset
2025-09-09 14:24:13,474:INFO:Defining folds
2025-09-09 14:24:13,474:INFO:Declaring metric variables
2025-09-09 14:24:13,479:INFO:Importing untrained model
2025-09-09 14:24:13,486:INFO:Extreme Gradient Boosting Imported successfully
2025-09-09 14:24:13,498:INFO:Starting cross validation
2025-09-09 14:24:13,504:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:24:15,666:INFO:Calculating mean and std
2025-09-09 14:24:15,668:INFO:Creating metrics dataframe
2025-09-09 14:24:15,671:INFO:Uploading results into container
2025-09-09 14:24:15,672:INFO:Uploading model into container now
2025-09-09 14:24:15,672:INFO:_master_model_container: 13
2025-09-09 14:24:15,673:INFO:_display_container: 2
2025-09-09 14:24:15,673:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-09-09 14:24:15,674:INFO:create_model() successfully completed......................................
2025-09-09 14:24:15,796:INFO:SubProcess create_model() end ==================================
2025-09-09 14:24:15,797:INFO:Creating metrics dataframe
2025-09-09 14:24:15,806:INFO:Initializing Light Gradient Boosting Machine
2025-09-09 14:24:15,806:INFO:Total runtime is 0.6512691736221313 minutes
2025-09-09 14:24:15,811:INFO:SubProcess create_model() called ==================================
2025-09-09 14:24:15,811:INFO:Initializing create_model()
2025-09-09 14:24:15,812:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178D5EFA510>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178E0A04590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:24:15,812:INFO:Checking exceptions
2025-09-09 14:24:15,812:INFO:Importing libraries
2025-09-09 14:24:15,812:INFO:Copying training dataset
2025-09-09 14:24:15,820:INFO:Defining folds
2025-09-09 14:24:15,820:INFO:Declaring metric variables
2025-09-09 14:24:15,826:INFO:Importing untrained model
2025-09-09 14:24:15,832:INFO:Light Gradient Boosting Machine Imported successfully
2025-09-09 14:24:15,847:INFO:Starting cross validation
2025-09-09 14:24:15,851:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:24:18,405:INFO:Calculating mean and std
2025-09-09 14:24:18,406:INFO:Creating metrics dataframe
2025-09-09 14:24:18,410:INFO:Uploading results into container
2025-09-09 14:24:18,410:INFO:Uploading model into container now
2025-09-09 14:24:18,411:INFO:_master_model_container: 14
2025-09-09 14:24:18,411:INFO:_display_container: 2
2025-09-09 14:24:18,413:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-09-09 14:24:18,413:INFO:create_model() successfully completed......................................
2025-09-09 14:24:18,556:INFO:SubProcess create_model() end ==================================
2025-09-09 14:24:18,556:INFO:Creating metrics dataframe
2025-09-09 14:24:18,563:INFO:Initializing CatBoost Classifier
2025-09-09 14:24:18,563:INFO:Total runtime is 0.6972299337387085 minutes
2025-09-09 14:24:18,570:INFO:SubProcess create_model() called ==================================
2025-09-09 14:24:18,571:INFO:Initializing create_model()
2025-09-09 14:24:18,571:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178D5EFA510>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178E0A04590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:24:18,571:INFO:Checking exceptions
2025-09-09 14:24:18,571:INFO:Importing libraries
2025-09-09 14:24:18,571:INFO:Copying training dataset
2025-09-09 14:24:18,580:INFO:Defining folds
2025-09-09 14:24:18,580:INFO:Declaring metric variables
2025-09-09 14:24:18,587:INFO:Importing untrained model
2025-09-09 14:24:18,595:INFO:CatBoost Classifier Imported successfully
2025-09-09 14:24:18,616:INFO:Starting cross validation
2025-09-09 14:24:18,621:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:24:36,685:INFO:Calculating mean and std
2025-09-09 14:24:36,686:INFO:Creating metrics dataframe
2025-09-09 14:24:36,688:INFO:Uploading results into container
2025-09-09 14:24:36,689:INFO:Uploading model into container now
2025-09-09 14:24:36,689:INFO:_master_model_container: 15
2025-09-09 14:24:36,689:INFO:_display_container: 2
2025-09-09 14:24:36,689:INFO:<catboost.core.CatBoostClassifier object at 0x00000178E09DC410>
2025-09-09 14:24:36,689:INFO:create_model() successfully completed......................................
2025-09-09 14:24:36,810:INFO:SubProcess create_model() end ==================================
2025-09-09 14:24:36,810:INFO:Creating metrics dataframe
2025-09-09 14:24:36,820:INFO:Initializing Dummy Classifier
2025-09-09 14:24:36,821:INFO:Total runtime is 1.0015254060427348 minutes
2025-09-09 14:24:36,827:INFO:SubProcess create_model() called ==================================
2025-09-09 14:24:36,827:INFO:Initializing create_model()
2025-09-09 14:24:36,828:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178D5EFA510>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178E0A04590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:24:36,828:INFO:Checking exceptions
2025-09-09 14:24:36,828:INFO:Importing libraries
2025-09-09 14:24:36,828:INFO:Copying training dataset
2025-09-09 14:24:36,838:INFO:Defining folds
2025-09-09 14:24:36,839:INFO:Declaring metric variables
2025-09-09 14:24:36,844:INFO:Importing untrained model
2025-09-09 14:24:36,851:INFO:Dummy Classifier Imported successfully
2025-09-09 14:24:36,863:INFO:Starting cross validation
2025-09-09 14:24:36,867:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:24:38,567:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 14:24:38,632:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 14:24:38,690:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 14:24:38,708:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 14:24:38,722:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 14:24:38,727:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 14:24:38,737:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 14:24:38,819:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 14:24:38,861:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 14:24:38,886:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 14:24:38,897:INFO:Calculating mean and std
2025-09-09 14:24:38,898:INFO:Creating metrics dataframe
2025-09-09 14:24:38,901:INFO:Uploading results into container
2025-09-09 14:24:38,901:INFO:Uploading model into container now
2025-09-09 14:24:38,902:INFO:_master_model_container: 16
2025-09-09 14:24:38,902:INFO:_display_container: 2
2025-09-09 14:24:38,902:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-09-09 14:24:38,902:INFO:create_model() successfully completed......................................
2025-09-09 14:24:39,052:INFO:SubProcess create_model() end ==================================
2025-09-09 14:24:39,053:INFO:Creating metrics dataframe
2025-09-09 14:24:39,079:INFO:Initializing create_model()
2025-09-09 14:24:39,080:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178D5EFA510>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:24:39,080:INFO:Checking exceptions
2025-09-09 14:24:39,084:INFO:Importing libraries
2025-09-09 14:24:39,085:INFO:Copying training dataset
2025-09-09 14:24:39,103:INFO:Defining folds
2025-09-09 14:24:39,103:INFO:Declaring metric variables
2025-09-09 14:24:39,104:INFO:Importing untrained model
2025-09-09 14:24:39,104:INFO:Declaring custom model
2025-09-09 14:24:39,106:INFO:Logistic Regression Imported successfully
2025-09-09 14:24:39,110:INFO:Cross validation set to False
2025-09-09 14:24:39,111:INFO:Fitting Model
2025-09-09 14:24:39,779:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-09-09 14:24:39,779:INFO:create_model() successfully completed......................................
2025-09-09 14:24:39,894:INFO:Initializing create_model()
2025-09-09 14:24:39,895:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178D5EFA510>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:24:39,895:INFO:Checking exceptions
2025-09-09 14:24:39,897:INFO:Importing libraries
2025-09-09 14:24:39,897:INFO:Copying training dataset
2025-09-09 14:24:39,905:INFO:Defining folds
2025-09-09 14:24:39,905:INFO:Declaring metric variables
2025-09-09 14:24:39,905:INFO:Importing untrained model
2025-09-09 14:24:39,905:INFO:Declaring custom model
2025-09-09 14:24:39,905:INFO:K Neighbors Classifier Imported successfully
2025-09-09 14:24:39,907:INFO:Cross validation set to False
2025-09-09 14:24:39,907:INFO:Fitting Model
2025-09-09 14:24:40,371:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-09-09 14:24:40,371:INFO:create_model() successfully completed......................................
2025-09-09 14:24:40,489:INFO:Initializing create_model()
2025-09-09 14:24:40,489:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178D5EFA510>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:24:40,489:INFO:Checking exceptions
2025-09-09 14:24:40,491:INFO:Importing libraries
2025-09-09 14:24:40,491:INFO:Copying training dataset
2025-09-09 14:24:40,498:INFO:Defining folds
2025-09-09 14:24:40,498:INFO:Declaring metric variables
2025-09-09 14:24:40,498:INFO:Importing untrained model
2025-09-09 14:24:40,499:INFO:Declaring custom model
2025-09-09 14:24:40,499:INFO:Naive Bayes Imported successfully
2025-09-09 14:24:40,501:INFO:Cross validation set to False
2025-09-09 14:24:40,501:INFO:Fitting Model
2025-09-09 14:24:40,928:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-09-09 14:24:40,928:INFO:create_model() successfully completed......................................
2025-09-09 14:24:41,059:INFO:_master_model_container: 16
2025-09-09 14:24:41,059:INFO:_display_container: 2
2025-09-09 14:24:41,059:INFO:[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), GaussianNB(priors=None, var_smoothing=1e-09)]
2025-09-09 14:24:41,059:INFO:compare_models() successfully completed......................................
2025-09-09 14:24:41,154:INFO:Initializing finalize_model()
2025-09-09 14:24:41,154:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178D5EFA510>, estimator=[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), GaussianNB(priors=None, var_smoothing=1e-09)], fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-09-09 14:24:41,156:INFO:Finalizing [LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), GaussianNB(priors=None, var_smoothing=1e-09)]
2025-09-09 14:24:41,159:INFO:Initializing create_model()
2025-09-09 14:24:41,160:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178D5EFA510>, estimator=[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), GaussianNB(priors=None, var_smoothing=1e-09)], fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:24:41,160:INFO:Checking exceptions
2025-09-09 14:35:48,430:INFO:Initializing create_model()
2025-09-09 14:35:48,430:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178D5EFA510>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=True, error_score=0.0, kwargs={})
2025-09-09 14:35:48,430:INFO:Checking exceptions
2025-09-09 14:35:48,446:INFO:Importing libraries
2025-09-09 14:35:48,447:INFO:Copying training dataset
2025-09-09 14:35:48,466:INFO:Defining folds
2025-09-09 14:35:48,466:INFO:Declaring metric variables
2025-09-09 14:35:48,475:INFO:Importing untrained model
2025-09-09 14:35:48,484:INFO:Logistic Regression Imported successfully
2025-09-09 14:35:48,500:INFO:Starting cross validation
2025-09-09 14:35:48,511:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 14:35:57,164:INFO:Calculating mean and std
2025-09-09 14:35:57,166:INFO:Creating metrics dataframe
2025-09-09 14:35:57,175:INFO:Finalizing model
2025-09-09 14:35:57,683:INFO:Initializing predict_model()
2025-09-09 14:35:57,683:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178D5EFA510>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['TimeStart', 'TimeStop',
                                             'ProductionDate', 'ApproveDate',
                                             'CreateDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Mpw', 'QtyOutput', 'QtyOutput3'],
                                    trans...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=42,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000178E47771A0>)
2025-09-09 14:35:57,683:INFO:Checking exceptions
2025-09-09 14:35:57,683:INFO:Preloading libraries
2025-09-09 14:35:57,684:INFO:Set up data.
2025-09-09 14:35:57,696:INFO:Set up index.
2025-09-09 14:35:58,099:INFO:Uploading results into container
2025-09-09 14:35:58,100:INFO:Uploading model into container now
2025-09-09 14:35:58,114:INFO:_master_model_container: 17
2025-09-09 14:35:58,114:INFO:_display_container: 3
2025-09-09 14:35:58,115:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-09-09 14:35:58,115:INFO:create_model() successfully completed......................................
2025-09-09 14:36:50,878:INFO:Initializing finalize_model()
2025-09-09 14:36:50,878:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178D5EFA510>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-09-09 14:36:50,879:INFO:Finalizing LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-09-09 14:36:50,886:INFO:Initializing create_model()
2025-09-09 14:36:50,886:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178D5EFA510>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 14:36:50,886:INFO:Checking exceptions
2025-09-09 14:36:50,889:INFO:Importing libraries
2025-09-09 14:36:50,889:INFO:Copying training dataset
2025-09-09 14:36:50,892:INFO:Defining folds
2025-09-09 14:36:50,893:INFO:Declaring metric variables
2025-09-09 14:36:50,893:INFO:Importing untrained model
2025-09-09 14:36:50,893:INFO:Declaring custom model
2025-09-09 14:36:50,894:INFO:Logistic Regression Imported successfully
2025-09-09 14:36:50,898:INFO:Cross validation set to False
2025-09-09 14:36:50,898:INFO:Fitting Model
2025-09-09 14:36:51,590:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['TimeStart', 'TimeStop',
                                             'ProductionDate', 'ApproveDate',
                                             'CreateDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Mpw', 'QtyOutput', 'QtyOutput3'],
                                    trans...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=42,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-09-09 14:36:51,590:INFO:create_model() successfully completed......................................
2025-09-09 14:36:51,742:INFO:_master_model_container: 17
2025-09-09 14:36:51,742:INFO:_display_container: 3
2025-09-09 14:36:51,762:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['TimeStart', 'TimeStop',
                                             'ProductionDate', 'ApproveDate',
                                             'CreateDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Mpw', 'QtyOutput', 'QtyOutput3'],
                                    trans...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=42,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-09-09 14:36:51,763:INFO:finalize_model() successfully completed......................................
2025-09-09 14:38:02,244:INFO:Initializing save_model()
2025-09-09 14:38:02,244:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['TimeStart', 'TimeStop',
                                             'ProductionDate', 'ApproveDate',
                                             'CreateDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Mpw', 'QtyOutput', 'QtyOutput3'],
                                    trans...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=42,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), model_name=Logistic_Regression_Model_RTW, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\SBM_ME~1\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['TimeStart', 'TimeStop',
                                             'ProductionDate', 'ApproveDate',
                                             'CreateDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    inc...
                                                                    'LeaderID',
                                                                    'ProdCode',
                                                                    'Lot',
                                                                    'LNCNo',
                                                                    'SessionID2',
                                                                    'FGCode',
                                                                    'LotNo'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-09-09 14:38:02,244:INFO:Adding model into prep_pipe
2025-09-09 14:38:02,244:WARNING:Only Model saved as it was a pipeline.
2025-09-09 14:38:02,263:INFO:Logistic_Regression_Model_RTW.pkl saved in current working directory
2025-09-09 14:38:02,279:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['TimeStart', 'TimeStop',
                                             'ProductionDate', 'ApproveDate',
                                             'CreateDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Mpw', 'QtyOutput', 'QtyOutput3'],
                                    trans...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=42,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-09-09 14:38:02,279:INFO:save_model() successfully completed......................................
2025-09-09 15:00:20,465:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-09 15:00:20,465:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-09 15:00:20,465:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-09 15:00:20,465:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-09 15:00:24,444:INFO:PyCaret ClassificationExperiment
2025-09-09 15:00:24,445:INFO:Logging name: clf-default-name
2025-09-09 15:00:24,445:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-09-09 15:00:24,445:INFO:version 3.3.2
2025-09-09 15:00:24,445:INFO:Initializing setup()
2025-09-09 15:00:24,445:INFO:self.USI: b58c
2025-09-09 15:00:24,445:INFO:self._variable_keys: {'html_param', 'fold_generator', 'idx', '_ml_usecase', 'gpu_param', 'n_jobs_param', 'pipeline', 'log_plots_param', 'target_param', '_available_plots', 'fix_imbalance', 'X_test', 'logging_param', 'fold_shuffle_param', 'memory', 'USI', 'y_train', 'is_multiclass', 'X', 'fold_groups_param', 'exp_name_log', 'y', 'data', 'y_test', 'X_train', 'exp_id', 'seed', 'gpu_n_jobs_param'}
2025-09-09 15:00:24,445:INFO:Checking environment
2025-09-09 15:00:24,445:INFO:python_version: 3.11.10
2025-09-09 15:00:24,445:INFO:python_build: ('main', 'Oct  3 2024 07:22:26')
2025-09-09 15:00:24,445:INFO:machine: AMD64
2025-09-09 15:00:24,445:INFO:platform: Windows-10-10.0.26100-SP0
2025-09-09 15:00:24,449:INFO:Memory: svmem(total=16837152768, available=1825382400, percent=89.2, used=15011770368, free=1825382400)
2025-09-09 15:00:24,449:INFO:Physical Core: 10
2025-09-09 15:00:24,449:INFO:Logical Core: 12
2025-09-09 15:00:24,449:INFO:Checking libraries
2025-09-09 15:00:24,449:INFO:System:
2025-09-09 15:00:24,449:INFO:    python: 3.11.10 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:26) [MSC v.1929 64 bit (AMD64)]
2025-09-09 15:00:24,449:INFO:executable: c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\python.exe
2025-09-09 15:00:24,449:INFO:   machine: Windows-10-10.0.26100-SP0
2025-09-09 15:00:24,449:INFO:PyCaret required dependencies:
2025-09-09 15:00:24,783:INFO:                 pip: 24.2
2025-09-09 15:00:24,783:INFO:          setuptools: 75.1.0
2025-09-09 15:00:24,783:INFO:             pycaret: 3.3.2
2025-09-09 15:00:24,783:INFO:             IPython: 9.2.0
2025-09-09 15:00:24,783:INFO:          ipywidgets: 8.1.7
2025-09-09 15:00:24,783:INFO:                tqdm: 4.67.1
2025-09-09 15:00:24,783:INFO:               numpy: 1.24.4
2025-09-09 15:00:24,783:INFO:              pandas: 1.5.3
2025-09-09 15:00:24,783:INFO:              jinja2: 3.1.6
2025-09-09 15:00:24,783:INFO:               scipy: 1.11.4
2025-09-09 15:00:24,783:INFO:              joblib: 1.3.2
2025-09-09 15:00:24,783:INFO:             sklearn: 1.4.2
2025-09-09 15:00:24,783:INFO:                pyod: 2.0.5
2025-09-09 15:00:24,783:INFO:            imblearn: 0.13.0
2025-09-09 15:00:24,783:INFO:   category_encoders: 2.7.0
2025-09-09 15:00:24,783:INFO:            lightgbm: 4.6.0
2025-09-09 15:00:24,783:INFO:               numba: 0.61.0
2025-09-09 15:00:24,783:INFO:            requests: 2.32.3
2025-09-09 15:00:24,783:INFO:          matplotlib: 3.7.5
2025-09-09 15:00:24,783:INFO:          scikitplot: 0.3.7
2025-09-09 15:00:24,783:INFO:         yellowbrick: 1.5
2025-09-09 15:00:24,783:INFO:              plotly: 5.24.1
2025-09-09 15:00:24,783:INFO:    plotly-resampler: Not installed
2025-09-09 15:00:24,783:INFO:             kaleido: 0.2.1
2025-09-09 15:00:24,783:INFO:           schemdraw: 0.15
2025-09-09 15:00:24,783:INFO:         statsmodels: 0.14.4
2025-09-09 15:00:24,783:INFO:              sktime: 0.26.0
2025-09-09 15:00:24,783:INFO:               tbats: 1.1.3
2025-09-09 15:00:24,783:INFO:            pmdarima: 2.0.4
2025-09-09 15:00:24,783:INFO:              psutil: 7.0.0
2025-09-09 15:00:24,783:INFO:          markupsafe: 3.0.2
2025-09-09 15:00:24,783:INFO:             pickle5: Not installed
2025-09-09 15:00:24,783:INFO:         cloudpickle: 3.1.1
2025-09-09 15:00:24,783:INFO:         deprecation: 2.1.0
2025-09-09 15:00:24,783:INFO:              xxhash: 3.5.0
2025-09-09 15:00:24,783:INFO:           wurlitzer: Not installed
2025-09-09 15:00:24,783:INFO:PyCaret optional dependencies:
2025-09-09 15:00:27,157:INFO:                shap: 0.44.1
2025-09-09 15:00:27,157:INFO:           interpret: 0.6.11
2025-09-09 15:00:27,157:INFO:                umap: 0.5.7
2025-09-09 15:00:27,157:INFO:     ydata_profiling: 4.16.1
2025-09-09 15:00:27,157:INFO:  explainerdashboard: 0.5.1
2025-09-09 15:00:27,157:INFO:             autoviz: Not installed
2025-09-09 15:00:27,157:INFO:           fairlearn: 0.7.0
2025-09-09 15:00:27,157:INFO:          deepchecks: Not installed
2025-09-09 15:00:27,157:INFO:             xgboost: 3.0.2
2025-09-09 15:00:27,157:INFO:            catboost: 1.2.8
2025-09-09 15:00:27,157:INFO:              kmodes: 0.12.2
2025-09-09 15:00:27,157:INFO:             mlxtend: 0.23.4
2025-09-09 15:00:27,157:INFO:       statsforecast: 1.5.0
2025-09-09 15:00:27,157:INFO:        tune_sklearn: Not installed
2025-09-09 15:00:27,157:INFO:                 ray: Not installed
2025-09-09 15:00:27,157:INFO:            hyperopt: 0.2.7
2025-09-09 15:00:27,157:INFO:              optuna: 4.3.0
2025-09-09 15:00:27,157:INFO:               skopt: 0.10.2
2025-09-09 15:00:27,157:INFO:              mlflow: 3.1.0
2025-09-09 15:00:27,157:INFO:              gradio: 5.33.1
2025-09-09 15:00:27,157:INFO:             fastapi: 0.115.12
2025-09-09 15:00:27,157:INFO:             uvicorn: 0.34.3
2025-09-09 15:00:27,157:INFO:              m2cgen: 0.10.0
2025-09-09 15:00:27,157:INFO:           evidently: 0.4.40
2025-09-09 15:00:27,157:INFO:               fugue: 0.8.7
2025-09-09 15:00:27,157:INFO:           streamlit: 1.45.1
2025-09-09 15:00:27,157:INFO:             prophet: 1.1.7
2025-09-09 15:00:27,157:INFO:None
2025-09-09 15:00:27,157:INFO:Set up data.
2025-09-09 15:00:27,189:INFO:Set up folding strategy.
2025-09-09 15:00:27,189:INFO:Set up train/test split.
2025-09-09 15:00:27,200:INFO:Set up index.
2025-09-09 15:00:27,200:INFO:Assigning column types.
2025-09-09 15:00:27,210:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-09-09 15:00:27,237:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-09 15:00:27,240:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-09 15:00:27,259:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 15:00:27,259:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 15:00:27,299:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-09 15:00:27,299:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-09 15:00:27,323:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 15:00:27,325:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 15:00:27,325:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-09-09 15:00:27,349:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-09 15:00:27,369:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 15:00:27,369:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 15:00:27,389:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-09 15:00:27,409:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 15:00:27,409:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 15:00:27,409:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-09-09 15:00:27,457:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 15:00:27,459:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 15:00:27,500:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 15:00:27,503:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 15:00:27,504:INFO:Preparing preprocessing pipeline...
2025-09-09 15:00:27,505:INFO:Set up date feature engineering.
2025-09-09 15:00:27,505:INFO:Set up simple imputation.
2025-09-09 15:00:27,512:INFO:Set up encoding of ordinal features.
2025-09-09 15:00:27,514:INFO:Set up encoding of categorical features.
2025-09-09 15:00:27,515:INFO:Set up feature normalization.
2025-09-09 15:00:28,046:INFO:Finished creating preprocessing pipeline.
2025-09-09 15:00:28,059:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\SBM_ME~1\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['TimeStart', 'TimeStop',
                                             'ProductionDate', 'ApproveDate',
                                             'CreateDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    inc...
                                                                    'LeaderID',
                                                                    'ProdCode',
                                                                    'Lot',
                                                                    'LNCNo',
                                                                    'SessionID2',
                                                                    'FGCode',
                                                                    'LotNo'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-09-09 15:00:28,059:INFO:Creating final display dataframe.
2025-09-09 15:00:29,119:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target              isNC
2                   Target type            Binary
3           Original data shape       (12216, 31)
4        Transformed data shape      (12216, 161)
5   Transformed train set shape       (8551, 161)
6    Transformed test set shape       (3665, 161)
7              Numeric features                 3
8                 Date features                 5
9          Categorical features                22
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                    Normalize              True
17             Normalize method            zscore
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              b58c
2025-09-09 15:00:29,169:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 15:00:29,169:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 15:00:29,209:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-09 15:00:29,214:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-09 15:00:29,219:INFO:setup() successfully completed in 4.8s...............
2025-09-09 15:00:29,239:INFO:Initializing compare_models()
2025-09-09 15:00:29,239:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021457E96010>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021457E96010>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-09-09 15:00:29,239:INFO:Checking exceptions
2025-09-09 15:00:29,249:INFO:Preparing display monitor
2025-09-09 15:00:29,290:INFO:Initializing Logistic Regression
2025-09-09 15:00:29,290:INFO:Total runtime is 0.0 minutes
2025-09-09 15:00:29,296:INFO:SubProcess create_model() called ==================================
2025-09-09 15:00:29,296:INFO:Initializing create_model()
2025-09-09 15:00:29,296:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021457E96010>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021457EF0550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 15:00:29,296:INFO:Checking exceptions
2025-09-09 15:00:29,296:INFO:Importing libraries
2025-09-09 15:00:29,297:INFO:Copying training dataset
2025-09-09 15:00:29,311:INFO:Defining folds
2025-09-09 15:00:29,311:INFO:Declaring metric variables
2025-09-09 15:00:29,314:INFO:Importing untrained model
2025-09-09 15:00:29,319:INFO:Logistic Regression Imported successfully
2025-09-09 15:00:29,328:INFO:Starting cross validation
2025-09-09 15:00:29,331:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 15:00:37,510:INFO:Calculating mean and std
2025-09-09 15:00:37,511:INFO:Creating metrics dataframe
2025-09-09 15:00:37,516:INFO:Uploading results into container
2025-09-09 15:00:37,517:INFO:Uploading model into container now
2025-09-09 15:00:37,517:INFO:_master_model_container: 1
2025-09-09 15:00:37,518:INFO:_display_container: 2
2025-09-09 15:00:37,518:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-09-09 15:00:37,518:INFO:create_model() successfully completed......................................
2025-09-09 15:00:37,680:INFO:SubProcess create_model() end ==================================
2025-09-09 15:00:37,680:INFO:Creating metrics dataframe
2025-09-09 15:00:37,691:INFO:Initializing K Neighbors Classifier
2025-09-09 15:00:37,691:INFO:Total runtime is 0.14001262585322063 minutes
2025-09-09 15:00:37,699:INFO:SubProcess create_model() called ==================================
2025-09-09 15:00:37,700:INFO:Initializing create_model()
2025-09-09 15:00:37,700:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021457E96010>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021457EF0550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 15:00:37,700:INFO:Checking exceptions
2025-09-09 15:00:37,700:INFO:Importing libraries
2025-09-09 15:00:37,700:INFO:Copying training dataset
2025-09-09 15:00:37,709:INFO:Defining folds
2025-09-09 15:00:37,709:INFO:Declaring metric variables
2025-09-09 15:00:37,715:INFO:Importing untrained model
2025-09-09 15:00:37,719:INFO:K Neighbors Classifier Imported successfully
2025-09-09 15:00:37,731:INFO:Starting cross validation
2025-09-09 15:00:37,731:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 15:00:42,723:INFO:Calculating mean and std
2025-09-09 15:00:42,725:INFO:Creating metrics dataframe
2025-09-09 15:00:42,725:INFO:Uploading results into container
2025-09-09 15:00:42,729:INFO:Uploading model into container now
2025-09-09 15:00:42,729:INFO:_master_model_container: 2
2025-09-09 15:00:42,729:INFO:_display_container: 2
2025-09-09 15:00:42,732:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-09-09 15:00:42,732:INFO:create_model() successfully completed......................................
2025-09-09 15:00:42,850:INFO:SubProcess create_model() end ==================================
2025-09-09 15:00:42,850:INFO:Creating metrics dataframe
2025-09-09 15:00:42,859:INFO:Initializing Naive Bayes
2025-09-09 15:00:42,859:INFO:Total runtime is 0.2261509696642558 minutes
2025-09-09 15:00:42,865:INFO:SubProcess create_model() called ==================================
2025-09-09 15:00:42,866:INFO:Initializing create_model()
2025-09-09 15:00:42,867:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021457E96010>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021457EF0550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 15:00:42,867:INFO:Checking exceptions
2025-09-09 15:00:42,867:INFO:Importing libraries
2025-09-09 15:00:42,867:INFO:Copying training dataset
2025-09-09 15:00:42,869:INFO:Defining folds
2025-09-09 15:00:42,869:INFO:Declaring metric variables
2025-09-09 15:00:42,877:INFO:Importing untrained model
2025-09-09 15:00:42,884:INFO:Naive Bayes Imported successfully
2025-09-09 15:00:42,889:INFO:Starting cross validation
2025-09-09 15:00:42,889:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 15:00:44,605:INFO:Calculating mean and std
2025-09-09 15:00:44,607:INFO:Creating metrics dataframe
2025-09-09 15:00:44,609:INFO:Uploading results into container
2025-09-09 15:00:44,610:INFO:Uploading model into container now
2025-09-09 15:00:44,611:INFO:_master_model_container: 3
2025-09-09 15:00:44,611:INFO:_display_container: 2
2025-09-09 15:00:44,611:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-09-09 15:00:44,611:INFO:create_model() successfully completed......................................
2025-09-09 15:00:44,719:INFO:SubProcess create_model() end ==================================
2025-09-09 15:00:44,719:INFO:Creating metrics dataframe
2025-09-09 15:00:44,732:INFO:Initializing Decision Tree Classifier
2025-09-09 15:00:44,732:INFO:Total runtime is 0.257367475827535 minutes
2025-09-09 15:00:44,739:INFO:SubProcess create_model() called ==================================
2025-09-09 15:00:44,739:INFO:Initializing create_model()
2025-09-09 15:00:44,739:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021457E96010>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021457EF0550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 15:00:44,739:INFO:Checking exceptions
2025-09-09 15:00:44,739:INFO:Importing libraries
2025-09-09 15:00:44,739:INFO:Copying training dataset
2025-09-09 15:00:44,748:INFO:Defining folds
2025-09-09 15:00:44,748:INFO:Declaring metric variables
2025-09-09 15:00:44,749:INFO:Importing untrained model
2025-09-09 15:00:44,749:INFO:Decision Tree Classifier Imported successfully
2025-09-09 15:00:44,771:INFO:Starting cross validation
2025-09-09 15:00:44,779:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 15:00:46,404:INFO:Calculating mean and std
2025-09-09 15:00:46,404:INFO:Creating metrics dataframe
2025-09-09 15:00:46,407:INFO:Uploading results into container
2025-09-09 15:00:46,408:INFO:Uploading model into container now
2025-09-09 15:00:46,408:INFO:_master_model_container: 4
2025-09-09 15:00:46,408:INFO:_display_container: 2
2025-09-09 15:00:46,408:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-09-09 15:00:46,409:INFO:create_model() successfully completed......................................
2025-09-09 15:00:46,525:INFO:SubProcess create_model() end ==================================
2025-09-09 15:00:46,525:INFO:Creating metrics dataframe
2025-09-09 15:00:46,533:INFO:Initializing SVM - Linear Kernel
2025-09-09 15:00:46,533:INFO:Total runtime is 0.287375529607137 minutes
2025-09-09 15:00:46,533:INFO:SubProcess create_model() called ==================================
2025-09-09 15:00:46,533:INFO:Initializing create_model()
2025-09-09 15:00:46,533:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021457E96010>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021457EF0550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 15:00:46,533:INFO:Checking exceptions
2025-09-09 15:00:46,533:INFO:Importing libraries
2025-09-09 15:00:46,533:INFO:Copying training dataset
2025-09-09 15:00:46,544:INFO:Defining folds
2025-09-09 15:00:46,544:INFO:Declaring metric variables
2025-09-09 15:00:46,549:INFO:Importing untrained model
2025-09-09 15:00:46,549:INFO:SVM - Linear Kernel Imported successfully
2025-09-09 15:00:46,565:INFO:Starting cross validation
2025-09-09 15:00:46,569:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 15:00:48,215:INFO:Calculating mean and std
2025-09-09 15:00:48,216:INFO:Creating metrics dataframe
2025-09-09 15:00:48,218:INFO:Uploading results into container
2025-09-09 15:00:48,218:INFO:Uploading model into container now
2025-09-09 15:00:48,219:INFO:_master_model_container: 5
2025-09-09 15:00:48,219:INFO:_display_container: 2
2025-09-09 15:00:48,219:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-09-09 15:00:48,220:INFO:create_model() successfully completed......................................
2025-09-09 15:00:48,330:INFO:SubProcess create_model() end ==================================
2025-09-09 15:00:48,330:INFO:Creating metrics dataframe
2025-09-09 15:00:48,340:INFO:Initializing Ridge Classifier
2025-09-09 15:00:48,340:INFO:Total runtime is 0.3174850622812907 minutes
2025-09-09 15:00:48,350:INFO:SubProcess create_model() called ==================================
2025-09-09 15:00:48,350:INFO:Initializing create_model()
2025-09-09 15:00:48,350:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021457E96010>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021457EF0550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 15:00:48,350:INFO:Checking exceptions
2025-09-09 15:00:48,350:INFO:Importing libraries
2025-09-09 15:00:48,350:INFO:Copying training dataset
2025-09-09 15:00:48,358:INFO:Defining folds
2025-09-09 15:00:48,358:INFO:Declaring metric variables
2025-09-09 15:00:48,364:INFO:Importing untrained model
2025-09-09 15:00:48,369:INFO:Ridge Classifier Imported successfully
2025-09-09 15:00:48,378:INFO:Starting cross validation
2025-09-09 15:00:48,382:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 15:00:50,071:INFO:Calculating mean and std
2025-09-09 15:00:50,072:INFO:Creating metrics dataframe
2025-09-09 15:00:50,074:INFO:Uploading results into container
2025-09-09 15:00:50,075:INFO:Uploading model into container now
2025-09-09 15:00:50,075:INFO:_master_model_container: 6
2025-09-09 15:00:50,075:INFO:_display_container: 2
2025-09-09 15:00:50,076:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-09-09 15:00:50,076:INFO:create_model() successfully completed......................................
2025-09-09 15:00:50,189:INFO:SubProcess create_model() end ==================================
2025-09-09 15:00:50,189:INFO:Creating metrics dataframe
2025-09-09 15:00:50,189:INFO:Initializing Random Forest Classifier
2025-09-09 15:00:50,189:INFO:Total runtime is 0.3483181118965149 minutes
2025-09-09 15:00:50,200:INFO:SubProcess create_model() called ==================================
2025-09-09 15:00:50,200:INFO:Initializing create_model()
2025-09-09 15:00:50,200:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021457E96010>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021457EF0550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 15:00:50,200:INFO:Checking exceptions
2025-09-09 15:00:50,200:INFO:Importing libraries
2025-09-09 15:00:50,200:INFO:Copying training dataset
2025-09-09 15:00:50,209:INFO:Defining folds
2025-09-09 15:00:50,209:INFO:Declaring metric variables
2025-09-09 15:00:50,216:INFO:Importing untrained model
2025-09-09 15:00:50,220:INFO:Random Forest Classifier Imported successfully
2025-09-09 15:00:50,235:INFO:Starting cross validation
2025-09-09 15:00:50,240:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 15:00:52,538:INFO:Calculating mean and std
2025-09-09 15:00:52,539:INFO:Creating metrics dataframe
2025-09-09 15:00:52,539:INFO:Uploading results into container
2025-09-09 15:00:52,539:INFO:Uploading model into container now
2025-09-09 15:00:52,539:INFO:_master_model_container: 7
2025-09-09 15:00:52,539:INFO:_display_container: 2
2025-09-09 15:00:52,539:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-09-09 15:00:52,539:INFO:create_model() successfully completed......................................
2025-09-09 15:00:52,662:INFO:SubProcess create_model() end ==================================
2025-09-09 15:00:52,662:INFO:Creating metrics dataframe
2025-09-09 15:00:52,669:INFO:Initializing Quadratic Discriminant Analysis
2025-09-09 15:00:52,669:INFO:Total runtime is 0.3896493633588155 minutes
2025-09-09 15:00:52,669:INFO:SubProcess create_model() called ==================================
2025-09-09 15:00:52,669:INFO:Initializing create_model()
2025-09-09 15:00:52,669:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021457E96010>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021457EF0550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 15:00:52,669:INFO:Checking exceptions
2025-09-09 15:00:52,669:INFO:Importing libraries
2025-09-09 15:00:52,669:INFO:Copying training dataset
2025-09-09 15:00:52,685:INFO:Defining folds
2025-09-09 15:00:52,685:INFO:Declaring metric variables
2025-09-09 15:00:52,689:INFO:Importing untrained model
2025-09-09 15:00:52,694:INFO:Quadratic Discriminant Analysis Imported successfully
2025-09-09 15:00:52,704:INFO:Starting cross validation
2025-09-09 15:00:52,707:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 15:00:54,627:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 15:00:54,687:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 15:00:54,699:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 15:00:54,742:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 15:00:54,752:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 15:00:54,758:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 15:00:54,772:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 15:00:54,779:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 15:00:54,870:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-09 15:00:55,309:INFO:Calculating mean and std
2025-09-09 15:00:55,309:INFO:Creating metrics dataframe
2025-09-09 15:00:55,309:INFO:Uploading results into container
2025-09-09 15:00:55,309:INFO:Uploading model into container now
2025-09-09 15:00:55,309:INFO:_master_model_container: 8
2025-09-09 15:00:55,309:INFO:_display_container: 2
2025-09-09 15:00:55,309:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-09-09 15:00:55,309:INFO:create_model() successfully completed......................................
2025-09-09 15:00:55,435:INFO:SubProcess create_model() end ==================================
2025-09-09 15:00:55,435:INFO:Creating metrics dataframe
2025-09-09 15:00:55,442:INFO:Initializing Ada Boost Classifier
2025-09-09 15:00:55,443:INFO:Total runtime is 0.4358786344528198 minutes
2025-09-09 15:00:55,447:INFO:SubProcess create_model() called ==================================
2025-09-09 15:00:55,448:INFO:Initializing create_model()
2025-09-09 15:00:55,448:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021457E96010>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021457EF0550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 15:00:55,448:INFO:Checking exceptions
2025-09-09 15:00:55,448:INFO:Importing libraries
2025-09-09 15:00:55,448:INFO:Copying training dataset
2025-09-09 15:00:55,457:INFO:Defining folds
2025-09-09 15:00:55,457:INFO:Declaring metric variables
2025-09-09 15:00:55,463:INFO:Importing untrained model
2025-09-09 15:00:55,465:INFO:Ada Boost Classifier Imported successfully
2025-09-09 15:00:55,472:INFO:Starting cross validation
2025-09-09 15:00:55,481:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 15:00:56,791:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 15:00:56,807:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 15:00:56,851:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 15:00:56,914:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 15:00:56,938:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 15:00:56,998:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 15:00:57,016:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 15:00:57,114:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 15:00:57,130:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 15:00:57,182:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-09 15:00:57,435:INFO:Calculating mean and std
2025-09-09 15:00:57,435:INFO:Creating metrics dataframe
2025-09-09 15:00:57,442:INFO:Uploading results into container
2025-09-09 15:00:57,442:INFO:Uploading model into container now
2025-09-09 15:00:57,442:INFO:_master_model_container: 9
2025-09-09 15:00:57,442:INFO:_display_container: 2
2025-09-09 15:00:57,442:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-09-09 15:00:57,442:INFO:create_model() successfully completed......................................
2025-09-09 15:00:57,582:INFO:SubProcess create_model() end ==================================
2025-09-09 15:00:57,582:INFO:Creating metrics dataframe
2025-09-09 15:00:57,590:INFO:Initializing Gradient Boosting Classifier
2025-09-09 15:00:57,590:INFO:Total runtime is 0.4716546972592672 minutes
2025-09-09 15:00:57,590:INFO:SubProcess create_model() called ==================================
2025-09-09 15:00:57,590:INFO:Initializing create_model()
2025-09-09 15:00:57,590:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021457E96010>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021457EF0550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 15:00:57,590:INFO:Checking exceptions
2025-09-09 15:00:57,590:INFO:Importing libraries
2025-09-09 15:00:57,590:INFO:Copying training dataset
2025-09-09 15:00:57,599:INFO:Defining folds
2025-09-09 15:00:57,599:INFO:Declaring metric variables
2025-09-09 15:00:57,609:INFO:Importing untrained model
2025-09-09 15:00:57,614:INFO:Gradient Boosting Classifier Imported successfully
2025-09-09 15:00:57,622:INFO:Starting cross validation
2025-09-09 15:00:57,622:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 15:01:01,107:INFO:Calculating mean and std
2025-09-09 15:01:01,108:INFO:Creating metrics dataframe
2025-09-09 15:01:01,111:INFO:Uploading results into container
2025-09-09 15:01:01,111:INFO:Uploading model into container now
2025-09-09 15:01:01,111:INFO:_master_model_container: 10
2025-09-09 15:01:01,111:INFO:_display_container: 2
2025-09-09 15:01:01,111:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-09-09 15:01:01,111:INFO:create_model() successfully completed......................................
2025-09-09 15:01:01,245:INFO:SubProcess create_model() end ==================================
2025-09-09 15:01:01,245:INFO:Creating metrics dataframe
2025-09-09 15:01:01,251:INFO:Initializing Linear Discriminant Analysis
2025-09-09 15:01:01,251:INFO:Total runtime is 0.5326699336369832 minutes
2025-09-09 15:01:01,251:INFO:SubProcess create_model() called ==================================
2025-09-09 15:01:01,259:INFO:Initializing create_model()
2025-09-09 15:01:01,259:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021457E96010>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021457EF0550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 15:01:01,259:INFO:Checking exceptions
2025-09-09 15:01:01,259:INFO:Importing libraries
2025-09-09 15:01:01,259:INFO:Copying training dataset
2025-09-09 15:01:01,272:INFO:Defining folds
2025-09-09 15:01:01,272:INFO:Declaring metric variables
2025-09-09 15:01:01,277:INFO:Importing untrained model
2025-09-09 15:01:01,285:INFO:Linear Discriminant Analysis Imported successfully
2025-09-09 15:01:01,298:INFO:Starting cross validation
2025-09-09 15:01:01,302:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 15:01:04,374:INFO:Calculating mean and std
2025-09-09 15:01:04,374:INFO:Creating metrics dataframe
2025-09-09 15:01:04,378:INFO:Uploading results into container
2025-09-09 15:01:04,379:INFO:Uploading model into container now
2025-09-09 15:01:04,380:INFO:_master_model_container: 11
2025-09-09 15:01:04,380:INFO:_display_container: 2
2025-09-09 15:01:04,381:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-09-09 15:01:04,381:INFO:create_model() successfully completed......................................
2025-09-09 15:01:04,507:INFO:SubProcess create_model() end ==================================
2025-09-09 15:01:04,508:INFO:Creating metrics dataframe
2025-09-09 15:01:04,516:INFO:Initializing Extra Trees Classifier
2025-09-09 15:01:04,516:INFO:Total runtime is 0.5871015350023905 minutes
2025-09-09 15:01:04,521:INFO:SubProcess create_model() called ==================================
2025-09-09 15:01:04,522:INFO:Initializing create_model()
2025-09-09 15:01:04,522:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021457E96010>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021457EF0550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 15:01:04,522:INFO:Checking exceptions
2025-09-09 15:01:04,522:INFO:Importing libraries
2025-09-09 15:01:04,522:INFO:Copying training dataset
2025-09-09 15:01:04,531:INFO:Defining folds
2025-09-09 15:01:04,531:INFO:Declaring metric variables
2025-09-09 15:01:04,537:INFO:Importing untrained model
2025-09-09 15:01:04,544:INFO:Extra Trees Classifier Imported successfully
2025-09-09 15:01:04,557:INFO:Starting cross validation
2025-09-09 15:01:04,562:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 15:01:06,809:INFO:Calculating mean and std
2025-09-09 15:01:06,809:INFO:Creating metrics dataframe
2025-09-09 15:01:06,812:INFO:Uploading results into container
2025-09-09 15:01:06,814:INFO:Uploading model into container now
2025-09-09 15:01:06,816:INFO:_master_model_container: 12
2025-09-09 15:01:06,816:INFO:_display_container: 2
2025-09-09 15:01:06,816:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-09-09 15:01:06,817:INFO:create_model() successfully completed......................................
2025-09-09 15:01:06,948:INFO:SubProcess create_model() end ==================================
2025-09-09 15:01:06,948:INFO:Creating metrics dataframe
2025-09-09 15:01:06,949:INFO:Initializing Extreme Gradient Boosting
2025-09-09 15:01:06,949:INFO:Total runtime is 0.6276483496030171 minutes
2025-09-09 15:01:06,964:INFO:SubProcess create_model() called ==================================
2025-09-09 15:01:06,965:INFO:Initializing create_model()
2025-09-09 15:01:06,965:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021457E96010>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021457EF0550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 15:01:06,965:INFO:Checking exceptions
2025-09-09 15:01:06,965:INFO:Importing libraries
2025-09-09 15:01:06,965:INFO:Copying training dataset
2025-09-09 15:01:06,970:INFO:Defining folds
2025-09-09 15:01:06,970:INFO:Declaring metric variables
2025-09-09 15:01:06,981:INFO:Importing untrained model
2025-09-09 15:01:06,988:INFO:Extreme Gradient Boosting Imported successfully
2025-09-09 15:01:07,005:INFO:Starting cross validation
2025-09-09 15:01:07,009:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 15:01:09,114:INFO:Calculating mean and std
2025-09-09 15:01:09,115:INFO:Creating metrics dataframe
2025-09-09 15:01:09,119:INFO:Uploading results into container
2025-09-09 15:01:09,120:INFO:Uploading model into container now
2025-09-09 15:01:09,121:INFO:_master_model_container: 13
2025-09-09 15:01:09,121:INFO:_display_container: 2
2025-09-09 15:01:09,122:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-09-09 15:01:09,123:INFO:create_model() successfully completed......................................
2025-09-09 15:01:09,262:INFO:SubProcess create_model() end ==================================
2025-09-09 15:01:09,262:INFO:Creating metrics dataframe
2025-09-09 15:01:09,270:INFO:Initializing Light Gradient Boosting Machine
2025-09-09 15:01:09,270:INFO:Total runtime is 0.6663248022397358 minutes
2025-09-09 15:01:09,270:INFO:SubProcess create_model() called ==================================
2025-09-09 15:01:09,270:INFO:Initializing create_model()
2025-09-09 15:01:09,270:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021457E96010>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021457EF0550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 15:01:09,270:INFO:Checking exceptions
2025-09-09 15:01:09,270:INFO:Importing libraries
2025-09-09 15:01:09,270:INFO:Copying training dataset
2025-09-09 15:01:09,286:INFO:Defining folds
2025-09-09 15:01:09,286:INFO:Declaring metric variables
2025-09-09 15:01:09,291:INFO:Importing untrained model
2025-09-09 15:01:09,298:INFO:Light Gradient Boosting Machine Imported successfully
2025-09-09 15:01:09,311:INFO:Starting cross validation
2025-09-09 15:01:09,316:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 15:01:11,737:INFO:Calculating mean and std
2025-09-09 15:01:11,737:INFO:Creating metrics dataframe
2025-09-09 15:01:11,741:INFO:Uploading results into container
2025-09-09 15:01:11,741:INFO:Uploading model into container now
2025-09-09 15:01:11,741:INFO:_master_model_container: 14
2025-09-09 15:01:11,741:INFO:_display_container: 2
2025-09-09 15:01:11,743:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-09-09 15:01:11,743:INFO:create_model() successfully completed......................................
2025-09-09 15:01:11,901:INFO:SubProcess create_model() end ==================================
2025-09-09 15:01:11,901:INFO:Creating metrics dataframe
2025-09-09 15:01:11,909:INFO:Initializing CatBoost Classifier
2025-09-09 15:01:11,909:INFO:Total runtime is 0.7103140473365782 minutes
2025-09-09 15:01:11,913:INFO:SubProcess create_model() called ==================================
2025-09-09 15:01:11,913:INFO:Initializing create_model()
2025-09-09 15:01:11,913:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021457E96010>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021457EF0550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 15:01:11,914:INFO:Checking exceptions
2025-09-09 15:01:11,914:INFO:Importing libraries
2025-09-09 15:01:11,914:INFO:Copying training dataset
2025-09-09 15:01:11,922:INFO:Defining folds
2025-09-09 15:01:11,922:INFO:Declaring metric variables
2025-09-09 15:01:11,926:INFO:Importing untrained model
2025-09-09 15:01:11,932:INFO:CatBoost Classifier Imported successfully
2025-09-09 15:01:11,948:INFO:Starting cross validation
2025-09-09 15:01:11,956:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 15:01:30,841:INFO:Calculating mean and std
2025-09-09 15:01:30,841:INFO:Creating metrics dataframe
2025-09-09 15:01:30,845:INFO:Uploading results into container
2025-09-09 15:01:30,845:INFO:Uploading model into container now
2025-09-09 15:01:30,845:INFO:_master_model_container: 15
2025-09-09 15:01:30,845:INFO:_display_container: 2
2025-09-09 15:01:30,845:INFO:<catboost.core.CatBoostClassifier object at 0x0000021462D8F810>
2025-09-09 15:01:30,845:INFO:create_model() successfully completed......................................
2025-09-09 15:01:30,988:INFO:SubProcess create_model() end ==================================
2025-09-09 15:01:30,989:INFO:Creating metrics dataframe
2025-09-09 15:01:30,998:INFO:Initializing Dummy Classifier
2025-09-09 15:01:30,999:INFO:Total runtime is 1.0284718513488769 minutes
2025-09-09 15:01:31,002:INFO:SubProcess create_model() called ==================================
2025-09-09 15:01:31,003:INFO:Initializing create_model()
2025-09-09 15:01:31,003:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021457E96010>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021457EF0550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 15:01:31,003:INFO:Checking exceptions
2025-09-09 15:01:31,003:INFO:Importing libraries
2025-09-09 15:01:31,003:INFO:Copying training dataset
2025-09-09 15:01:31,011:INFO:Defining folds
2025-09-09 15:01:31,011:INFO:Declaring metric variables
2025-09-09 15:01:31,017:INFO:Importing untrained model
2025-09-09 15:01:31,025:INFO:Dummy Classifier Imported successfully
2025-09-09 15:01:31,040:INFO:Starting cross validation
2025-09-09 15:01:31,045:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 15:01:32,642:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 15:01:32,660:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 15:01:32,750:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 15:01:32,774:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 15:01:32,840:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 15:01:32,874:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 15:01:32,888:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 15:01:32,910:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 15:01:32,914:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 15:01:32,914:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-09 15:01:32,930:INFO:Calculating mean and std
2025-09-09 15:01:32,932:INFO:Creating metrics dataframe
2025-09-09 15:01:32,934:INFO:Uploading results into container
2025-09-09 15:01:32,935:INFO:Uploading model into container now
2025-09-09 15:01:32,935:INFO:_master_model_container: 16
2025-09-09 15:01:32,935:INFO:_display_container: 2
2025-09-09 15:01:32,935:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-09-09 15:01:32,936:INFO:create_model() successfully completed......................................
2025-09-09 15:01:33,096:INFO:SubProcess create_model() end ==================================
2025-09-09 15:01:33,096:INFO:Creating metrics dataframe
2025-09-09 15:01:33,120:INFO:Initializing create_model()
2025-09-09 15:01:33,120:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021457E96010>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 15:01:33,120:INFO:Checking exceptions
2025-09-09 15:01:33,120:INFO:Importing libraries
2025-09-09 15:01:33,120:INFO:Copying training dataset
2025-09-09 15:01:33,140:INFO:Defining folds
2025-09-09 15:01:33,140:INFO:Declaring metric variables
2025-09-09 15:01:33,140:INFO:Importing untrained model
2025-09-09 15:01:33,140:INFO:Declaring custom model
2025-09-09 15:01:33,140:INFO:Logistic Regression Imported successfully
2025-09-09 15:01:33,140:INFO:Cross validation set to False
2025-09-09 15:01:33,140:INFO:Fitting Model
2025-09-09 15:01:33,846:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-09-09 15:01:33,846:INFO:create_model() successfully completed......................................
2025-09-09 15:01:34,017:INFO:Initializing create_model()
2025-09-09 15:01:34,018:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021457E96010>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 15:01:34,018:INFO:Checking exceptions
2025-09-09 15:01:34,021:INFO:Importing libraries
2025-09-09 15:01:34,021:INFO:Copying training dataset
2025-09-09 15:01:34,029:INFO:Defining folds
2025-09-09 15:01:34,029:INFO:Declaring metric variables
2025-09-09 15:01:34,029:INFO:Importing untrained model
2025-09-09 15:01:34,030:INFO:Declaring custom model
2025-09-09 15:01:34,030:INFO:K Neighbors Classifier Imported successfully
2025-09-09 15:01:34,032:INFO:Cross validation set to False
2025-09-09 15:01:34,033:INFO:Fitting Model
2025-09-09 15:01:34,475:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-09-09 15:01:34,475:INFO:create_model() successfully completed......................................
2025-09-09 15:01:34,658:INFO:Initializing create_model()
2025-09-09 15:01:34,658:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021457E96010>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 15:01:34,658:INFO:Checking exceptions
2025-09-09 15:01:34,661:INFO:Importing libraries
2025-09-09 15:01:34,661:INFO:Copying training dataset
2025-09-09 15:01:34,671:INFO:Defining folds
2025-09-09 15:01:34,671:INFO:Declaring metric variables
2025-09-09 15:01:34,671:INFO:Importing untrained model
2025-09-09 15:01:34,671:INFO:Declaring custom model
2025-09-09 15:01:34,671:INFO:Naive Bayes Imported successfully
2025-09-09 15:01:34,673:INFO:Cross validation set to False
2025-09-09 15:01:34,673:INFO:Fitting Model
2025-09-09 15:01:35,155:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-09-09 15:01:35,155:INFO:create_model() successfully completed......................................
2025-09-09 15:01:35,290:INFO:_master_model_container: 16
2025-09-09 15:01:35,290:INFO:_display_container: 2
2025-09-09 15:01:35,290:INFO:[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), GaussianNB(priors=None, var_smoothing=1e-09)]
2025-09-09 15:01:35,290:INFO:compare_models() successfully completed......................................
2025-09-09 15:01:35,354:INFO:Initializing create_model()
2025-09-09 15:01:35,354:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021457E96010>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=True, error_score=0.0, kwargs={})
2025-09-09 15:01:35,355:INFO:Checking exceptions
2025-09-09 15:01:35,371:INFO:Importing libraries
2025-09-09 15:01:35,371:INFO:Copying training dataset
2025-09-09 15:01:35,384:INFO:Defining folds
2025-09-09 15:01:35,384:INFO:Declaring metric variables
2025-09-09 15:01:35,388:INFO:Importing untrained model
2025-09-09 15:01:35,396:INFO:Logistic Regression Imported successfully
2025-09-09 15:01:35,407:INFO:Starting cross validation
2025-09-09 15:01:35,412:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-09 15:01:38,004:INFO:Calculating mean and std
2025-09-09 15:01:38,006:INFO:Creating metrics dataframe
2025-09-09 15:01:38,017:INFO:Finalizing model
2025-09-09 15:01:38,470:INFO:Initializing predict_model()
2025-09-09 15:01:38,470:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021457E96010>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['TimeStart', 'TimeStop',
                                             'ProductionDate', 'ApproveDate',
                                             'CreateDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Mpw', 'QtyOutput', 'QtyOutput3'],
                                    trans...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=42,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021462AF65C0>)
2025-09-09 15:01:38,470:INFO:Checking exceptions
2025-09-09 15:01:38,470:INFO:Preloading libraries
2025-09-09 15:01:38,477:INFO:Set up data.
2025-09-09 15:01:38,488:INFO:Set up index.
2025-09-09 15:01:38,826:INFO:Uploading results into container
2025-09-09 15:01:38,828:INFO:Uploading model into container now
2025-09-09 15:01:38,840:INFO:_master_model_container: 17
2025-09-09 15:01:38,841:INFO:_display_container: 3
2025-09-09 15:01:38,841:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-09-09 15:01:38,841:INFO:create_model() successfully completed......................................
2025-09-09 15:01:39,000:INFO:Initializing finalize_model()
2025-09-09 15:01:39,000:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021457E96010>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-09-09 15:01:39,001:INFO:Finalizing LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-09-09 15:01:39,009:INFO:Initializing create_model()
2025-09-09 15:01:39,009:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021457E96010>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-09-09 15:01:39,009:INFO:Checking exceptions
2025-09-09 15:01:39,010:INFO:Importing libraries
2025-09-09 15:01:39,010:INFO:Copying training dataset
2025-09-09 15:01:39,012:INFO:Defining folds
2025-09-09 15:01:39,013:INFO:Declaring metric variables
2025-09-09 15:01:39,013:INFO:Importing untrained model
2025-09-09 15:01:39,014:INFO:Declaring custom model
2025-09-09 15:01:39,014:INFO:Logistic Regression Imported successfully
2025-09-09 15:01:39,020:INFO:Cross validation set to False
2025-09-09 15:01:39,021:INFO:Fitting Model
2025-09-09 15:01:39,629:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['TimeStart', 'TimeStop',
                                             'ProductionDate', 'ApproveDate',
                                             'CreateDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Mpw', 'QtyOutput', 'QtyOutput3'],
                                    trans...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=42,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-09-09 15:01:39,629:INFO:create_model() successfully completed......................................
2025-09-09 15:01:39,730:INFO:_master_model_container: 17
2025-09-09 15:01:39,730:INFO:_display_container: 3
2025-09-09 15:01:39,750:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['TimeStart', 'TimeStop',
                                             'ProductionDate', 'ApproveDate',
                                             'CreateDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Mpw', 'QtyOutput', 'QtyOutput3'],
                                    trans...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=42,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-09-09 15:01:39,750:INFO:finalize_model() successfully completed......................................
2025-09-09 15:01:39,921:INFO:Initializing save_model()
2025-09-09 15:01:39,921:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['TimeStart', 'TimeStop',
                                             'ProductionDate', 'ApproveDate',
                                             'CreateDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Mpw', 'QtyOutput', 'QtyOutput3'],
                                    trans...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=42,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), model_name=Logistic_Regression_Model_RTW, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\SBM_ME~1\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['TimeStart', 'TimeStop',
                                             'ProductionDate', 'ApproveDate',
                                             'CreateDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    inc...
                                                                    'LeaderID',
                                                                    'ProdCode',
                                                                    'Lot',
                                                                    'LNCNo',
                                                                    'SessionID2',
                                                                    'FGCode',
                                                                    'LotNo'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-09-09 15:01:39,921:INFO:Adding model into prep_pipe
2025-09-09 15:01:39,922:WARNING:Only Model saved as it was a pipeline.
2025-09-09 15:01:39,940:INFO:Logistic_Regression_Model_RTW.pkl saved in current working directory
2025-09-09 15:01:39,960:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['TimeStart', 'TimeStop',
                                             'ProductionDate', 'ApproveDate',
                                             'CreateDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Mpw', 'QtyOutput', 'QtyOutput3'],
                                    trans...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=42,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-09-09 15:01:39,960:INFO:save_model() successfully completed......................................
2025-09-10 10:13:51,354:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 10:13:51,359:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 10:13:51,359:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 10:13:51,359:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 10:13:55,618:INFO:PyCaret ClassificationExperiment
2025-09-10 10:13:55,619:INFO:Logging name: clf-default-name
2025-09-10 10:13:55,619:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-09-10 10:13:55,619:INFO:version 3.3.2
2025-09-10 10:13:55,619:INFO:Initializing setup()
2025-09-10 10:13:55,619:INFO:self.USI: cbba
2025-09-10 10:13:55,619:INFO:self._variable_keys: {'seed', 'gpu_param', 'n_jobs_param', 'gpu_n_jobs_param', 'fold_generator', 'html_param', 'pipeline', '_available_plots', 'X_train', 'logging_param', 'data', 'X_test', '_ml_usecase', 'USI', 'log_plots_param', 'fold_shuffle_param', 'fix_imbalance', 'fold_groups_param', 'y_train', 'memory', 'y', 'is_multiclass', 'exp_id', 'target_param', 'X', 'y_test', 'idx', 'exp_name_log'}
2025-09-10 10:13:55,619:INFO:Checking environment
2025-09-10 10:13:55,619:INFO:python_version: 3.11.10
2025-09-10 10:13:55,619:INFO:python_build: ('main', 'Oct  3 2024 07:22:26')
2025-09-10 10:13:55,619:INFO:machine: AMD64
2025-09-10 10:13:55,619:INFO:platform: Windows-10-10.0.26100-SP0
2025-09-10 10:13:55,624:INFO:Memory: svmem(total=16837152768, available=2248003584, percent=86.6, used=14589149184, free=2248003584)
2025-09-10 10:13:55,624:INFO:Physical Core: 10
2025-09-10 10:13:55,624:INFO:Logical Core: 12
2025-09-10 10:13:55,624:INFO:Checking libraries
2025-09-10 10:13:55,624:INFO:System:
2025-09-10 10:13:55,624:INFO:    python: 3.11.10 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:26) [MSC v.1929 64 bit (AMD64)]
2025-09-10 10:13:55,624:INFO:executable: c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\python.exe
2025-09-10 10:13:55,624:INFO:   machine: Windows-10-10.0.26100-SP0
2025-09-10 10:13:55,624:INFO:PyCaret required dependencies:
2025-09-10 10:13:55,966:INFO:                 pip: 24.2
2025-09-10 10:13:55,966:INFO:          setuptools: 75.1.0
2025-09-10 10:13:55,966:INFO:             pycaret: 3.3.2
2025-09-10 10:13:55,966:INFO:             IPython: 9.2.0
2025-09-10 10:13:55,966:INFO:          ipywidgets: 8.1.7
2025-09-10 10:13:55,966:INFO:                tqdm: 4.67.1
2025-09-10 10:13:55,966:INFO:               numpy: 1.24.4
2025-09-10 10:13:55,966:INFO:              pandas: 1.5.3
2025-09-10 10:13:55,967:INFO:              jinja2: 3.1.6
2025-09-10 10:13:55,967:INFO:               scipy: 1.11.4
2025-09-10 10:13:55,967:INFO:              joblib: 1.3.2
2025-09-10 10:13:55,967:INFO:             sklearn: 1.4.2
2025-09-10 10:13:55,967:INFO:                pyod: 2.0.5
2025-09-10 10:13:55,967:INFO:            imblearn: 0.13.0
2025-09-10 10:13:55,967:INFO:   category_encoders: 2.7.0
2025-09-10 10:13:55,967:INFO:            lightgbm: 4.6.0
2025-09-10 10:13:55,967:INFO:               numba: 0.61.0
2025-09-10 10:13:55,967:INFO:            requests: 2.32.3
2025-09-10 10:13:55,967:INFO:          matplotlib: 3.7.5
2025-09-10 10:13:55,967:INFO:          scikitplot: 0.3.7
2025-09-10 10:13:55,967:INFO:         yellowbrick: 1.5
2025-09-10 10:13:55,967:INFO:              plotly: 5.24.1
2025-09-10 10:13:55,967:INFO:    plotly-resampler: Not installed
2025-09-10 10:13:55,967:INFO:             kaleido: 0.2.1
2025-09-10 10:13:55,967:INFO:           schemdraw: 0.15
2025-09-10 10:13:55,967:INFO:         statsmodels: 0.14.4
2025-09-10 10:13:55,967:INFO:              sktime: 0.26.0
2025-09-10 10:13:55,967:INFO:               tbats: 1.1.3
2025-09-10 10:13:55,967:INFO:            pmdarima: 2.0.4
2025-09-10 10:13:55,967:INFO:              psutil: 7.0.0
2025-09-10 10:13:55,967:INFO:          markupsafe: 3.0.2
2025-09-10 10:13:55,967:INFO:             pickle5: Not installed
2025-09-10 10:13:55,967:INFO:         cloudpickle: 3.1.1
2025-09-10 10:13:55,967:INFO:         deprecation: 2.1.0
2025-09-10 10:13:55,967:INFO:              xxhash: 3.5.0
2025-09-10 10:13:55,967:INFO:           wurlitzer: Not installed
2025-09-10 10:13:55,967:INFO:PyCaret optional dependencies:
2025-09-10 10:13:59,297:INFO:                shap: 0.44.1
2025-09-10 10:13:59,297:INFO:           interpret: 0.6.11
2025-09-10 10:13:59,297:INFO:                umap: 0.5.7
2025-09-10 10:13:59,297:INFO:     ydata_profiling: 4.16.1
2025-09-10 10:13:59,297:INFO:  explainerdashboard: 0.5.1
2025-09-10 10:13:59,297:INFO:             autoviz: Not installed
2025-09-10 10:13:59,297:INFO:           fairlearn: 0.7.0
2025-09-10 10:13:59,297:INFO:          deepchecks: Not installed
2025-09-10 10:13:59,297:INFO:             xgboost: 3.0.2
2025-09-10 10:13:59,297:INFO:            catboost: 1.2.8
2025-09-10 10:13:59,297:INFO:              kmodes: 0.12.2
2025-09-10 10:13:59,297:INFO:             mlxtend: 0.23.4
2025-09-10 10:13:59,297:INFO:       statsforecast: 1.5.0
2025-09-10 10:13:59,297:INFO:        tune_sklearn: Not installed
2025-09-10 10:13:59,297:INFO:                 ray: Not installed
2025-09-10 10:13:59,297:INFO:            hyperopt: 0.2.7
2025-09-10 10:13:59,297:INFO:              optuna: 4.3.0
2025-09-10 10:13:59,297:INFO:               skopt: 0.10.2
2025-09-10 10:13:59,297:INFO:              mlflow: 3.1.0
2025-09-10 10:13:59,297:INFO:              gradio: 5.33.1
2025-09-10 10:13:59,297:INFO:             fastapi: 0.115.12
2025-09-10 10:13:59,298:INFO:             uvicorn: 0.34.3
2025-09-10 10:13:59,298:INFO:              m2cgen: 0.10.0
2025-09-10 10:13:59,298:INFO:           evidently: 0.4.40
2025-09-10 10:13:59,298:INFO:               fugue: 0.8.7
2025-09-10 10:13:59,298:INFO:           streamlit: 1.45.1
2025-09-10 10:13:59,298:INFO:             prophet: 1.1.7
2025-09-10 10:13:59,298:INFO:None
2025-09-10 10:13:59,298:INFO:Set up data.
2025-09-10 10:13:59,328:INFO:Set up folding strategy.
2025-09-10 10:13:59,328:INFO:Set up train/test split.
2025-09-10 10:13:59,343:INFO:Set up index.
2025-09-10 10:13:59,344:INFO:Assigning column types.
2025-09-10 10:13:59,348:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-09-10 10:13:59,371:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 10:13:59,376:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-10 10:13:59,405:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 10:13:59,407:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 10:13:59,555:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 10:13:59,555:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-10 10:13:59,572:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 10:13:59,574:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 10:13:59,574:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-09-10 10:13:59,601:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-10 10:13:59,618:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 10:13:59,620:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 10:13:59,649:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-10 10:13:59,666:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 10:13:59,667:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 10:13:59,668:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-09-10 10:13:59,708:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 10:13:59,711:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 10:13:59,752:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 10:13:59,754:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 10:13:59,760:INFO:Preparing preprocessing pipeline...
2025-09-10 10:13:59,762:INFO:Set up date feature engineering.
2025-09-10 10:13:59,762:INFO:Set up simple imputation.
2025-09-10 10:13:59,770:INFO:Set up encoding of ordinal features.
2025-09-10 10:13:59,772:INFO:Set up encoding of categorical features.
2025-09-10 10:13:59,773:INFO:Set up feature normalization.
2025-09-10 10:14:00,321:INFO:Finished creating preprocessing pipeline.
2025-09-10 10:14:00,338:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\SBM_ME~1\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['TimeStart', 'TimeStop',
                                             'ProductionDate', 'ApproveDate',
                                             'CreateDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    inc...
                                                                    'LeaderID',
                                                                    'ProdCode',
                                                                    'Lot',
                                                                    'LNCNo',
                                                                    'SessionID2',
                                                                    'FGCode',
                                                                    'LotNo'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-09-10 10:14:00,338:INFO:Creating final display dataframe.
2025-09-10 10:14:00,585:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target              isNC
2                   Target type            Binary
3           Original data shape       (12216, 31)
4        Transformed data shape      (12216, 161)
5   Transformed train set shape       (8551, 161)
6    Transformed test set shape       (3665, 161)
7              Numeric features                 3
8                 Date features                 5
9          Categorical features                22
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                    Normalize              True
17             Normalize method            zscore
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              cbba
2025-09-10 10:14:00,632:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 10:14:00,634:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 10:14:00,676:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 10:14:00,677:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 10:14:00,678:INFO:setup() successfully completed in 5.13s...............
2025-09-10 10:14:00,697:INFO:Initializing compare_models()
2025-09-10 10:14:00,697:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FAEF5CD390>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001FAEF5CD390>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-09-10 10:14:00,697:INFO:Checking exceptions
2025-09-10 10:14:00,710:INFO:Preparing display monitor
2025-09-10 10:14:00,746:INFO:Initializing Logistic Regression
2025-09-10 10:14:00,746:INFO:Total runtime is 0.0 minutes
2025-09-10 10:14:00,751:INFO:SubProcess create_model() called ==================================
2025-09-10 10:14:00,752:INFO:Initializing create_model()
2025-09-10 10:14:00,752:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FAEF5CD390>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAFA083450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 10:14:00,752:INFO:Checking exceptions
2025-09-10 10:14:00,752:INFO:Importing libraries
2025-09-10 10:14:00,752:INFO:Copying training dataset
2025-09-10 10:14:00,760:INFO:Defining folds
2025-09-10 10:14:00,761:INFO:Declaring metric variables
2025-09-10 10:14:00,764:INFO:Importing untrained model
2025-09-10 10:14:00,768:INFO:Logistic Regression Imported successfully
2025-09-10 10:14:00,778:INFO:Starting cross validation
2025-09-10 10:14:00,781:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 10:14:08,908:INFO:Calculating mean and std
2025-09-10 10:14:08,910:INFO:Creating metrics dataframe
2025-09-10 10:14:08,929:INFO:Uploading results into container
2025-09-10 10:14:08,930:INFO:Uploading model into container now
2025-09-10 10:14:08,931:INFO:_master_model_container: 1
2025-09-10 10:14:08,931:INFO:_display_container: 2
2025-09-10 10:14:08,932:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-09-10 10:14:08,932:INFO:create_model() successfully completed......................................
2025-09-10 10:14:09,076:INFO:SubProcess create_model() end ==================================
2025-09-10 10:14:09,077:INFO:Creating metrics dataframe
2025-09-10 10:14:09,083:INFO:Initializing K Neighbors Classifier
2025-09-10 10:14:09,083:INFO:Total runtime is 0.1389432986577352 minutes
2025-09-10 10:14:09,088:INFO:SubProcess create_model() called ==================================
2025-09-10 10:14:09,089:INFO:Initializing create_model()
2025-09-10 10:14:09,089:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FAEF5CD390>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAFA083450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 10:14:09,089:INFO:Checking exceptions
2025-09-10 10:14:09,089:INFO:Importing libraries
2025-09-10 10:14:09,089:INFO:Copying training dataset
2025-09-10 10:14:09,098:INFO:Defining folds
2025-09-10 10:14:09,098:INFO:Declaring metric variables
2025-09-10 10:14:09,104:INFO:Importing untrained model
2025-09-10 10:14:09,109:INFO:K Neighbors Classifier Imported successfully
2025-09-10 10:14:09,119:INFO:Starting cross validation
2025-09-10 10:14:09,123:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 10:14:13,848:INFO:Calculating mean and std
2025-09-10 10:14:13,849:INFO:Creating metrics dataframe
2025-09-10 10:14:13,851:INFO:Uploading results into container
2025-09-10 10:14:13,852:INFO:Uploading model into container now
2025-09-10 10:14:13,853:INFO:_master_model_container: 2
2025-09-10 10:14:13,853:INFO:_display_container: 2
2025-09-10 10:14:13,853:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-09-10 10:14:13,854:INFO:create_model() successfully completed......................................
2025-09-10 10:14:13,973:INFO:SubProcess create_model() end ==================================
2025-09-10 10:14:13,973:INFO:Creating metrics dataframe
2025-09-10 10:14:13,986:INFO:Initializing Naive Bayes
2025-09-10 10:14:13,986:INFO:Total runtime is 0.22066360314687095 minutes
2025-09-10 10:14:13,990:INFO:SubProcess create_model() called ==================================
2025-09-10 10:14:13,990:INFO:Initializing create_model()
2025-09-10 10:14:13,991:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FAEF5CD390>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAFA083450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 10:14:13,991:INFO:Checking exceptions
2025-09-10 10:14:13,991:INFO:Importing libraries
2025-09-10 10:14:13,991:INFO:Copying training dataset
2025-09-10 10:14:13,999:INFO:Defining folds
2025-09-10 10:14:13,999:INFO:Declaring metric variables
2025-09-10 10:14:14,006:INFO:Importing untrained model
2025-09-10 10:14:14,014:INFO:Naive Bayes Imported successfully
2025-09-10 10:14:14,027:INFO:Starting cross validation
2025-09-10 10:14:14,030:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 10:14:15,816:INFO:Calculating mean and std
2025-09-10 10:14:15,816:INFO:Creating metrics dataframe
2025-09-10 10:14:15,820:INFO:Uploading results into container
2025-09-10 10:14:15,821:INFO:Uploading model into container now
2025-09-10 10:14:15,821:INFO:_master_model_container: 3
2025-09-10 10:14:15,821:INFO:_display_container: 2
2025-09-10 10:14:15,822:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-09-10 10:14:15,822:INFO:create_model() successfully completed......................................
2025-09-10 10:14:15,948:INFO:SubProcess create_model() end ==================================
2025-09-10 10:14:15,948:INFO:Creating metrics dataframe
2025-09-10 10:14:15,954:INFO:Initializing Decision Tree Classifier
2025-09-10 10:14:15,955:INFO:Total runtime is 0.25348130464553836 minutes
2025-09-10 10:14:15,960:INFO:SubProcess create_model() called ==================================
2025-09-10 10:14:15,960:INFO:Initializing create_model()
2025-09-10 10:14:15,960:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FAEF5CD390>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAFA083450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 10:14:15,961:INFO:Checking exceptions
2025-09-10 10:14:15,961:INFO:Importing libraries
2025-09-10 10:14:15,961:INFO:Copying training dataset
2025-09-10 10:14:15,969:INFO:Defining folds
2025-09-10 10:14:15,969:INFO:Declaring metric variables
2025-09-10 10:14:15,975:INFO:Importing untrained model
2025-09-10 10:14:15,983:INFO:Decision Tree Classifier Imported successfully
2025-09-10 10:14:15,996:INFO:Starting cross validation
2025-09-10 10:14:15,999:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 10:14:17,676:INFO:Calculating mean and std
2025-09-10 10:14:17,677:INFO:Creating metrics dataframe
2025-09-10 10:14:17,680:INFO:Uploading results into container
2025-09-10 10:14:17,680:INFO:Uploading model into container now
2025-09-10 10:14:17,681:INFO:_master_model_container: 4
2025-09-10 10:14:17,681:INFO:_display_container: 2
2025-09-10 10:14:17,681:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-09-10 10:14:17,681:INFO:create_model() successfully completed......................................
2025-09-10 10:14:17,804:INFO:SubProcess create_model() end ==================================
2025-09-10 10:14:17,805:INFO:Creating metrics dataframe
2025-09-10 10:14:17,813:INFO:Initializing SVM - Linear Kernel
2025-09-10 10:14:17,813:INFO:Total runtime is 0.2844430247942607 minutes
2025-09-10 10:14:17,817:INFO:SubProcess create_model() called ==================================
2025-09-10 10:14:17,817:INFO:Initializing create_model()
2025-09-10 10:14:17,817:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FAEF5CD390>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAFA083450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 10:14:17,817:INFO:Checking exceptions
2025-09-10 10:14:17,818:INFO:Importing libraries
2025-09-10 10:14:17,818:INFO:Copying training dataset
2025-09-10 10:14:17,824:INFO:Defining folds
2025-09-10 10:14:17,824:INFO:Declaring metric variables
2025-09-10 10:14:17,832:INFO:Importing untrained model
2025-09-10 10:14:17,837:INFO:SVM - Linear Kernel Imported successfully
2025-09-10 10:14:17,849:INFO:Starting cross validation
2025-09-10 10:14:17,854:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 10:14:19,746:INFO:Calculating mean and std
2025-09-10 10:14:19,746:INFO:Creating metrics dataframe
2025-09-10 10:14:19,749:INFO:Uploading results into container
2025-09-10 10:14:19,749:INFO:Uploading model into container now
2025-09-10 10:14:19,750:INFO:_master_model_container: 5
2025-09-10 10:14:19,750:INFO:_display_container: 2
2025-09-10 10:14:19,751:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-09-10 10:14:19,751:INFO:create_model() successfully completed......................................
2025-09-10 10:14:19,876:INFO:SubProcess create_model() end ==================================
2025-09-10 10:14:19,877:INFO:Creating metrics dataframe
2025-09-10 10:14:19,884:INFO:Initializing Ridge Classifier
2025-09-10 10:14:19,884:INFO:Total runtime is 0.3189650774002076 minutes
2025-09-10 10:14:19,888:INFO:SubProcess create_model() called ==================================
2025-09-10 10:14:19,888:INFO:Initializing create_model()
2025-09-10 10:14:19,888:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FAEF5CD390>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAFA083450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 10:14:19,889:INFO:Checking exceptions
2025-09-10 10:14:19,889:INFO:Importing libraries
2025-09-10 10:14:19,889:INFO:Copying training dataset
2025-09-10 10:14:19,896:INFO:Defining folds
2025-09-10 10:14:19,896:INFO:Declaring metric variables
2025-09-10 10:14:19,901:INFO:Importing untrained model
2025-09-10 10:14:19,909:INFO:Ridge Classifier Imported successfully
2025-09-10 10:14:19,921:INFO:Starting cross validation
2025-09-10 10:14:19,927:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 10:14:21,912:INFO:Calculating mean and std
2025-09-10 10:14:21,913:INFO:Creating metrics dataframe
2025-09-10 10:14:21,917:INFO:Uploading results into container
2025-09-10 10:14:21,918:INFO:Uploading model into container now
2025-09-10 10:14:21,918:INFO:_master_model_container: 6
2025-09-10 10:14:21,918:INFO:_display_container: 2
2025-09-10 10:14:21,918:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-09-10 10:14:21,918:INFO:create_model() successfully completed......................................
2025-09-10 10:14:22,057:INFO:SubProcess create_model() end ==================================
2025-09-10 10:14:22,057:INFO:Creating metrics dataframe
2025-09-10 10:14:22,078:INFO:Initializing Random Forest Classifier
2025-09-10 10:14:22,078:INFO:Total runtime is 0.3555317838986715 minutes
2025-09-10 10:14:22,084:INFO:SubProcess create_model() called ==================================
2025-09-10 10:14:22,084:INFO:Initializing create_model()
2025-09-10 10:14:22,084:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FAEF5CD390>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAFA083450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 10:14:22,084:INFO:Checking exceptions
2025-09-10 10:14:22,084:INFO:Importing libraries
2025-09-10 10:14:22,084:INFO:Copying training dataset
2025-09-10 10:14:22,106:INFO:Defining folds
2025-09-10 10:14:22,106:INFO:Declaring metric variables
2025-09-10 10:14:22,114:INFO:Importing untrained model
2025-09-10 10:14:22,125:INFO:Random Forest Classifier Imported successfully
2025-09-10 10:14:22,143:INFO:Starting cross validation
2025-09-10 10:14:22,148:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 10:14:25,044:INFO:Calculating mean and std
2025-09-10 10:14:25,044:INFO:Creating metrics dataframe
2025-09-10 10:14:25,048:INFO:Uploading results into container
2025-09-10 10:14:25,048:INFO:Uploading model into container now
2025-09-10 10:14:25,048:INFO:_master_model_container: 7
2025-09-10 10:14:25,048:INFO:_display_container: 2
2025-09-10 10:14:25,048:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-09-10 10:14:25,051:INFO:create_model() successfully completed......................................
2025-09-10 10:14:25,232:INFO:SubProcess create_model() end ==================================
2025-09-10 10:14:25,232:INFO:Creating metrics dataframe
2025-09-10 10:14:25,249:INFO:Initializing Quadratic Discriminant Analysis
2025-09-10 10:14:25,249:INFO:Total runtime is 0.40838255882263186 minutes
2025-09-10 10:14:25,256:INFO:SubProcess create_model() called ==================================
2025-09-10 10:14:25,257:INFO:Initializing create_model()
2025-09-10 10:14:25,257:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FAEF5CD390>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAFA083450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 10:14:25,258:INFO:Checking exceptions
2025-09-10 10:14:25,258:INFO:Importing libraries
2025-09-10 10:14:25,258:INFO:Copying training dataset
2025-09-10 10:14:25,270:INFO:Defining folds
2025-09-10 10:14:25,270:INFO:Declaring metric variables
2025-09-10 10:14:25,282:INFO:Importing untrained model
2025-09-10 10:14:25,289:INFO:Quadratic Discriminant Analysis Imported successfully
2025-09-10 10:14:25,305:INFO:Starting cross validation
2025-09-10 10:14:25,310:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 10:14:27,198:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-10 10:14:27,217:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-10 10:14:27,285:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-10 10:14:27,330:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-10 10:14:27,478:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-10 10:14:27,505:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-10 10:14:27,525:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-10 10:14:27,532:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-10 10:14:27,551:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-10 10:14:27,592:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-10 10:14:28,175:INFO:Calculating mean and std
2025-09-10 10:14:28,176:INFO:Creating metrics dataframe
2025-09-10 10:14:28,180:INFO:Uploading results into container
2025-09-10 10:14:28,182:INFO:Uploading model into container now
2025-09-10 10:14:28,183:INFO:_master_model_container: 8
2025-09-10 10:14:28,183:INFO:_display_container: 2
2025-09-10 10:14:28,183:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-09-10 10:14:28,183:INFO:create_model() successfully completed......................................
2025-09-10 10:14:28,375:INFO:SubProcess create_model() end ==================================
2025-09-10 10:14:28,375:INFO:Creating metrics dataframe
2025-09-10 10:14:28,375:INFO:Initializing Ada Boost Classifier
2025-09-10 10:14:28,375:INFO:Total runtime is 0.46048228740692143 minutes
2025-09-10 10:14:28,391:INFO:SubProcess create_model() called ==================================
2025-09-10 10:14:28,391:INFO:Initializing create_model()
2025-09-10 10:14:28,391:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FAEF5CD390>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAFA083450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 10:14:28,391:INFO:Checking exceptions
2025-09-10 10:14:28,391:INFO:Importing libraries
2025-09-10 10:14:28,391:INFO:Copying training dataset
2025-09-10 10:14:28,415:INFO:Defining folds
2025-09-10 10:14:28,416:INFO:Declaring metric variables
2025-09-10 10:14:28,426:INFO:Importing untrained model
2025-09-10 10:14:28,436:INFO:Ada Boost Classifier Imported successfully
2025-09-10 10:14:28,452:INFO:Starting cross validation
2025-09-10 10:14:28,456:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 10:14:29,931:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-10 10:14:30,127:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-10 10:14:30,138:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-10 10:14:30,178:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-10 10:14:30,184:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-10 10:14:30,189:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-10 10:14:30,250:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-10 10:14:30,273:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-10 10:14:30,399:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-10 10:14:30,477:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-10 10:14:30,701:INFO:Calculating mean and std
2025-09-10 10:14:30,703:INFO:Creating metrics dataframe
2025-09-10 10:14:30,710:INFO:Uploading results into container
2025-09-10 10:14:30,712:INFO:Uploading model into container now
2025-09-10 10:14:30,712:INFO:_master_model_container: 9
2025-09-10 10:14:30,713:INFO:_display_container: 2
2025-09-10 10:14:30,713:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-09-10 10:14:30,714:INFO:create_model() successfully completed......................................
2025-09-10 10:14:30,963:INFO:SubProcess create_model() end ==================================
2025-09-10 10:14:30,964:INFO:Creating metrics dataframe
2025-09-10 10:14:30,977:INFO:Initializing Gradient Boosting Classifier
2025-09-10 10:14:30,977:INFO:Total runtime is 0.503844714164734 minutes
2025-09-10 10:14:30,980:INFO:SubProcess create_model() called ==================================
2025-09-10 10:14:30,980:INFO:Initializing create_model()
2025-09-10 10:14:30,980:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FAEF5CD390>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAFA083450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 10:14:30,980:INFO:Checking exceptions
2025-09-10 10:14:30,980:INFO:Importing libraries
2025-09-10 10:14:30,980:INFO:Copying training dataset
2025-09-10 10:14:31,000:INFO:Defining folds
2025-09-10 10:14:31,000:INFO:Declaring metric variables
2025-09-10 10:14:31,011:INFO:Importing untrained model
2025-09-10 10:14:31,021:INFO:Gradient Boosting Classifier Imported successfully
2025-09-10 10:14:31,035:INFO:Starting cross validation
2025-09-10 10:14:31,039:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 10:14:33,926:INFO:Calculating mean and std
2025-09-10 10:14:33,927:INFO:Creating metrics dataframe
2025-09-10 10:14:33,929:INFO:Uploading results into container
2025-09-10 10:14:33,929:INFO:Uploading model into container now
2025-09-10 10:14:33,930:INFO:_master_model_container: 10
2025-09-10 10:14:33,930:INFO:_display_container: 2
2025-09-10 10:14:33,930:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-09-10 10:14:33,930:INFO:create_model() successfully completed......................................
2025-09-10 10:14:34,058:INFO:SubProcess create_model() end ==================================
2025-09-10 10:14:34,058:INFO:Creating metrics dataframe
2025-09-10 10:14:34,076:INFO:Initializing Linear Discriminant Analysis
2025-09-10 10:14:34,076:INFO:Total runtime is 0.5555044571558635 minutes
2025-09-10 10:14:34,076:INFO:SubProcess create_model() called ==================================
2025-09-10 10:14:34,076:INFO:Initializing create_model()
2025-09-10 10:14:34,076:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FAEF5CD390>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAFA083450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 10:14:34,076:INFO:Checking exceptions
2025-09-10 10:14:34,076:INFO:Importing libraries
2025-09-10 10:14:34,076:INFO:Copying training dataset
2025-09-10 10:14:34,097:INFO:Defining folds
2025-09-10 10:14:34,098:INFO:Declaring metric variables
2025-09-10 10:14:34,103:INFO:Importing untrained model
2025-09-10 10:14:34,109:INFO:Linear Discriminant Analysis Imported successfully
2025-09-10 10:14:34,123:INFO:Starting cross validation
2025-09-10 10:14:34,128:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 10:14:36,939:INFO:Calculating mean and std
2025-09-10 10:14:36,940:INFO:Creating metrics dataframe
2025-09-10 10:14:36,942:INFO:Uploading results into container
2025-09-10 10:14:36,942:INFO:Uploading model into container now
2025-09-10 10:14:36,942:INFO:_master_model_container: 11
2025-09-10 10:14:36,942:INFO:_display_container: 2
2025-09-10 10:14:36,946:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-09-10 10:14:36,946:INFO:create_model() successfully completed......................................
2025-09-10 10:14:37,058:INFO:SubProcess create_model() end ==================================
2025-09-10 10:14:37,058:INFO:Creating metrics dataframe
2025-09-10 10:14:37,078:INFO:Initializing Extra Trees Classifier
2025-09-10 10:14:37,078:INFO:Total runtime is 0.6055376052856446 minutes
2025-09-10 10:14:37,078:INFO:SubProcess create_model() called ==================================
2025-09-10 10:14:37,078:INFO:Initializing create_model()
2025-09-10 10:14:37,078:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FAEF5CD390>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAFA083450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 10:14:37,078:INFO:Checking exceptions
2025-09-10 10:14:37,078:INFO:Importing libraries
2025-09-10 10:14:37,078:INFO:Copying training dataset
2025-09-10 10:14:37,093:INFO:Defining folds
2025-09-10 10:14:37,093:INFO:Declaring metric variables
2025-09-10 10:14:37,101:INFO:Importing untrained model
2025-09-10 10:14:37,108:INFO:Extra Trees Classifier Imported successfully
2025-09-10 10:14:37,122:INFO:Starting cross validation
2025-09-10 10:14:37,126:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 10:14:39,142:INFO:Calculating mean and std
2025-09-10 10:14:39,142:INFO:Creating metrics dataframe
2025-09-10 10:14:39,142:INFO:Uploading results into container
2025-09-10 10:14:39,142:INFO:Uploading model into container now
2025-09-10 10:14:39,142:INFO:_master_model_container: 12
2025-09-10 10:14:39,142:INFO:_display_container: 2
2025-09-10 10:14:39,142:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-09-10 10:14:39,142:INFO:create_model() successfully completed......................................
2025-09-10 10:14:39,296:INFO:SubProcess create_model() end ==================================
2025-09-10 10:14:39,296:INFO:Creating metrics dataframe
2025-09-10 10:14:39,312:INFO:Initializing Extreme Gradient Boosting
2025-09-10 10:14:39,312:INFO:Total runtime is 0.6427625934282939 minutes
2025-09-10 10:14:39,312:INFO:SubProcess create_model() called ==================================
2025-09-10 10:14:39,312:INFO:Initializing create_model()
2025-09-10 10:14:39,312:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FAEF5CD390>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAFA083450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 10:14:39,312:INFO:Checking exceptions
2025-09-10 10:14:39,312:INFO:Importing libraries
2025-09-10 10:14:39,312:INFO:Copying training dataset
2025-09-10 10:14:39,327:INFO:Defining folds
2025-09-10 10:14:39,327:INFO:Declaring metric variables
2025-09-10 10:14:39,344:INFO:Importing untrained model
2025-09-10 10:14:39,350:INFO:Extreme Gradient Boosting Imported successfully
2025-09-10 10:14:39,364:INFO:Starting cross validation
2025-09-10 10:14:39,369:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 10:14:41,403:INFO:Calculating mean and std
2025-09-10 10:14:41,403:INFO:Creating metrics dataframe
2025-09-10 10:14:41,408:INFO:Uploading results into container
2025-09-10 10:14:41,410:INFO:Uploading model into container now
2025-09-10 10:14:41,411:INFO:_master_model_container: 13
2025-09-10 10:14:41,411:INFO:_display_container: 2
2025-09-10 10:14:41,412:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-09-10 10:14:41,413:INFO:create_model() successfully completed......................................
2025-09-10 10:14:41,528:INFO:SubProcess create_model() end ==================================
2025-09-10 10:14:41,528:INFO:Creating metrics dataframe
2025-09-10 10:14:41,528:INFO:Initializing Light Gradient Boosting Machine
2025-09-10 10:14:41,528:INFO:Total runtime is 0.6797015269597372 minutes
2025-09-10 10:14:41,544:INFO:SubProcess create_model() called ==================================
2025-09-10 10:14:41,544:INFO:Initializing create_model()
2025-09-10 10:14:41,544:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FAEF5CD390>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAFA083450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 10:14:41,544:INFO:Checking exceptions
2025-09-10 10:14:41,544:INFO:Importing libraries
2025-09-10 10:14:41,544:INFO:Copying training dataset
2025-09-10 10:14:41,558:INFO:Defining folds
2025-09-10 10:14:41,558:INFO:Declaring metric variables
2025-09-10 10:14:41,564:INFO:Importing untrained model
2025-09-10 10:14:41,564:INFO:Light Gradient Boosting Machine Imported successfully
2025-09-10 10:14:41,586:INFO:Starting cross validation
2025-09-10 10:14:41,589:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 10:14:43,939:INFO:Calculating mean and std
2025-09-10 10:14:43,939:INFO:Creating metrics dataframe
2025-09-10 10:14:43,943:INFO:Uploading results into container
2025-09-10 10:14:43,944:INFO:Uploading model into container now
2025-09-10 10:14:43,944:INFO:_master_model_container: 14
2025-09-10 10:14:43,944:INFO:_display_container: 2
2025-09-10 10:14:43,946:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-09-10 10:14:43,946:INFO:create_model() successfully completed......................................
2025-09-10 10:14:44,074:INFO:SubProcess create_model() end ==================================
2025-09-10 10:14:44,074:INFO:Creating metrics dataframe
2025-09-10 10:14:44,100:INFO:Initializing CatBoost Classifier
2025-09-10 10:14:44,100:INFO:Total runtime is 0.7225615620613098 minutes
2025-09-10 10:14:44,106:INFO:SubProcess create_model() called ==================================
2025-09-10 10:14:44,107:INFO:Initializing create_model()
2025-09-10 10:14:44,107:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FAEF5CD390>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAFA083450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 10:14:44,107:INFO:Checking exceptions
2025-09-10 10:14:44,107:INFO:Importing libraries
2025-09-10 10:14:44,107:INFO:Copying training dataset
2025-09-10 10:14:44,121:INFO:Defining folds
2025-09-10 10:14:44,121:INFO:Declaring metric variables
2025-09-10 10:14:44,128:INFO:Importing untrained model
2025-09-10 10:14:44,134:INFO:CatBoost Classifier Imported successfully
2025-09-10 10:14:44,147:INFO:Starting cross validation
2025-09-10 10:14:44,151:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 10:15:02,045:INFO:Calculating mean and std
2025-09-10 10:15:02,046:INFO:Creating metrics dataframe
2025-09-10 10:15:02,050:INFO:Uploading results into container
2025-09-10 10:15:02,051:INFO:Uploading model into container now
2025-09-10 10:15:02,051:INFO:_master_model_container: 15
2025-09-10 10:15:02,051:INFO:_display_container: 2
2025-09-10 10:15:02,052:INFO:<catboost.core.CatBoostClassifier object at 0x000001FAF98D0290>
2025-09-10 10:15:02,052:INFO:create_model() successfully completed......................................
2025-09-10 10:15:02,206:INFO:SubProcess create_model() end ==================================
2025-09-10 10:15:02,206:INFO:Creating metrics dataframe
2025-09-10 10:15:02,213:INFO:Initializing Dummy Classifier
2025-09-10 10:15:02,213:INFO:Total runtime is 1.0244591196378072 minutes
2025-09-10 10:15:02,225:INFO:SubProcess create_model() called ==================================
2025-09-10 10:15:02,226:INFO:Initializing create_model()
2025-09-10 10:15:02,226:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FAEF5CD390>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FAFA083450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 10:15:02,226:INFO:Checking exceptions
2025-09-10 10:15:02,226:INFO:Importing libraries
2025-09-10 10:15:02,226:INFO:Copying training dataset
2025-09-10 10:15:02,235:INFO:Defining folds
2025-09-10 10:15:02,236:INFO:Declaring metric variables
2025-09-10 10:15:02,243:INFO:Importing untrained model
2025-09-10 10:15:02,251:INFO:Dummy Classifier Imported successfully
2025-09-10 10:15:02,264:INFO:Starting cross validation
2025-09-10 10:15:02,268:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 10:15:03,930:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-10 10:15:03,936:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-10 10:15:03,942:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-10 10:15:03,952:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-10 10:15:03,973:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-10 10:15:03,988:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-10 10:15:03,989:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-10 10:15:03,992:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-10 10:15:04,004:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-10 10:15:04,013:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-10 10:15:04,034:INFO:Calculating mean and std
2025-09-10 10:15:04,036:INFO:Creating metrics dataframe
2025-09-10 10:15:04,041:INFO:Uploading results into container
2025-09-10 10:15:04,043:INFO:Uploading model into container now
2025-09-10 10:15:04,044:INFO:_master_model_container: 16
2025-09-10 10:15:04,044:INFO:_display_container: 2
2025-09-10 10:15:04,044:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-09-10 10:15:04,044:INFO:create_model() successfully completed......................................
2025-09-10 10:15:04,210:INFO:SubProcess create_model() end ==================================
2025-09-10 10:15:04,211:INFO:Creating metrics dataframe
2025-09-10 10:15:04,243:INFO:Initializing create_model()
2025-09-10 10:15:04,244:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FAEF5CD390>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 10:15:04,244:INFO:Checking exceptions
2025-09-10 10:15:04,244:INFO:Importing libraries
2025-09-10 10:15:04,244:INFO:Copying training dataset
2025-09-10 10:15:04,262:INFO:Defining folds
2025-09-10 10:15:04,262:INFO:Declaring metric variables
2025-09-10 10:15:04,262:INFO:Importing untrained model
2025-09-10 10:15:04,262:INFO:Declaring custom model
2025-09-10 10:15:04,263:INFO:Logistic Regression Imported successfully
2025-09-10 10:15:04,268:INFO:Cross validation set to False
2025-09-10 10:15:04,268:INFO:Fitting Model
2025-09-10 10:15:04,889:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-09-10 10:15:04,889:INFO:create_model() successfully completed......................................
2025-09-10 10:15:05,048:INFO:Initializing create_model()
2025-09-10 10:15:05,048:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FAEF5CD390>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 10:15:05,048:INFO:Checking exceptions
2025-09-10 10:15:05,048:INFO:Importing libraries
2025-09-10 10:15:05,048:INFO:Copying training dataset
2025-09-10 10:15:05,059:INFO:Defining folds
2025-09-10 10:15:05,060:INFO:Declaring metric variables
2025-09-10 10:15:05,060:INFO:Importing untrained model
2025-09-10 10:15:05,060:INFO:Declaring custom model
2025-09-10 10:15:05,060:INFO:K Neighbors Classifier Imported successfully
2025-09-10 10:15:05,060:INFO:Cross validation set to False
2025-09-10 10:15:05,060:INFO:Fitting Model
2025-09-10 10:15:05,599:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-09-10 10:15:05,599:INFO:create_model() successfully completed......................................
2025-09-10 10:15:05,725:INFO:Initializing create_model()
2025-09-10 10:15:05,725:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FAEF5CD390>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 10:15:05,726:INFO:Checking exceptions
2025-09-10 10:15:05,728:INFO:Importing libraries
2025-09-10 10:15:05,728:INFO:Copying training dataset
2025-09-10 10:15:05,734:INFO:Defining folds
2025-09-10 10:15:05,734:INFO:Declaring metric variables
2025-09-10 10:15:05,735:INFO:Importing untrained model
2025-09-10 10:15:05,735:INFO:Declaring custom model
2025-09-10 10:15:05,735:INFO:Naive Bayes Imported successfully
2025-09-10 10:15:05,736:INFO:Cross validation set to False
2025-09-10 10:15:05,736:INFO:Fitting Model
2025-09-10 10:15:06,282:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-09-10 10:15:06,282:INFO:create_model() successfully completed......................................
2025-09-10 10:15:06,461:INFO:_master_model_container: 16
2025-09-10 10:15:06,462:INFO:_display_container: 2
2025-09-10 10:15:06,462:INFO:[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), GaussianNB(priors=None, var_smoothing=1e-09)]
2025-09-10 10:15:06,463:INFO:compare_models() successfully completed......................................
2025-09-10 10:15:06,520:INFO:Initializing create_model()
2025-09-10 10:15:06,521:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FAEF5CD390>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=True, error_score=0.0, kwargs={})
2025-09-10 10:15:06,521:INFO:Checking exceptions
2025-09-10 10:15:06,546:INFO:Importing libraries
2025-09-10 10:15:06,547:INFO:Copying training dataset
2025-09-10 10:15:06,563:INFO:Defining folds
2025-09-10 10:15:06,564:INFO:Declaring metric variables
2025-09-10 10:15:06,570:INFO:Importing untrained model
2025-09-10 10:15:06,581:INFO:Logistic Regression Imported successfully
2025-09-10 10:15:06,594:INFO:Starting cross validation
2025-09-10 10:15:06,598:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 10:15:09,064:INFO:Calculating mean and std
2025-09-10 10:15:09,064:INFO:Creating metrics dataframe
2025-09-10 10:15:09,082:INFO:Finalizing model
2025-09-10 10:15:09,641:INFO:Initializing predict_model()
2025-09-10 10:15:09,641:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FAEF5CD390>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['TimeStart', 'TimeStop',
                                             'ProductionDate', 'ApproveDate',
                                             'CreateDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Mpw', 'QtyOutput', 'QtyOutput3'],
                                    trans...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=42,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FAFA087600>)
2025-09-10 10:15:09,641:INFO:Checking exceptions
2025-09-10 10:15:09,641:INFO:Preloading libraries
2025-09-10 10:15:09,641:INFO:Set up data.
2025-09-10 10:15:09,657:INFO:Set up index.
2025-09-10 10:15:10,025:INFO:Uploading results into container
2025-09-10 10:15:10,026:INFO:Uploading model into container now
2025-09-10 10:15:10,046:INFO:_master_model_container: 17
2025-09-10 10:15:10,046:INFO:_display_container: 3
2025-09-10 10:15:10,046:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-09-10 10:15:10,046:INFO:create_model() successfully completed......................................
2025-09-10 10:15:10,259:INFO:Initializing finalize_model()
2025-09-10 10:15:10,259:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FAEF5CD390>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-09-10 10:15:10,260:INFO:Finalizing LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-09-10 10:15:10,267:INFO:Initializing create_model()
2025-09-10 10:15:10,268:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FAEF5CD390>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 10:15:10,268:INFO:Checking exceptions
2025-09-10 10:15:10,270:INFO:Importing libraries
2025-09-10 10:15:10,270:INFO:Copying training dataset
2025-09-10 10:15:10,272:INFO:Defining folds
2025-09-10 10:15:10,272:INFO:Declaring metric variables
2025-09-10 10:15:10,272:INFO:Importing untrained model
2025-09-10 10:15:10,273:INFO:Declaring custom model
2025-09-10 10:15:10,273:INFO:Logistic Regression Imported successfully
2025-09-10 10:15:10,278:INFO:Cross validation set to False
2025-09-10 10:15:10,278:INFO:Fitting Model
2025-09-10 10:15:10,929:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['TimeStart', 'TimeStop',
                                             'ProductionDate', 'ApproveDate',
                                             'CreateDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Mpw', 'QtyOutput', 'QtyOutput3'],
                                    trans...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=42,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-09-10 10:15:10,929:INFO:create_model() successfully completed......................................
2025-09-10 10:15:11,042:INFO:_master_model_container: 17
2025-09-10 10:15:11,042:INFO:_display_container: 3
2025-09-10 10:15:11,074:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['TimeStart', 'TimeStop',
                                             'ProductionDate', 'ApproveDate',
                                             'CreateDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Mpw', 'QtyOutput', 'QtyOutput3'],
                                    trans...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=42,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-09-10 10:15:11,074:INFO:finalize_model() successfully completed......................................
2025-09-10 10:15:11,305:INFO:Initializing save_model()
2025-09-10 10:15:11,305:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['TimeStart', 'TimeStop',
                                             'ProductionDate', 'ApproveDate',
                                             'CreateDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Mpw', 'QtyOutput', 'QtyOutput3'],
                                    trans...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=42,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), model_name=Logistic_Regression_Model_RTW, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\SBM_ME~1\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['TimeStart', 'TimeStop',
                                             'ProductionDate', 'ApproveDate',
                                             'CreateDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    inc...
                                                                    'LeaderID',
                                                                    'ProdCode',
                                                                    'Lot',
                                                                    'LNCNo',
                                                                    'SessionID2',
                                                                    'FGCode',
                                                                    'LotNo'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-09-10 10:15:11,306:INFO:Adding model into prep_pipe
2025-09-10 10:15:11,306:WARNING:Only Model saved as it was a pipeline.
2025-09-10 10:15:11,331:INFO:Logistic_Regression_Model_RTW.pkl saved in current working directory
2025-09-10 10:15:11,352:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['TimeStart', 'TimeStop',
                                             'ProductionDate', 'ApproveDate',
                                             'CreateDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Mpw', 'QtyOutput', 'QtyOutput3'],
                                    trans...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=42,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-09-10 10:15:11,352:INFO:save_model() successfully completed......................................
2025-09-10 11:52:06,264:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 11:52:06,265:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 11:52:06,265:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 11:52:06,265:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 12:06:40,647:INFO:PyCaret ClassificationExperiment
2025-09-10 12:06:40,647:INFO:Logging name: clf-default-name
2025-09-10 12:06:40,647:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-09-10 12:06:40,647:INFO:version 3.3.2
2025-09-10 12:06:40,647:INFO:Initializing setup()
2025-09-10 12:06:40,647:INFO:self.USI: 4a01
2025-09-10 12:06:40,647:INFO:self._variable_keys: {'exp_name_log', 'log_plots_param', 'fold_groups_param', 'is_multiclass', 'target_param', 'pipeline', 'fold_generator', 'y', 'X', 'fold_shuffle_param', 'gpu_param', 'logging_param', 'data', 'y_test', 'memory', 'X_test', '_ml_usecase', '_available_plots', 'html_param', 'fix_imbalance', 'X_train', 'y_train', 'USI', 'seed', 'exp_id', 'gpu_n_jobs_param', 'n_jobs_param', 'idx'}
2025-09-10 12:06:40,647:INFO:Checking environment
2025-09-10 12:06:40,647:INFO:python_version: 3.11.10
2025-09-10 12:06:40,647:INFO:python_build: ('main', 'Oct  3 2024 07:22:26')
2025-09-10 12:06:40,647:INFO:machine: AMD64
2025-09-10 12:06:40,647:INFO:platform: Windows-10-10.0.26100-SP0
2025-09-10 12:06:40,652:INFO:Memory: svmem(total=16837152768, available=3185651712, percent=81.1, used=13651501056, free=3185651712)
2025-09-10 12:06:40,652:INFO:Physical Core: 10
2025-09-10 12:06:40,652:INFO:Logical Core: 12
2025-09-10 12:06:40,652:INFO:Checking libraries
2025-09-10 12:06:40,652:INFO:System:
2025-09-10 12:06:40,652:INFO:    python: 3.11.10 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:26) [MSC v.1929 64 bit (AMD64)]
2025-09-10 12:06:40,652:INFO:executable: c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\python.exe
2025-09-10 12:06:40,652:INFO:   machine: Windows-10-10.0.26100-SP0
2025-09-10 12:06:40,652:INFO:PyCaret required dependencies:
2025-09-10 12:06:41,041:INFO:                 pip: 24.2
2025-09-10 12:06:41,041:INFO:          setuptools: 75.1.0
2025-09-10 12:06:41,042:INFO:             pycaret: 3.3.2
2025-09-10 12:06:41,042:INFO:             IPython: 9.2.0
2025-09-10 12:06:41,042:INFO:          ipywidgets: 8.1.7
2025-09-10 12:06:41,042:INFO:                tqdm: 4.67.1
2025-09-10 12:06:41,042:INFO:               numpy: 1.24.4
2025-09-10 12:06:41,042:INFO:              pandas: 1.5.3
2025-09-10 12:06:41,042:INFO:              jinja2: 3.1.6
2025-09-10 12:06:41,042:INFO:               scipy: 1.11.4
2025-09-10 12:06:41,042:INFO:              joblib: 1.3.2
2025-09-10 12:06:41,042:INFO:             sklearn: 1.4.2
2025-09-10 12:06:41,042:INFO:                pyod: 2.0.5
2025-09-10 12:06:41,042:INFO:            imblearn: 0.13.0
2025-09-10 12:06:41,042:INFO:   category_encoders: 2.7.0
2025-09-10 12:06:41,042:INFO:            lightgbm: 4.6.0
2025-09-10 12:06:41,042:INFO:               numba: 0.61.0
2025-09-10 12:06:41,042:INFO:            requests: 2.32.3
2025-09-10 12:06:41,042:INFO:          matplotlib: 3.7.5
2025-09-10 12:06:41,042:INFO:          scikitplot: 0.3.7
2025-09-10 12:06:41,042:INFO:         yellowbrick: 1.5
2025-09-10 12:06:41,042:INFO:              plotly: 5.24.1
2025-09-10 12:06:41,042:INFO:    plotly-resampler: Not installed
2025-09-10 12:06:41,042:INFO:             kaleido: 0.2.1
2025-09-10 12:06:41,042:INFO:           schemdraw: 0.15
2025-09-10 12:06:41,042:INFO:         statsmodels: 0.14.4
2025-09-10 12:06:41,042:INFO:              sktime: 0.26.0
2025-09-10 12:06:41,042:INFO:               tbats: 1.1.3
2025-09-10 12:06:41,042:INFO:            pmdarima: 2.0.4
2025-09-10 12:06:41,042:INFO:              psutil: 7.0.0
2025-09-10 12:06:41,042:INFO:          markupsafe: 3.0.2
2025-09-10 12:06:41,042:INFO:             pickle5: Not installed
2025-09-10 12:06:41,042:INFO:         cloudpickle: 3.1.1
2025-09-10 12:06:41,042:INFO:         deprecation: 2.1.0
2025-09-10 12:06:41,042:INFO:              xxhash: 3.5.0
2025-09-10 12:06:41,042:INFO:           wurlitzer: Not installed
2025-09-10 12:06:41,042:INFO:PyCaret optional dependencies:
2025-09-10 12:06:43,589:INFO:                shap: 0.44.1
2025-09-10 12:06:43,589:INFO:           interpret: 0.6.11
2025-09-10 12:06:43,589:INFO:                umap: 0.5.7
2025-09-10 12:06:43,589:INFO:     ydata_profiling: 4.16.1
2025-09-10 12:06:43,589:INFO:  explainerdashboard: 0.5.1
2025-09-10 12:06:43,589:INFO:             autoviz: Not installed
2025-09-10 12:06:43,589:INFO:           fairlearn: 0.7.0
2025-09-10 12:06:43,589:INFO:          deepchecks: Not installed
2025-09-10 12:06:43,589:INFO:             xgboost: 3.0.2
2025-09-10 12:06:43,589:INFO:            catboost: 1.2.8
2025-09-10 12:06:43,589:INFO:              kmodes: 0.12.2
2025-09-10 12:06:43,589:INFO:             mlxtend: 0.23.4
2025-09-10 12:06:43,589:INFO:       statsforecast: 1.5.0
2025-09-10 12:06:43,589:INFO:        tune_sklearn: Not installed
2025-09-10 12:06:43,589:INFO:                 ray: Not installed
2025-09-10 12:06:43,589:INFO:            hyperopt: 0.2.7
2025-09-10 12:06:43,589:INFO:              optuna: 4.3.0
2025-09-10 12:06:43,589:INFO:               skopt: 0.10.2
2025-09-10 12:06:43,589:INFO:              mlflow: 3.1.0
2025-09-10 12:06:43,589:INFO:              gradio: 5.33.1
2025-09-10 12:06:43,589:INFO:             fastapi: 0.115.12
2025-09-10 12:06:43,589:INFO:             uvicorn: 0.34.3
2025-09-10 12:06:43,589:INFO:              m2cgen: 0.10.0
2025-09-10 12:06:43,589:INFO:           evidently: 0.4.40
2025-09-10 12:06:43,589:INFO:               fugue: 0.8.7
2025-09-10 12:06:43,589:INFO:           streamlit: 1.45.1
2025-09-10 12:06:43,589:INFO:             prophet: 1.1.7
2025-09-10 12:06:43,589:INFO:None
2025-09-10 12:06:43,589:INFO:Set up data.
2025-09-10 12:06:43,605:INFO:Set up folding strategy.
2025-09-10 12:06:43,605:INFO:Set up train/test split.
2025-09-10 12:06:43,621:INFO:Set up index.
2025-09-10 12:06:43,622:INFO:Assigning column types.
2025-09-10 12:06:43,625:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-09-10 12:06:43,649:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 12:06:43,657:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-10 12:06:43,679:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 12:06:43,679:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 12:06:43,744:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 12:06:43,744:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-10 12:06:43,760:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 12:06:43,762:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 12:06:43,764:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-09-10 12:06:43,793:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-10 12:06:43,809:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 12:06:43,811:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 12:06:43,836:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-10 12:06:43,852:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 12:06:43,853:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 12:06:43,854:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-09-10 12:06:43,886:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 12:06:43,886:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 12:06:43,936:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 12:06:43,936:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 12:06:43,936:INFO:Preparing preprocessing pipeline...
2025-09-10 12:06:43,936:INFO:Set up date feature engineering.
2025-09-10 12:06:43,936:INFO:Set up simple imputation.
2025-09-10 12:06:43,936:INFO:Set up encoding of ordinal features.
2025-09-10 12:06:43,936:INFO:Set up encoding of categorical features.
2025-09-10 12:06:43,936:INFO:Set up removing multicollinearity.
2025-09-10 12:06:43,936:INFO:Set up imbalanced handling.
2025-09-10 12:06:43,936:INFO:Set up feature normalization.
2025-09-10 12:06:44,370:INFO:Finished creating preprocessing pipeline.
2025-09-10 12:06:44,386:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\SBM_ME~1\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['TimeStart', 'TimeStop',
                                             'ProductionDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Mpw', 'QtyOutput', 'Qt...
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=RandomOverSampler(random_state=42,
                                                                                          sampling_strategy='auto',
                                                                                          shrinkage=None)))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-09-10 12:06:44,386:INFO:Creating final display dataframe.
2025-09-10 12:06:44,969:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3           Original data shape   
4        Transformed data shape   
5   Transformed train set shape   
6    Transformed test set shape   
7              Numeric features   
8                 Date features   
9          Categorical features   
10                   Preprocess   
11              Imputation type   
12           Numeric imputation   
13       Categorical imputation   
14     Maximum one-hot encoding   
15              Encoding method   
16     Remove multicollinearity   
17  Multicollinearity threshold   
18                Fix imbalance   
19         Fix imbalance method   
20                    Normalize   
21             Normalize method   
22               Fold Generator   
23                  Fold Number   
24                     CPU Jobs   
25                      Use GPU   
26               Log Experiment   
27              Experiment Name   
28                          USI   

                                                Value  
0                                                  42  
1                                                isNC  
2                                              Binary  
3                                          (5647, 24)  
4                                          (9121, 88)  
5                                          (7426, 88)  
6                                          (1695, 88)  
7                                                   4  
8                                                   3  
9                                                  16  
10                                               True  
11                                             simple  
12                                               mean  
13                                               mode  
14                                                 25  
15                                               None  
16                                               True  
17                                               0.95  
18                                               True  
19  RandomOverSampler(random_state=42, sampling_st...  
20                                               True  
21                                             zscore  
22                                    StratifiedKFold  
23                                                 10  
24                                                 -1  
25                                              False  
26                                              False  
27                                   clf-default-name  
28                                               4a01  
2025-09-10 12:06:45,033:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 12:06:45,035:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 12:06:45,080:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 12:06:45,081:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 12:06:45,083:INFO:setup() successfully completed in 4.48s...............
2025-09-10 12:06:45,083:INFO:Initializing compare_models()
2025-09-10 12:06:45,083:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249FDD02F10>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000249FDD02F10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-09-10 12:06:45,083:INFO:Checking exceptions
2025-09-10 12:06:45,087:INFO:Preparing display monitor
2025-09-10 12:06:45,112:INFO:Initializing Logistic Regression
2025-09-10 12:06:45,113:INFO:Total runtime is 1.6729036966959637e-05 minutes
2025-09-10 12:06:45,119:INFO:SubProcess create_model() called ==================================
2025-09-10 12:06:45,120:INFO:Initializing create_model()
2025-09-10 12:06:45,120:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249FDD02F10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024987110710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 12:06:45,120:INFO:Checking exceptions
2025-09-10 12:06:45,120:INFO:Importing libraries
2025-09-10 12:06:45,120:INFO:Copying training dataset
2025-09-10 12:06:45,125:INFO:Defining folds
2025-09-10 12:06:45,125:INFO:Declaring metric variables
2025-09-10 12:06:45,134:INFO:Importing untrained model
2025-09-10 12:06:45,146:INFO:Logistic Regression Imported successfully
2025-09-10 12:06:45,164:INFO:Starting cross validation
2025-09-10 12:06:45,169:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 12:06:52,254:INFO:Calculating mean and std
2025-09-10 12:06:52,255:INFO:Creating metrics dataframe
2025-09-10 12:06:52,259:INFO:Uploading results into container
2025-09-10 12:06:52,260:INFO:Uploading model into container now
2025-09-10 12:06:52,260:INFO:_master_model_container: 1
2025-09-10 12:06:52,261:INFO:_display_container: 2
2025-09-10 12:06:52,261:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-09-10 12:06:52,262:INFO:create_model() successfully completed......................................
2025-09-10 12:06:52,368:INFO:SubProcess create_model() end ==================================
2025-09-10 12:06:52,368:INFO:Creating metrics dataframe
2025-09-10 12:06:52,368:INFO:Initializing K Neighbors Classifier
2025-09-10 12:06:52,368:INFO:Total runtime is 0.12093562682469686 minutes
2025-09-10 12:06:52,384:INFO:SubProcess create_model() called ==================================
2025-09-10 12:06:52,384:INFO:Initializing create_model()
2025-09-10 12:06:52,384:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249FDD02F10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024987110710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 12:06:52,384:INFO:Checking exceptions
2025-09-10 12:06:52,384:INFO:Importing libraries
2025-09-10 12:06:52,384:INFO:Copying training dataset
2025-09-10 12:06:52,389:INFO:Defining folds
2025-09-10 12:06:52,391:INFO:Declaring metric variables
2025-09-10 12:06:52,395:INFO:Importing untrained model
2025-09-10 12:06:52,402:INFO:K Neighbors Classifier Imported successfully
2025-09-10 12:06:52,415:INFO:Starting cross validation
2025-09-10 12:06:52,420:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 12:06:56,122:INFO:Calculating mean and std
2025-09-10 12:06:56,122:INFO:Creating metrics dataframe
2025-09-10 12:06:56,128:INFO:Uploading results into container
2025-09-10 12:06:56,128:INFO:Uploading model into container now
2025-09-10 12:06:56,128:INFO:_master_model_container: 2
2025-09-10 12:06:56,128:INFO:_display_container: 2
2025-09-10 12:06:56,128:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-09-10 12:06:56,128:INFO:create_model() successfully completed......................................
2025-09-10 12:06:56,239:INFO:SubProcess create_model() end ==================================
2025-09-10 12:06:56,239:INFO:Creating metrics dataframe
2025-09-10 12:06:56,256:INFO:Initializing Naive Bayes
2025-09-10 12:06:56,256:INFO:Total runtime is 0.18573482433954874 minutes
2025-09-10 12:06:56,256:INFO:SubProcess create_model() called ==================================
2025-09-10 12:06:56,256:INFO:Initializing create_model()
2025-09-10 12:06:56,256:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249FDD02F10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024987110710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 12:06:56,256:INFO:Checking exceptions
2025-09-10 12:06:56,256:INFO:Importing libraries
2025-09-10 12:06:56,256:INFO:Copying training dataset
2025-09-10 12:06:56,269:INFO:Defining folds
2025-09-10 12:06:56,269:INFO:Declaring metric variables
2025-09-10 12:06:56,275:INFO:Importing untrained model
2025-09-10 12:06:56,275:INFO:Naive Bayes Imported successfully
2025-09-10 12:06:56,294:INFO:Starting cross validation
2025-09-10 12:06:56,299:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 12:06:57,322:INFO:Calculating mean and std
2025-09-10 12:06:57,322:INFO:Creating metrics dataframe
2025-09-10 12:06:57,322:INFO:Uploading results into container
2025-09-10 12:06:57,322:INFO:Uploading model into container now
2025-09-10 12:06:57,322:INFO:_master_model_container: 3
2025-09-10 12:06:57,322:INFO:_display_container: 2
2025-09-10 12:06:57,322:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-09-10 12:06:57,322:INFO:create_model() successfully completed......................................
2025-09-10 12:06:57,437:INFO:SubProcess create_model() end ==================================
2025-09-10 12:06:57,437:INFO:Creating metrics dataframe
2025-09-10 12:06:57,443:INFO:Initializing Decision Tree Classifier
2025-09-10 12:06:57,443:INFO:Total runtime is 0.20551809072494506 minutes
2025-09-10 12:06:57,447:INFO:SubProcess create_model() called ==================================
2025-09-10 12:06:57,447:INFO:Initializing create_model()
2025-09-10 12:06:57,448:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249FDD02F10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024987110710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 12:06:57,448:INFO:Checking exceptions
2025-09-10 12:06:57,448:INFO:Importing libraries
2025-09-10 12:06:57,448:INFO:Copying training dataset
2025-09-10 12:06:57,452:INFO:Defining folds
2025-09-10 12:06:57,452:INFO:Declaring metric variables
2025-09-10 12:06:57,457:INFO:Importing untrained model
2025-09-10 12:06:57,457:INFO:Decision Tree Classifier Imported successfully
2025-09-10 12:06:57,475:INFO:Starting cross validation
2025-09-10 12:06:57,477:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 12:06:58,394:INFO:Calculating mean and std
2025-09-10 12:06:58,394:INFO:Creating metrics dataframe
2025-09-10 12:06:58,394:INFO:Uploading results into container
2025-09-10 12:06:58,394:INFO:Uploading model into container now
2025-09-10 12:06:58,394:INFO:_master_model_container: 4
2025-09-10 12:06:58,394:INFO:_display_container: 2
2025-09-10 12:06:58,394:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-09-10 12:06:58,394:INFO:create_model() successfully completed......................................
2025-09-10 12:06:58,500:INFO:SubProcess create_model() end ==================================
2025-09-10 12:06:58,500:INFO:Creating metrics dataframe
2025-09-10 12:06:58,517:INFO:Initializing SVM - Linear Kernel
2025-09-10 12:06:58,517:INFO:Total runtime is 0.22341509262720743 minutes
2025-09-10 12:06:58,522:INFO:SubProcess create_model() called ==================================
2025-09-10 12:06:58,522:INFO:Initializing create_model()
2025-09-10 12:06:58,522:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249FDD02F10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024987110710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 12:06:58,522:INFO:Checking exceptions
2025-09-10 12:06:58,522:INFO:Importing libraries
2025-09-10 12:06:58,522:INFO:Copying training dataset
2025-09-10 12:06:58,527:INFO:Defining folds
2025-09-10 12:06:58,527:INFO:Declaring metric variables
2025-09-10 12:06:58,532:INFO:Importing untrained model
2025-09-10 12:06:58,537:INFO:SVM - Linear Kernel Imported successfully
2025-09-10 12:06:58,550:INFO:Starting cross validation
2025-09-10 12:06:58,554:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 12:06:59,500:INFO:Calculating mean and std
2025-09-10 12:06:59,500:INFO:Creating metrics dataframe
2025-09-10 12:06:59,500:INFO:Uploading results into container
2025-09-10 12:06:59,500:INFO:Uploading model into container now
2025-09-10 12:06:59,500:INFO:_master_model_container: 5
2025-09-10 12:06:59,500:INFO:_display_container: 2
2025-09-10 12:06:59,500:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-09-10 12:06:59,500:INFO:create_model() successfully completed......................................
2025-09-10 12:06:59,613:INFO:SubProcess create_model() end ==================================
2025-09-10 12:06:59,613:INFO:Creating metrics dataframe
2025-09-10 12:06:59,620:INFO:Initializing Ridge Classifier
2025-09-10 12:06:59,620:INFO:Total runtime is 0.24180304209391276 minutes
2025-09-10 12:06:59,625:INFO:SubProcess create_model() called ==================================
2025-09-10 12:06:59,625:INFO:Initializing create_model()
2025-09-10 12:06:59,625:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249FDD02F10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024987110710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 12:06:59,625:INFO:Checking exceptions
2025-09-10 12:06:59,625:INFO:Importing libraries
2025-09-10 12:06:59,625:INFO:Copying training dataset
2025-09-10 12:06:59,630:INFO:Defining folds
2025-09-10 12:06:59,630:INFO:Declaring metric variables
2025-09-10 12:06:59,639:INFO:Importing untrained model
2025-09-10 12:06:59,646:INFO:Ridge Classifier Imported successfully
2025-09-10 12:06:59,661:INFO:Starting cross validation
2025-09-10 12:06:59,661:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 12:07:00,656:INFO:Calculating mean and std
2025-09-10 12:07:00,656:INFO:Creating metrics dataframe
2025-09-10 12:07:00,656:INFO:Uploading results into container
2025-09-10 12:07:00,656:INFO:Uploading model into container now
2025-09-10 12:07:00,656:INFO:_master_model_container: 6
2025-09-10 12:07:00,656:INFO:_display_container: 2
2025-09-10 12:07:00,656:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-09-10 12:07:00,656:INFO:create_model() successfully completed......................................
2025-09-10 12:07:00,754:INFO:SubProcess create_model() end ==================================
2025-09-10 12:07:00,754:INFO:Creating metrics dataframe
2025-09-10 12:07:00,770:INFO:Initializing Random Forest Classifier
2025-09-10 12:07:00,770:INFO:Total runtime is 0.26096588373184204 minutes
2025-09-10 12:07:00,770:INFO:SubProcess create_model() called ==================================
2025-09-10 12:07:00,770:INFO:Initializing create_model()
2025-09-10 12:07:00,770:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249FDD02F10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024987110710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 12:07:00,770:INFO:Checking exceptions
2025-09-10 12:07:00,770:INFO:Importing libraries
2025-09-10 12:07:00,770:INFO:Copying training dataset
2025-09-10 12:07:00,770:INFO:Defining folds
2025-09-10 12:07:00,770:INFO:Declaring metric variables
2025-09-10 12:07:00,786:INFO:Importing untrained model
2025-09-10 12:07:00,787:INFO:Random Forest Classifier Imported successfully
2025-09-10 12:07:00,806:INFO:Starting cross validation
2025-09-10 12:07:00,808:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 12:07:02,247:INFO:Calculating mean and std
2025-09-10 12:07:02,247:INFO:Creating metrics dataframe
2025-09-10 12:07:02,247:INFO:Uploading results into container
2025-09-10 12:07:02,247:INFO:Uploading model into container now
2025-09-10 12:07:02,247:INFO:_master_model_container: 7
2025-09-10 12:07:02,247:INFO:_display_container: 2
2025-09-10 12:07:02,247:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-09-10 12:07:02,247:INFO:create_model() successfully completed......................................
2025-09-10 12:07:02,357:INFO:SubProcess create_model() end ==================================
2025-09-10 12:07:02,357:INFO:Creating metrics dataframe
2025-09-10 12:07:02,363:INFO:Initializing Quadratic Discriminant Analysis
2025-09-10 12:07:02,363:INFO:Total runtime is 0.2875261425971985 minutes
2025-09-10 12:07:02,367:INFO:SubProcess create_model() called ==================================
2025-09-10 12:07:02,367:INFO:Initializing create_model()
2025-09-10 12:07:02,367:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249FDD02F10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024987110710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 12:07:02,368:INFO:Checking exceptions
2025-09-10 12:07:02,369:INFO:Importing libraries
2025-09-10 12:07:02,369:INFO:Copying training dataset
2025-09-10 12:07:02,369:INFO:Defining folds
2025-09-10 12:07:02,369:INFO:Declaring metric variables
2025-09-10 12:07:02,379:INFO:Importing untrained model
2025-09-10 12:07:02,385:INFO:Quadratic Discriminant Analysis Imported successfully
2025-09-10 12:07:02,396:INFO:Starting cross validation
2025-09-10 12:07:02,398:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 12:07:03,185:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-10 12:07:03,215:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-10 12:07:03,227:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-10 12:07:03,232:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-10 12:07:03,232:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-10 12:07:03,255:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-10 12:07:03,286:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-10 12:07:03,286:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-09-10 12:07:03,431:INFO:Calculating mean and std
2025-09-10 12:07:03,432:INFO:Creating metrics dataframe
2025-09-10 12:07:03,435:INFO:Uploading results into container
2025-09-10 12:07:03,435:INFO:Uploading model into container now
2025-09-10 12:07:03,435:INFO:_master_model_container: 8
2025-09-10 12:07:03,435:INFO:_display_container: 2
2025-09-10 12:07:03,435:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-09-10 12:07:03,435:INFO:create_model() successfully completed......................................
2025-09-10 12:07:03,544:INFO:SubProcess create_model() end ==================================
2025-09-10 12:07:03,544:INFO:Creating metrics dataframe
2025-09-10 12:07:03,552:INFO:Initializing Ada Boost Classifier
2025-09-10 12:07:03,552:INFO:Total runtime is 0.3073313037554423 minutes
2025-09-10 12:07:03,552:INFO:SubProcess create_model() called ==================================
2025-09-10 12:07:03,552:INFO:Initializing create_model()
2025-09-10 12:07:03,552:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249FDD02F10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024987110710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 12:07:03,552:INFO:Checking exceptions
2025-09-10 12:07:03,552:INFO:Importing libraries
2025-09-10 12:07:03,552:INFO:Copying training dataset
2025-09-10 12:07:03,552:INFO:Defining folds
2025-09-10 12:07:03,552:INFO:Declaring metric variables
2025-09-10 12:07:03,569:INFO:Importing untrained model
2025-09-10 12:07:03,575:INFO:Ada Boost Classifier Imported successfully
2025-09-10 12:07:03,586:INFO:Starting cross validation
2025-09-10 12:07:03,588:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 12:07:04,356:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-10 12:07:04,408:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-10 12:07:04,449:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-10 12:07:04,462:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-10 12:07:04,474:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-10 12:07:04,483:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-10 12:07:04,483:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-10 12:07:04,490:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-10 12:07:04,510:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-10 12:07:04,526:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-09-10 12:07:04,649:INFO:Calculating mean and std
2025-09-10 12:07:04,649:INFO:Creating metrics dataframe
2025-09-10 12:07:04,651:INFO:Uploading results into container
2025-09-10 12:07:04,652:INFO:Uploading model into container now
2025-09-10 12:07:04,652:INFO:_master_model_container: 9
2025-09-10 12:07:04,652:INFO:_display_container: 2
2025-09-10 12:07:04,652:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-09-10 12:07:04,652:INFO:create_model() successfully completed......................................
2025-09-10 12:07:04,754:INFO:SubProcess create_model() end ==================================
2025-09-10 12:07:04,754:INFO:Creating metrics dataframe
2025-09-10 12:07:04,754:INFO:Initializing Gradient Boosting Classifier
2025-09-10 12:07:04,754:INFO:Total runtime is 0.3273715893427531 minutes
2025-09-10 12:07:04,770:INFO:SubProcess create_model() called ==================================
2025-09-10 12:07:04,770:INFO:Initializing create_model()
2025-09-10 12:07:04,770:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249FDD02F10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024987110710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 12:07:04,770:INFO:Checking exceptions
2025-09-10 12:07:04,770:INFO:Importing libraries
2025-09-10 12:07:04,770:INFO:Copying training dataset
2025-09-10 12:07:04,776:INFO:Defining folds
2025-09-10 12:07:04,776:INFO:Declaring metric variables
2025-09-10 12:07:04,781:INFO:Importing untrained model
2025-09-10 12:07:04,789:INFO:Gradient Boosting Classifier Imported successfully
2025-09-10 12:07:04,801:INFO:Starting cross validation
2025-09-10 12:07:04,805:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 12:07:06,371:INFO:Calculating mean and std
2025-09-10 12:07:06,371:INFO:Creating metrics dataframe
2025-09-10 12:07:06,371:INFO:Uploading results into container
2025-09-10 12:07:06,371:INFO:Uploading model into container now
2025-09-10 12:07:06,371:INFO:_master_model_container: 10
2025-09-10 12:07:06,371:INFO:_display_container: 2
2025-09-10 12:07:06,371:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-09-10 12:07:06,371:INFO:create_model() successfully completed......................................
2025-09-10 12:07:06,477:INFO:SubProcess create_model() end ==================================
2025-09-10 12:07:06,477:INFO:Creating metrics dataframe
2025-09-10 12:07:06,483:INFO:Initializing Linear Discriminant Analysis
2025-09-10 12:07:06,483:INFO:Total runtime is 0.3561831911404928 minutes
2025-09-10 12:07:06,484:INFO:SubProcess create_model() called ==================================
2025-09-10 12:07:06,484:INFO:Initializing create_model()
2025-09-10 12:07:06,484:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249FDD02F10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024987110710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 12:07:06,484:INFO:Checking exceptions
2025-09-10 12:07:06,484:INFO:Importing libraries
2025-09-10 12:07:06,484:INFO:Copying training dataset
2025-09-10 12:07:06,493:INFO:Defining folds
2025-09-10 12:07:06,493:INFO:Declaring metric variables
2025-09-10 12:07:06,498:INFO:Importing untrained model
2025-09-10 12:07:06,506:INFO:Linear Discriminant Analysis Imported successfully
2025-09-10 12:07:06,518:INFO:Starting cross validation
2025-09-10 12:07:06,520:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 12:07:07,703:INFO:Calculating mean and std
2025-09-10 12:07:07,703:INFO:Creating metrics dataframe
2025-09-10 12:07:07,703:INFO:Uploading results into container
2025-09-10 12:07:07,703:INFO:Uploading model into container now
2025-09-10 12:07:07,703:INFO:_master_model_container: 11
2025-09-10 12:07:07,703:INFO:_display_container: 2
2025-09-10 12:07:07,703:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-09-10 12:07:07,703:INFO:create_model() successfully completed......................................
2025-09-10 12:07:07,814:INFO:SubProcess create_model() end ==================================
2025-09-10 12:07:07,814:INFO:Creating metrics dataframe
2025-09-10 12:07:07,824:INFO:Initializing Extra Trees Classifier
2025-09-10 12:07:07,824:INFO:Total runtime is 0.37853644291559857 minutes
2025-09-10 12:07:07,828:INFO:SubProcess create_model() called ==================================
2025-09-10 12:07:07,828:INFO:Initializing create_model()
2025-09-10 12:07:07,828:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249FDD02F10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024987110710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 12:07:07,828:INFO:Checking exceptions
2025-09-10 12:07:07,829:INFO:Importing libraries
2025-09-10 12:07:07,829:INFO:Copying training dataset
2025-09-10 12:07:07,836:INFO:Defining folds
2025-09-10 12:07:07,837:INFO:Declaring metric variables
2025-09-10 12:07:07,841:INFO:Importing untrained model
2025-09-10 12:07:07,841:INFO:Extra Trees Classifier Imported successfully
2025-09-10 12:07:07,857:INFO:Starting cross validation
2025-09-10 12:07:07,861:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 12:07:09,319:INFO:Calculating mean and std
2025-09-10 12:07:09,321:INFO:Creating metrics dataframe
2025-09-10 12:07:09,323:INFO:Uploading results into container
2025-09-10 12:07:09,323:INFO:Uploading model into container now
2025-09-10 12:07:09,324:INFO:_master_model_container: 12
2025-09-10 12:07:09,324:INFO:_display_container: 2
2025-09-10 12:07:09,324:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-09-10 12:07:09,324:INFO:create_model() successfully completed......................................
2025-09-10 12:07:09,431:INFO:SubProcess create_model() end ==================================
2025-09-10 12:07:09,431:INFO:Creating metrics dataframe
2025-09-10 12:07:09,440:INFO:Initializing Extreme Gradient Boosting
2025-09-10 12:07:09,440:INFO:Total runtime is 0.4054720004399618 minutes
2025-09-10 12:07:09,440:INFO:SubProcess create_model() called ==================================
2025-09-10 12:07:09,440:INFO:Initializing create_model()
2025-09-10 12:07:09,440:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249FDD02F10>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024987110710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 12:07:09,440:INFO:Checking exceptions
2025-09-10 12:07:09,440:INFO:Importing libraries
2025-09-10 12:07:09,440:INFO:Copying training dataset
2025-09-10 12:07:09,440:INFO:Defining folds
2025-09-10 12:07:09,440:INFO:Declaring metric variables
2025-09-10 12:07:09,456:INFO:Importing untrained model
2025-09-10 12:07:09,465:INFO:Extreme Gradient Boosting Imported successfully
2025-09-10 12:07:09,479:INFO:Starting cross validation
2025-09-10 12:07:09,483:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 12:07:10,721:INFO:Calculating mean and std
2025-09-10 12:07:10,721:INFO:Creating metrics dataframe
2025-09-10 12:07:10,721:INFO:Uploading results into container
2025-09-10 12:07:10,721:INFO:Uploading model into container now
2025-09-10 12:07:10,721:INFO:_master_model_container: 13
2025-09-10 12:07:10,721:INFO:_display_container: 2
2025-09-10 12:07:10,721:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-09-10 12:07:10,721:INFO:create_model() successfully completed......................................
2025-09-10 12:07:10,835:INFO:SubProcess create_model() end ==================================
2025-09-10 12:07:10,835:INFO:Creating metrics dataframe
2025-09-10 12:07:10,836:INFO:Initializing Light Gradient Boosting Machine
2025-09-10 12:07:10,836:INFO:Total runtime is 0.4287322640419007 minutes
2025-09-10 12:07:10,836:INFO:SubProcess create_model() called ==================================
2025-09-10 12:07:10,836:INFO:Initializing create_model()
2025-09-10 12:07:10,836:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249FDD02F10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024987110710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 12:07:10,836:INFO:Checking exceptions
2025-09-10 12:07:10,836:INFO:Importing libraries
2025-09-10 12:07:10,836:INFO:Copying training dataset
2025-09-10 12:07:10,851:INFO:Defining folds
2025-09-10 12:07:10,851:INFO:Declaring metric variables
2025-09-10 12:07:10,860:INFO:Importing untrained model
2025-09-10 12:07:10,860:INFO:Light Gradient Boosting Machine Imported successfully
2025-09-10 12:07:10,878:INFO:Starting cross validation
2025-09-10 12:07:10,883:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 12:07:12,446:INFO:Calculating mean and std
2025-09-10 12:07:12,447:INFO:Creating metrics dataframe
2025-09-10 12:07:12,450:INFO:Uploading results into container
2025-09-10 12:07:12,450:INFO:Uploading model into container now
2025-09-10 12:07:12,451:INFO:_master_model_container: 14
2025-09-10 12:07:12,451:INFO:_display_container: 2
2025-09-10 12:07:12,453:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-09-10 12:07:12,453:INFO:create_model() successfully completed......................................
2025-09-10 12:07:12,582:INFO:SubProcess create_model() end ==================================
2025-09-10 12:07:12,582:INFO:Creating metrics dataframe
2025-09-10 12:07:12,591:INFO:Initializing CatBoost Classifier
2025-09-10 12:07:12,591:INFO:Total runtime is 0.45799128611882534 minutes
2025-09-10 12:07:12,591:INFO:SubProcess create_model() called ==================================
2025-09-10 12:07:12,591:INFO:Initializing create_model()
2025-09-10 12:07:12,591:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249FDD02F10>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024987110710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 12:07:12,591:INFO:Checking exceptions
2025-09-10 12:07:12,597:INFO:Importing libraries
2025-09-10 12:07:12,597:INFO:Copying training dataset
2025-09-10 12:07:12,604:INFO:Defining folds
2025-09-10 12:07:12,604:INFO:Declaring metric variables
2025-09-10 12:07:12,610:INFO:Importing untrained model
2025-09-10 12:07:12,616:INFO:CatBoost Classifier Imported successfully
2025-09-10 12:07:12,630:INFO:Starting cross validation
2025-09-10 12:07:12,633:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 12:07:26,037:INFO:Calculating mean and std
2025-09-10 12:07:26,037:INFO:Creating metrics dataframe
2025-09-10 12:07:26,037:INFO:Uploading results into container
2025-09-10 12:07:26,037:INFO:Uploading model into container now
2025-09-10 12:07:26,037:INFO:_master_model_container: 15
2025-09-10 12:07:26,037:INFO:_display_container: 2
2025-09-10 12:07:26,037:INFO:<catboost.core.CatBoostClassifier object at 0x0000024989387810>
2025-09-10 12:07:26,037:INFO:create_model() successfully completed......................................
2025-09-10 12:07:26,151:INFO:SubProcess create_model() end ==================================
2025-09-10 12:07:26,151:INFO:Creating metrics dataframe
2025-09-10 12:07:26,174:INFO:Initializing Dummy Classifier
2025-09-10 12:07:26,174:INFO:Total runtime is 0.6843728542327882 minutes
2025-09-10 12:07:26,179:INFO:SubProcess create_model() called ==================================
2025-09-10 12:07:26,180:INFO:Initializing create_model()
2025-09-10 12:07:26,180:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249FDD02F10>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024987110710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 12:07:26,180:INFO:Checking exceptions
2025-09-10 12:07:26,180:INFO:Importing libraries
2025-09-10 12:07:26,180:INFO:Copying training dataset
2025-09-10 12:07:26,187:INFO:Defining folds
2025-09-10 12:07:26,187:INFO:Declaring metric variables
2025-09-10 12:07:26,187:INFO:Importing untrained model
2025-09-10 12:07:26,187:INFO:Dummy Classifier Imported successfully
2025-09-10 12:07:26,210:INFO:Starting cross validation
2025-09-10 12:07:26,214:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 12:07:27,220:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-10 12:07:27,221:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-10 12:07:27,261:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-10 12:07:27,280:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-10 12:07:27,298:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-10 12:07:27,322:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-10 12:07:27,382:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-10 12:07:27,411:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-10 12:07:27,420:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-10 12:07:27,427:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-09-10 12:07:27,437:INFO:Calculating mean and std
2025-09-10 12:07:27,439:INFO:Creating metrics dataframe
2025-09-10 12:07:27,443:INFO:Uploading results into container
2025-09-10 12:07:27,444:INFO:Uploading model into container now
2025-09-10 12:07:27,445:INFO:_master_model_container: 16
2025-09-10 12:07:27,445:INFO:_display_container: 2
2025-09-10 12:07:27,445:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-09-10 12:07:27,445:INFO:create_model() successfully completed......................................
2025-09-10 12:07:27,605:INFO:SubProcess create_model() end ==================================
2025-09-10 12:07:27,605:INFO:Creating metrics dataframe
2025-09-10 12:07:27,621:INFO:Initializing create_model()
2025-09-10 12:07:27,621:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249FDD02F10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 12:07:27,621:INFO:Checking exceptions
2025-09-10 12:07:27,621:INFO:Importing libraries
2025-09-10 12:07:27,621:INFO:Copying training dataset
2025-09-10 12:07:27,629:INFO:Defining folds
2025-09-10 12:07:27,629:INFO:Declaring metric variables
2025-09-10 12:07:27,629:INFO:Importing untrained model
2025-09-10 12:07:27,629:INFO:Declaring custom model
2025-09-10 12:07:27,629:INFO:Logistic Regression Imported successfully
2025-09-10 12:07:27,635:INFO:Cross validation set to False
2025-09-10 12:07:27,635:INFO:Fitting Model
2025-09-10 12:07:27,976:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-09-10 12:07:27,976:INFO:create_model() successfully completed......................................
2025-09-10 12:07:28,116:INFO:_master_model_container: 16
2025-09-10 12:07:28,116:INFO:_display_container: 2
2025-09-10 12:07:28,116:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-09-10 12:07:28,117:INFO:compare_models() successfully completed......................................
2025-09-10 12:07:28,117:INFO:Initializing finalize_model()
2025-09-10 12:07:28,119:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249FDD02F10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-09-10 12:07:28,119:INFO:Finalizing LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-09-10 12:07:28,122:INFO:Initializing create_model()
2025-09-10 12:07:28,122:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000249FDD02F10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 12:07:28,122:INFO:Checking exceptions
2025-09-10 12:07:28,124:INFO:Importing libraries
2025-09-10 12:07:28,124:INFO:Copying training dataset
2025-09-10 12:07:28,126:INFO:Defining folds
2025-09-10 12:07:28,127:INFO:Declaring metric variables
2025-09-10 12:07:28,128:INFO:Importing untrained model
2025-09-10 12:07:28,128:INFO:Declaring custom model
2025-09-10 12:07:28,128:INFO:Logistic Regression Imported successfully
2025-09-10 12:07:28,131:INFO:Cross validation set to False
2025-09-10 12:07:28,131:INFO:Fitting Model
2025-09-10 14:17:25,894:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 14:17:25,896:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 14:17:25,896:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 14:17:25,896:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 14:44:08,107:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 14:44:08,108:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 14:44:08,108:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 14:44:08,108:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 15:02:05,821:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 15:02:05,821:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 15:02:05,821:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 15:02:05,821:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 15:32:09,268:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 15:32:09,268:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 15:32:09,268:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 15:32:09,268:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 15:44:54,215:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 15:44:54,215:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 15:44:54,215:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 15:44:54,215:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 16:31:06,386:INFO:PyCaret ClassificationExperiment
2025-09-10 16:31:06,386:INFO:Logging name: clf-default-name
2025-09-10 16:31:06,386:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-09-10 16:31:06,386:INFO:version 3.3.2
2025-09-10 16:31:06,386:INFO:Initializing setup()
2025-09-10 16:31:06,386:INFO:self.USI: d82d
2025-09-10 16:31:06,386:INFO:self._variable_keys: {'gpu_param', 'y_train', '_ml_usecase', 'fold_generator', 'html_param', 'fold_groups_param', 'data', 'memory', 'logging_param', '_available_plots', 'y_test', 'pipeline', 'n_jobs_param', 'y', 'fix_imbalance', 'gpu_n_jobs_param', 'X_test', 'exp_name_log', 'idx', 'fold_shuffle_param', 'log_plots_param', 'X', 'X_train', 'seed', 'is_multiclass', 'target_param', 'USI', 'exp_id'}
2025-09-10 16:31:06,386:INFO:Checking environment
2025-09-10 16:31:06,386:INFO:python_version: 3.11.10
2025-09-10 16:31:06,386:INFO:python_build: ('main', 'Oct  3 2024 07:22:26')
2025-09-10 16:31:06,386:INFO:machine: AMD64
2025-09-10 16:31:06,386:INFO:platform: Windows-10-10.0.26100-SP0
2025-09-10 16:31:06,398:INFO:Memory: svmem(total=16837152768, available=3827429376, percent=77.3, used=13009723392, free=3827429376)
2025-09-10 16:31:06,398:INFO:Physical Core: 10
2025-09-10 16:31:06,398:INFO:Logical Core: 12
2025-09-10 16:31:06,398:INFO:Checking libraries
2025-09-10 16:31:06,398:INFO:System:
2025-09-10 16:31:06,398:INFO:    python: 3.11.10 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:26) [MSC v.1929 64 bit (AMD64)]
2025-09-10 16:31:06,398:INFO:executable: c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\python.exe
2025-09-10 16:31:06,398:INFO:   machine: Windows-10-10.0.26100-SP0
2025-09-10 16:31:06,398:INFO:PyCaret required dependencies:
2025-09-10 16:31:06,825:INFO:                 pip: 24.2
2025-09-10 16:31:06,825:INFO:          setuptools: 75.1.0
2025-09-10 16:31:06,825:INFO:             pycaret: 3.3.2
2025-09-10 16:31:06,825:INFO:             IPython: 9.2.0
2025-09-10 16:31:06,825:INFO:          ipywidgets: 8.1.7
2025-09-10 16:31:06,825:INFO:                tqdm: 4.67.1
2025-09-10 16:31:06,825:INFO:               numpy: 1.24.4
2025-09-10 16:31:06,825:INFO:              pandas: 1.5.3
2025-09-10 16:31:06,825:INFO:              jinja2: 3.1.6
2025-09-10 16:31:06,826:INFO:               scipy: 1.11.4
2025-09-10 16:31:06,826:INFO:              joblib: 1.3.2
2025-09-10 16:31:06,826:INFO:             sklearn: 1.4.2
2025-09-10 16:31:06,826:INFO:                pyod: 2.0.5
2025-09-10 16:31:06,826:INFO:            imblearn: 0.13.0
2025-09-10 16:31:06,826:INFO:   category_encoders: 2.7.0
2025-09-10 16:31:06,826:INFO:            lightgbm: 4.6.0
2025-09-10 16:31:06,826:INFO:               numba: 0.61.0
2025-09-10 16:31:06,826:INFO:            requests: 2.32.3
2025-09-10 16:31:06,826:INFO:          matplotlib: 3.7.5
2025-09-10 16:31:06,826:INFO:          scikitplot: 0.3.7
2025-09-10 16:31:06,826:INFO:         yellowbrick: 1.5
2025-09-10 16:31:06,826:INFO:              plotly: 5.24.1
2025-09-10 16:31:06,826:INFO:    plotly-resampler: Not installed
2025-09-10 16:31:06,826:INFO:             kaleido: 0.2.1
2025-09-10 16:31:06,826:INFO:           schemdraw: 0.15
2025-09-10 16:31:06,826:INFO:         statsmodels: 0.14.4
2025-09-10 16:31:06,826:INFO:              sktime: 0.26.0
2025-09-10 16:31:06,826:INFO:               tbats: 1.1.3
2025-09-10 16:31:06,826:INFO:            pmdarima: 2.0.4
2025-09-10 16:31:06,826:INFO:              psutil: 7.0.0
2025-09-10 16:31:06,826:INFO:          markupsafe: 3.0.2
2025-09-10 16:31:06,826:INFO:             pickle5: Not installed
2025-09-10 16:31:06,826:INFO:         cloudpickle: 3.1.1
2025-09-10 16:31:06,826:INFO:         deprecation: 2.1.0
2025-09-10 16:31:06,826:INFO:              xxhash: 3.5.0
2025-09-10 16:31:06,826:INFO:           wurlitzer: Not installed
2025-09-10 16:31:06,826:INFO:PyCaret optional dependencies:
2025-09-10 16:31:10,175:INFO:                shap: 0.44.1
2025-09-10 16:31:10,175:INFO:           interpret: 0.6.11
2025-09-10 16:31:10,175:INFO:                umap: 0.5.7
2025-09-10 16:31:10,175:INFO:     ydata_profiling: 4.16.1
2025-09-10 16:31:10,175:INFO:  explainerdashboard: 0.5.1
2025-09-10 16:31:10,175:INFO:             autoviz: Not installed
2025-09-10 16:31:10,175:INFO:           fairlearn: 0.7.0
2025-09-10 16:31:10,175:INFO:          deepchecks: Not installed
2025-09-10 16:31:10,175:INFO:             xgboost: 3.0.2
2025-09-10 16:31:10,175:INFO:            catboost: 1.2.8
2025-09-10 16:31:10,175:INFO:              kmodes: 0.12.2
2025-09-10 16:31:10,175:INFO:             mlxtend: 0.23.4
2025-09-10 16:31:10,175:INFO:       statsforecast: 1.5.0
2025-09-10 16:31:10,175:INFO:        tune_sklearn: Not installed
2025-09-10 16:31:10,175:INFO:                 ray: Not installed
2025-09-10 16:31:10,175:INFO:            hyperopt: 0.2.7
2025-09-10 16:31:10,175:INFO:              optuna: 4.3.0
2025-09-10 16:31:10,175:INFO:               skopt: 0.10.2
2025-09-10 16:31:10,175:INFO:              mlflow: 3.1.0
2025-09-10 16:31:10,175:INFO:              gradio: 5.33.1
2025-09-10 16:31:10,175:INFO:             fastapi: 0.115.12
2025-09-10 16:31:10,175:INFO:             uvicorn: 0.34.3
2025-09-10 16:31:10,175:INFO:              m2cgen: 0.10.0
2025-09-10 16:31:10,175:INFO:           evidently: 0.4.40
2025-09-10 16:31:10,175:INFO:               fugue: 0.8.7
2025-09-10 16:31:10,175:INFO:           streamlit: 1.45.1
2025-09-10 16:31:10,175:INFO:             prophet: 1.1.7
2025-09-10 16:31:10,175:INFO:None
2025-09-10 16:31:10,175:INFO:Set up data.
2025-09-10 16:31:10,197:INFO:Set up folding strategy.
2025-09-10 16:31:10,198:INFO:Set up train/test split.
2025-09-10 16:31:10,212:INFO:Set up index.
2025-09-10 16:31:10,212:INFO:Assigning column types.
2025-09-10 16:31:10,216:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-09-10 16:31:10,241:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 16:31:10,244:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-10 16:31:10,268:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 16:31:10,270:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 16:31:10,398:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 16:31:10,398:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-10 16:31:10,415:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 16:31:10,415:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 16:31:10,415:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-09-10 16:31:10,448:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-10 16:31:10,465:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 16:31:10,465:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 16:31:10,498:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-10 16:31:10,515:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 16:31:10,515:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 16:31:10,515:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-09-10 16:31:10,548:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 16:31:10,548:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 16:31:10,598:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 16:31:10,598:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 16:31:10,598:INFO:Preparing preprocessing pipeline...
2025-09-10 16:31:10,598:INFO:Set up label encoding.
2025-09-10 16:31:10,598:INFO:Set up date feature engineering.
2025-09-10 16:31:10,598:INFO:Set up iterative imputation.
2025-09-10 16:31:10,598:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-09-10 16:31:10,615:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-09-10 16:31:10,615:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-09-10 16:31:10,648:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 16:31:10,665:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 16:31:10,665:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 16:31:10,715:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 16:31:10,715:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 16:31:10,746:INFO:Set up encoding of ordinal features.
2025-09-10 16:31:10,748:INFO:Set up encoding of categorical features.
2025-09-10 16:31:10,748:INFO:Set up removing multicollinearity.
2025-09-10 16:31:10,748:INFO:Set up removing outliers.
2025-09-10 16:31:10,748:INFO:Set up imbalanced handling.
2025-09-10 16:31:10,748:INFO:Set up column transformation.
2025-09-10 16:31:10,748:INFO:Set up feature normalization.
2025-09-10 16:31:10,748:INFO:Set up column name cleaning.
2025-09-10 16:39:16,475:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 16:39:16,475:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 16:39:16,475:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 16:39:16,475:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 16:40:11,881:INFO:PyCaret ClassificationExperiment
2025-09-10 16:40:11,881:INFO:Logging name: clf-default-name
2025-09-10 16:40:11,881:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-09-10 16:40:11,881:INFO:version 3.3.2
2025-09-10 16:40:11,881:INFO:Initializing setup()
2025-09-10 16:40:11,881:INFO:self.USI: c276
2025-09-10 16:40:11,881:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y', 'data', 'X_test', 'USI', 'html_param', 'target_param', 'n_jobs_param', 'X_train', 'pipeline', 'seed', 'exp_id', '_available_plots', 'y_train', 'idx', 'fold_groups_param', 'memory', 'gpu_param', 'y_test', 'fold_generator', 'exp_name_log', 'is_multiclass', '_ml_usecase', 'logging_param', 'X', 'fold_shuffle_param', 'log_plots_param', 'fix_imbalance'}
2025-09-10 16:40:11,881:INFO:Checking environment
2025-09-10 16:40:11,881:INFO:python_version: 3.11.10
2025-09-10 16:40:11,881:INFO:python_build: ('main', 'Oct  3 2024 07:22:26')
2025-09-10 16:40:11,881:INFO:machine: AMD64
2025-09-10 16:40:11,881:INFO:platform: Windows-10-10.0.26100-SP0
2025-09-10 16:40:11,891:INFO:Memory: svmem(total=16837152768, available=3885842432, percent=76.9, used=12951310336, free=3885842432)
2025-09-10 16:40:11,891:INFO:Physical Core: 10
2025-09-10 16:40:11,891:INFO:Logical Core: 12
2025-09-10 16:40:11,891:INFO:Checking libraries
2025-09-10 16:40:11,891:INFO:System:
2025-09-10 16:40:11,891:INFO:    python: 3.11.10 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:26) [MSC v.1929 64 bit (AMD64)]
2025-09-10 16:40:11,891:INFO:executable: c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\python.exe
2025-09-10 16:40:11,891:INFO:   machine: Windows-10-10.0.26100-SP0
2025-09-10 16:40:11,891:INFO:PyCaret required dependencies:
2025-09-10 16:40:12,240:INFO:                 pip: 24.2
2025-09-10 16:40:12,240:INFO:          setuptools: 75.1.0
2025-09-10 16:40:12,240:INFO:             pycaret: 3.3.2
2025-09-10 16:40:12,240:INFO:             IPython: 9.2.0
2025-09-10 16:40:12,240:INFO:          ipywidgets: 8.1.7
2025-09-10 16:40:12,240:INFO:                tqdm: 4.67.1
2025-09-10 16:40:12,240:INFO:               numpy: 1.24.4
2025-09-10 16:40:12,241:INFO:              pandas: 1.5.3
2025-09-10 16:40:12,241:INFO:              jinja2: 3.1.6
2025-09-10 16:40:12,241:INFO:               scipy: 1.11.4
2025-09-10 16:40:12,241:INFO:              joblib: 1.3.2
2025-09-10 16:40:12,241:INFO:             sklearn: 1.4.2
2025-09-10 16:40:12,241:INFO:                pyod: 2.0.5
2025-09-10 16:40:12,241:INFO:            imblearn: 0.13.0
2025-09-10 16:40:12,241:INFO:   category_encoders: 2.7.0
2025-09-10 16:40:12,241:INFO:            lightgbm: 4.6.0
2025-09-10 16:40:12,241:INFO:               numba: 0.61.0
2025-09-10 16:40:12,241:INFO:            requests: 2.32.3
2025-09-10 16:40:12,241:INFO:          matplotlib: 3.7.5
2025-09-10 16:40:12,241:INFO:          scikitplot: 0.3.7
2025-09-10 16:40:12,241:INFO:         yellowbrick: 1.5
2025-09-10 16:40:12,241:INFO:              plotly: 5.24.1
2025-09-10 16:40:12,241:INFO:    plotly-resampler: Not installed
2025-09-10 16:40:12,241:INFO:             kaleido: 0.2.1
2025-09-10 16:40:12,241:INFO:           schemdraw: 0.15
2025-09-10 16:40:12,241:INFO:         statsmodels: 0.14.4
2025-09-10 16:40:12,241:INFO:              sktime: 0.26.0
2025-09-10 16:40:12,241:INFO:               tbats: 1.1.3
2025-09-10 16:40:12,241:INFO:            pmdarima: 2.0.4
2025-09-10 16:40:12,241:INFO:              psutil: 7.0.0
2025-09-10 16:40:12,241:INFO:          markupsafe: 3.0.2
2025-09-10 16:40:12,241:INFO:             pickle5: Not installed
2025-09-10 16:40:12,241:INFO:         cloudpickle: 3.1.1
2025-09-10 16:40:12,241:INFO:         deprecation: 2.1.0
2025-09-10 16:40:12,241:INFO:              xxhash: 3.5.0
2025-09-10 16:40:12,241:INFO:           wurlitzer: Not installed
2025-09-10 16:40:12,241:INFO:PyCaret optional dependencies:
2025-09-10 16:40:14,589:INFO:                shap: 0.44.1
2025-09-10 16:40:14,589:INFO:           interpret: 0.6.11
2025-09-10 16:40:14,589:INFO:                umap: 0.5.7
2025-09-10 16:40:14,589:INFO:     ydata_profiling: 4.16.1
2025-09-10 16:40:14,589:INFO:  explainerdashboard: 0.5.1
2025-09-10 16:40:14,589:INFO:             autoviz: Not installed
2025-09-10 16:40:14,589:INFO:           fairlearn: 0.7.0
2025-09-10 16:40:14,589:INFO:          deepchecks: Not installed
2025-09-10 16:40:14,589:INFO:             xgboost: 3.0.2
2025-09-10 16:40:14,589:INFO:            catboost: 1.2.8
2025-09-10 16:40:14,589:INFO:              kmodes: 0.12.2
2025-09-10 16:40:14,589:INFO:             mlxtend: 0.23.4
2025-09-10 16:40:14,589:INFO:       statsforecast: 1.5.0
2025-09-10 16:40:14,589:INFO:        tune_sklearn: Not installed
2025-09-10 16:40:14,589:INFO:                 ray: Not installed
2025-09-10 16:40:14,589:INFO:            hyperopt: 0.2.7
2025-09-10 16:40:14,589:INFO:              optuna: 4.3.0
2025-09-10 16:40:14,589:INFO:               skopt: 0.10.2
2025-09-10 16:40:14,589:INFO:              mlflow: 3.1.0
2025-09-10 16:40:14,589:INFO:              gradio: 5.33.1
2025-09-10 16:40:14,589:INFO:             fastapi: 0.115.12
2025-09-10 16:40:14,589:INFO:             uvicorn: 0.34.3
2025-09-10 16:40:14,589:INFO:              m2cgen: 0.10.0
2025-09-10 16:40:14,589:INFO:           evidently: 0.4.40
2025-09-10 16:40:14,589:INFO:               fugue: 0.8.7
2025-09-10 16:40:14,589:INFO:           streamlit: 1.45.1
2025-09-10 16:40:14,589:INFO:             prophet: 1.1.7
2025-09-10 16:40:14,589:INFO:None
2025-09-10 16:40:14,589:INFO:Set up data.
2025-09-10 16:40:14,608:INFO:Set up folding strategy.
2025-09-10 16:40:14,608:INFO:Set up train/test split.
2025-09-10 16:40:14,622:INFO:Set up index.
2025-09-10 16:40:14,622:INFO:Assigning column types.
2025-09-10 16:40:14,622:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-09-10 16:40:14,655:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 16:40:14,655:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-10 16:40:14,672:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 16:40:14,672:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 16:40:14,724:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 16:40:14,724:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-10 16:40:14,739:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 16:40:14,739:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 16:40:14,739:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-09-10 16:40:14,772:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-10 16:40:14,788:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 16:40:14,788:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 16:40:14,805:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-10 16:40:14,824:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 16:40:14,838:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 16:40:14,839:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-09-10 16:40:14,872:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 16:40:14,872:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 16:40:14,921:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 16:40:14,922:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 16:40:14,922:INFO:Preparing preprocessing pipeline...
2025-09-10 16:40:14,922:INFO:Set up label encoding.
2025-09-10 16:40:14,922:INFO:Set up date feature engineering.
2025-09-10 16:40:14,922:INFO:Set up iterative imputation.
2025-09-10 16:40:14,922:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-09-10 16:40:14,922:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-09-10 16:40:14,922:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-09-10 16:40:14,955:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 16:40:14,988:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 16:40:14,988:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 16:40:15,022:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 16:40:15,022:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 16:40:15,055:INFO:Set up encoding of categorical features.
2025-09-10 16:40:15,055:INFO:Set up removing multicollinearity.
2025-09-10 16:40:15,055:INFO:Set up removing outliers.
2025-09-10 16:40:15,055:INFO:Set up imbalanced handling.
2025-09-10 16:40:15,055:INFO:Set up column transformation.
2025-09-10 16:40:15,055:INFO:Set up feature normalization.
2025-09-10 16:40:15,055:INFO:Set up column name cleaning.
2025-09-10 16:48:20,422:INFO:PyCaret ClassificationExperiment
2025-09-10 16:48:20,423:INFO:Logging name: clf-default-name
2025-09-10 16:48:20,423:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-09-10 16:48:20,423:INFO:version 3.3.2
2025-09-10 16:48:20,423:INFO:Initializing setup()
2025-09-10 16:48:20,423:INFO:self.USI: 3dce
2025-09-10 16:48:20,423:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y', 'data', 'X_test', 'USI', 'html_param', 'target_param', 'n_jobs_param', 'X_train', 'pipeline', 'seed', 'exp_id', '_available_plots', 'y_train', 'idx', 'fold_groups_param', 'memory', 'gpu_param', 'y_test', 'fold_generator', 'exp_name_log', 'is_multiclass', '_ml_usecase', 'logging_param', 'X', 'fold_shuffle_param', 'log_plots_param', 'fix_imbalance'}
2025-09-10 16:48:20,423:INFO:Checking environment
2025-09-10 16:48:20,423:INFO:python_version: 3.11.10
2025-09-10 16:48:20,424:INFO:python_build: ('main', 'Oct  3 2024 07:22:26')
2025-09-10 16:48:20,424:INFO:machine: AMD64
2025-09-10 16:48:20,424:INFO:platform: Windows-10-10.0.26100-SP0
2025-09-10 16:48:20,430:INFO:Memory: svmem(total=16837152768, available=3761020928, percent=77.7, used=13076131840, free=3761020928)
2025-09-10 16:48:20,431:INFO:Physical Core: 10
2025-09-10 16:48:20,431:INFO:Logical Core: 12
2025-09-10 16:48:20,431:INFO:Checking libraries
2025-09-10 16:48:20,431:INFO:System:
2025-09-10 16:48:20,431:INFO:    python: 3.11.10 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:26) [MSC v.1929 64 bit (AMD64)]
2025-09-10 16:48:20,431:INFO:executable: c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\python.exe
2025-09-10 16:48:20,431:INFO:   machine: Windows-10-10.0.26100-SP0
2025-09-10 16:48:20,431:INFO:PyCaret required dependencies:
2025-09-10 16:48:20,431:INFO:                 pip: 24.2
2025-09-10 16:48:20,431:INFO:          setuptools: 75.1.0
2025-09-10 16:48:20,431:INFO:             pycaret: 3.3.2
2025-09-10 16:48:20,431:INFO:             IPython: 9.2.0
2025-09-10 16:48:20,431:INFO:          ipywidgets: 8.1.7
2025-09-10 16:48:20,431:INFO:                tqdm: 4.67.1
2025-09-10 16:48:20,431:INFO:               numpy: 1.24.4
2025-09-10 16:48:20,431:INFO:              pandas: 1.5.3
2025-09-10 16:48:20,431:INFO:              jinja2: 3.1.6
2025-09-10 16:48:20,431:INFO:               scipy: 1.11.4
2025-09-10 16:48:20,431:INFO:              joblib: 1.3.2
2025-09-10 16:48:20,431:INFO:             sklearn: 1.4.2
2025-09-10 16:48:20,431:INFO:                pyod: 2.0.5
2025-09-10 16:48:20,431:INFO:            imblearn: 0.13.0
2025-09-10 16:48:20,431:INFO:   category_encoders: 2.7.0
2025-09-10 16:48:20,431:INFO:            lightgbm: 4.6.0
2025-09-10 16:48:20,431:INFO:               numba: 0.61.0
2025-09-10 16:48:20,431:INFO:            requests: 2.32.3
2025-09-10 16:48:20,431:INFO:          matplotlib: 3.7.5
2025-09-10 16:48:20,431:INFO:          scikitplot: 0.3.7
2025-09-10 16:48:20,431:INFO:         yellowbrick: 1.5
2025-09-10 16:48:20,431:INFO:              plotly: 5.24.1
2025-09-10 16:48:20,431:INFO:    plotly-resampler: Not installed
2025-09-10 16:48:20,432:INFO:             kaleido: 0.2.1
2025-09-10 16:48:20,432:INFO:           schemdraw: 0.15
2025-09-10 16:48:20,432:INFO:         statsmodels: 0.14.4
2025-09-10 16:48:20,432:INFO:              sktime: 0.26.0
2025-09-10 16:48:20,432:INFO:               tbats: 1.1.3
2025-09-10 16:48:20,432:INFO:            pmdarima: 2.0.4
2025-09-10 16:48:20,432:INFO:              psutil: 7.0.0
2025-09-10 16:48:20,432:INFO:          markupsafe: 3.0.2
2025-09-10 16:48:20,432:INFO:             pickle5: Not installed
2025-09-10 16:48:20,432:INFO:         cloudpickle: 3.1.1
2025-09-10 16:48:20,432:INFO:         deprecation: 2.1.0
2025-09-10 16:48:20,432:INFO:              xxhash: 3.5.0
2025-09-10 16:48:20,432:INFO:           wurlitzer: Not installed
2025-09-10 16:48:20,432:INFO:PyCaret optional dependencies:
2025-09-10 16:48:20,432:INFO:                shap: 0.44.1
2025-09-10 16:48:20,432:INFO:           interpret: 0.6.11
2025-09-10 16:48:20,432:INFO:                umap: 0.5.7
2025-09-10 16:48:20,432:INFO:     ydata_profiling: 4.16.1
2025-09-10 16:48:20,432:INFO:  explainerdashboard: 0.5.1
2025-09-10 16:48:20,432:INFO:             autoviz: Not installed
2025-09-10 16:48:20,432:INFO:           fairlearn: 0.7.0
2025-09-10 16:48:20,432:INFO:          deepchecks: Not installed
2025-09-10 16:48:20,432:INFO:             xgboost: 3.0.2
2025-09-10 16:48:20,432:INFO:            catboost: 1.2.8
2025-09-10 16:48:20,432:INFO:              kmodes: 0.12.2
2025-09-10 16:48:20,432:INFO:             mlxtend: 0.23.4
2025-09-10 16:48:20,432:INFO:       statsforecast: 1.5.0
2025-09-10 16:48:20,432:INFO:        tune_sklearn: Not installed
2025-09-10 16:48:20,432:INFO:                 ray: Not installed
2025-09-10 16:48:20,432:INFO:            hyperopt: 0.2.7
2025-09-10 16:48:20,432:INFO:              optuna: 4.3.0
2025-09-10 16:48:20,432:INFO:               skopt: 0.10.2
2025-09-10 16:48:20,432:INFO:              mlflow: 3.1.0
2025-09-10 16:48:20,432:INFO:              gradio: 5.33.1
2025-09-10 16:48:20,432:INFO:             fastapi: 0.115.12
2025-09-10 16:48:20,432:INFO:             uvicorn: 0.34.3
2025-09-10 16:48:20,432:INFO:              m2cgen: 0.10.0
2025-09-10 16:48:20,432:INFO:           evidently: 0.4.40
2025-09-10 16:48:20,432:INFO:               fugue: 0.8.7
2025-09-10 16:48:20,432:INFO:           streamlit: 1.45.1
2025-09-10 16:48:20,432:INFO:             prophet: 1.1.7
2025-09-10 16:48:20,432:INFO:None
2025-09-10 16:48:20,433:INFO:Set up data.
2025-09-10 16:48:20,454:INFO:Set up folding strategy.
2025-09-10 16:48:20,454:INFO:Set up train/test split.
2025-09-10 16:48:20,470:INFO:Set up index.
2025-09-10 16:48:20,470:INFO:Assigning column types.
2025-09-10 16:48:20,470:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-09-10 16:48:20,499:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 16:48:20,500:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-10 16:48:20,518:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 16:48:20,518:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 16:48:20,550:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 16:48:20,551:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-10 16:48:20,568:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 16:48:20,571:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 16:48:20,571:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-09-10 16:48:20,602:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-10 16:48:20,620:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 16:48:20,620:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 16:48:20,646:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-10 16:48:20,661:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 16:48:20,663:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 16:48:20,663:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-09-10 16:48:20,703:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 16:48:20,705:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 16:48:20,748:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 16:48:20,750:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 16:48:20,750:INFO:Preparing preprocessing pipeline...
2025-09-10 16:48:20,750:INFO:Set up label encoding.
2025-09-10 16:48:20,750:INFO:Set up date feature engineering.
2025-09-10 16:48:20,750:INFO:Set up simple imputation.
2025-09-10 16:48:20,750:INFO:Set up encoding of categorical features.
2025-09-10 16:48:20,750:INFO:Set up removing multicollinearity.
2025-09-10 16:48:20,750:INFO:Set up removing outliers.
2025-09-10 16:48:20,750:INFO:Set up imbalanced handling.
2025-09-10 16:48:20,750:INFO:Set up column transformation.
2025-09-10 16:48:20,750:INFO:Set up feature normalization.
2025-09-10 16:48:20,750:INFO:Set up column name cleaning.
2025-09-10 16:49:01,317:INFO:PyCaret ClassificationExperiment
2025-09-10 16:49:01,317:INFO:Logging name: clf-default-name
2025-09-10 16:49:01,317:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-09-10 16:49:01,317:INFO:version 3.3.2
2025-09-10 16:49:01,317:INFO:Initializing setup()
2025-09-10 16:49:01,317:INFO:self.USI: 9679
2025-09-10 16:49:01,317:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y', 'data', 'X_test', 'USI', 'html_param', 'target_param', 'n_jobs_param', 'X_train', 'pipeline', 'seed', 'exp_id', '_available_plots', 'y_train', 'idx', 'fold_groups_param', 'memory', 'gpu_param', 'y_test', 'fold_generator', 'exp_name_log', 'is_multiclass', '_ml_usecase', 'logging_param', 'X', 'fold_shuffle_param', 'log_plots_param', 'fix_imbalance'}
2025-09-10 16:49:01,317:INFO:Checking environment
2025-09-10 16:49:01,317:INFO:python_version: 3.11.10
2025-09-10 16:49:01,317:INFO:python_build: ('main', 'Oct  3 2024 07:22:26')
2025-09-10 16:49:01,317:INFO:machine: AMD64
2025-09-10 16:49:01,317:INFO:platform: Windows-10-10.0.26100-SP0
2025-09-10 16:49:01,323:INFO:Memory: svmem(total=16837152768, available=3758456832, percent=77.7, used=13078695936, free=3758456832)
2025-09-10 16:49:01,323:INFO:Physical Core: 10
2025-09-10 16:49:01,323:INFO:Logical Core: 12
2025-09-10 16:49:01,323:INFO:Checking libraries
2025-09-10 16:49:01,323:INFO:System:
2025-09-10 16:49:01,323:INFO:    python: 3.11.10 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:26) [MSC v.1929 64 bit (AMD64)]
2025-09-10 16:49:01,323:INFO:executable: c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\python.exe
2025-09-10 16:49:01,323:INFO:   machine: Windows-10-10.0.26100-SP0
2025-09-10 16:49:01,323:INFO:PyCaret required dependencies:
2025-09-10 16:49:01,323:INFO:                 pip: 24.2
2025-09-10 16:49:01,323:INFO:          setuptools: 75.1.0
2025-09-10 16:49:01,323:INFO:             pycaret: 3.3.2
2025-09-10 16:49:01,323:INFO:             IPython: 9.2.0
2025-09-10 16:49:01,323:INFO:          ipywidgets: 8.1.7
2025-09-10 16:49:01,323:INFO:                tqdm: 4.67.1
2025-09-10 16:49:01,323:INFO:               numpy: 1.24.4
2025-09-10 16:49:01,323:INFO:              pandas: 1.5.3
2025-09-10 16:49:01,323:INFO:              jinja2: 3.1.6
2025-09-10 16:49:01,323:INFO:               scipy: 1.11.4
2025-09-10 16:49:01,323:INFO:              joblib: 1.3.2
2025-09-10 16:49:01,323:INFO:             sklearn: 1.4.2
2025-09-10 16:49:01,323:INFO:                pyod: 2.0.5
2025-09-10 16:49:01,323:INFO:            imblearn: 0.13.0
2025-09-10 16:49:01,323:INFO:   category_encoders: 2.7.0
2025-09-10 16:49:01,323:INFO:            lightgbm: 4.6.0
2025-09-10 16:49:01,323:INFO:               numba: 0.61.0
2025-09-10 16:49:01,323:INFO:            requests: 2.32.3
2025-09-10 16:49:01,323:INFO:          matplotlib: 3.7.5
2025-09-10 16:49:01,323:INFO:          scikitplot: 0.3.7
2025-09-10 16:49:01,323:INFO:         yellowbrick: 1.5
2025-09-10 16:49:01,323:INFO:              plotly: 5.24.1
2025-09-10 16:49:01,323:INFO:    plotly-resampler: Not installed
2025-09-10 16:49:01,323:INFO:             kaleido: 0.2.1
2025-09-10 16:49:01,323:INFO:           schemdraw: 0.15
2025-09-10 16:49:01,323:INFO:         statsmodels: 0.14.4
2025-09-10 16:49:01,323:INFO:              sktime: 0.26.0
2025-09-10 16:49:01,323:INFO:               tbats: 1.1.3
2025-09-10 16:49:01,323:INFO:            pmdarima: 2.0.4
2025-09-10 16:49:01,323:INFO:              psutil: 7.0.0
2025-09-10 16:49:01,323:INFO:          markupsafe: 3.0.2
2025-09-10 16:49:01,323:INFO:             pickle5: Not installed
2025-09-10 16:49:01,323:INFO:         cloudpickle: 3.1.1
2025-09-10 16:49:01,323:INFO:         deprecation: 2.1.0
2025-09-10 16:49:01,323:INFO:              xxhash: 3.5.0
2025-09-10 16:49:01,323:INFO:           wurlitzer: Not installed
2025-09-10 16:49:01,323:INFO:PyCaret optional dependencies:
2025-09-10 16:49:01,323:INFO:                shap: 0.44.1
2025-09-10 16:49:01,323:INFO:           interpret: 0.6.11
2025-09-10 16:49:01,323:INFO:                umap: 0.5.7
2025-09-10 16:49:01,323:INFO:     ydata_profiling: 4.16.1
2025-09-10 16:49:01,323:INFO:  explainerdashboard: 0.5.1
2025-09-10 16:49:01,325:INFO:             autoviz: Not installed
2025-09-10 16:49:01,325:INFO:           fairlearn: 0.7.0
2025-09-10 16:49:01,325:INFO:          deepchecks: Not installed
2025-09-10 16:49:01,325:INFO:             xgboost: 3.0.2
2025-09-10 16:49:01,325:INFO:            catboost: 1.2.8
2025-09-10 16:49:01,325:INFO:              kmodes: 0.12.2
2025-09-10 16:49:01,325:INFO:             mlxtend: 0.23.4
2025-09-10 16:49:01,325:INFO:       statsforecast: 1.5.0
2025-09-10 16:49:01,325:INFO:        tune_sklearn: Not installed
2025-09-10 16:49:01,325:INFO:                 ray: Not installed
2025-09-10 16:49:01,325:INFO:            hyperopt: 0.2.7
2025-09-10 16:49:01,325:INFO:              optuna: 4.3.0
2025-09-10 16:49:01,325:INFO:               skopt: 0.10.2
2025-09-10 16:49:01,325:INFO:              mlflow: 3.1.0
2025-09-10 16:49:01,325:INFO:              gradio: 5.33.1
2025-09-10 16:49:01,325:INFO:             fastapi: 0.115.12
2025-09-10 16:49:01,325:INFO:             uvicorn: 0.34.3
2025-09-10 16:49:01,325:INFO:              m2cgen: 0.10.0
2025-09-10 16:49:01,325:INFO:           evidently: 0.4.40
2025-09-10 16:49:01,325:INFO:               fugue: 0.8.7
2025-09-10 16:49:01,325:INFO:           streamlit: 1.45.1
2025-09-10 16:49:01,325:INFO:             prophet: 1.1.7
2025-09-10 16:49:01,325:INFO:None
2025-09-10 16:49:01,325:INFO:Set up data.
2025-09-10 16:49:01,352:INFO:Set up folding strategy.
2025-09-10 16:49:01,353:INFO:Set up train/test split.
2025-09-10 16:49:01,363:INFO:Set up index.
2025-09-10 16:49:01,363:INFO:Assigning column types.
2025-09-10 16:49:01,367:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-09-10 16:49:01,387:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 16:49:01,387:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-10 16:49:01,409:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 16:49:01,409:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 16:49:01,435:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 16:49:01,435:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-10 16:49:01,447:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 16:49:01,447:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 16:49:01,447:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-09-10 16:49:01,476:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-10 16:49:01,493:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 16:49:01,493:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 16:49:01,516:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-10 16:49:01,538:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 16:49:01,540:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 16:49:01,540:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-09-10 16:49:01,581:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 16:49:01,583:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 16:49:01,630:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 16:49:01,632:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 16:49:01,633:INFO:Preparing preprocessing pipeline...
2025-09-10 16:49:01,634:INFO:Set up label encoding.
2025-09-10 16:49:01,634:INFO:Set up date feature engineering.
2025-09-10 16:49:01,634:INFO:Set up simple imputation.
2025-09-10 16:49:01,636:INFO:Set up encoding of categorical features.
2025-09-10 16:49:01,636:INFO:Set up removing multicollinearity.
2025-09-10 16:49:01,636:INFO:Set up removing outliers.
2025-09-10 16:49:01,636:INFO:Set up imbalanced handling.
2025-09-10 16:49:01,636:INFO:Set up column transformation.
2025-09-10 16:49:01,636:INFO:Set up feature normalization.
2025-09-10 16:49:01,636:INFO:Set up column name cleaning.
2025-09-10 17:01:54,574:INFO:PyCaret RegressionExperiment
2025-09-10 17:01:54,576:INFO:Logging name: reg-default-name
2025-09-10 17:01:54,576:INFO:ML Usecase: MLUsecase.REGRESSION
2025-09-10 17:01:54,576:INFO:version 3.3.2
2025-09-10 17:01:54,576:INFO:Initializing setup()
2025-09-10 17:01:54,576:INFO:self.USI: 10ca
2025-09-10 17:01:54,576:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y', 'transform_target_param', 'data', 'X_test', 'USI', 'html_param', 'target_param', 'n_jobs_param', 'X_train', 'pipeline', 'seed', 'exp_id', '_available_plots', 'y_train', 'idx', 'fold_groups_param', 'memory', 'gpu_param', 'y_test', 'fold_generator', 'exp_name_log', '_ml_usecase', 'logging_param', 'X', 'fold_shuffle_param', 'log_plots_param'}
2025-09-10 17:01:54,576:INFO:Checking environment
2025-09-10 17:01:54,576:INFO:python_version: 3.11.10
2025-09-10 17:01:54,576:INFO:python_build: ('main', 'Oct  3 2024 07:22:26')
2025-09-10 17:01:54,576:INFO:machine: AMD64
2025-09-10 17:01:54,576:INFO:platform: Windows-10-10.0.26100-SP0
2025-09-10 17:01:54,581:INFO:Memory: svmem(total=16837152768, available=3250180096, percent=80.7, used=13586972672, free=3250180096)
2025-09-10 17:01:54,581:INFO:Physical Core: 10
2025-09-10 17:01:54,581:INFO:Logical Core: 12
2025-09-10 17:01:54,581:INFO:Checking libraries
2025-09-10 17:01:54,581:INFO:System:
2025-09-10 17:01:54,581:INFO:    python: 3.11.10 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:26) [MSC v.1929 64 bit (AMD64)]
2025-09-10 17:01:54,581:INFO:executable: c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\python.exe
2025-09-10 17:01:54,581:INFO:   machine: Windows-10-10.0.26100-SP0
2025-09-10 17:01:54,581:INFO:PyCaret required dependencies:
2025-09-10 17:01:54,581:INFO:                 pip: 24.2
2025-09-10 17:01:54,581:INFO:          setuptools: 75.1.0
2025-09-10 17:01:54,581:INFO:             pycaret: 3.3.2
2025-09-10 17:01:54,581:INFO:             IPython: 9.2.0
2025-09-10 17:01:54,581:INFO:          ipywidgets: 8.1.7
2025-09-10 17:01:54,581:INFO:                tqdm: 4.67.1
2025-09-10 17:01:54,581:INFO:               numpy: 1.24.4
2025-09-10 17:01:54,581:INFO:              pandas: 1.5.3
2025-09-10 17:01:54,581:INFO:              jinja2: 3.1.6
2025-09-10 17:01:54,581:INFO:               scipy: 1.11.4
2025-09-10 17:01:54,581:INFO:              joblib: 1.3.2
2025-09-10 17:01:54,581:INFO:             sklearn: 1.4.2
2025-09-10 17:01:54,581:INFO:                pyod: 2.0.5
2025-09-10 17:01:54,581:INFO:            imblearn: 0.13.0
2025-09-10 17:01:54,581:INFO:   category_encoders: 2.7.0
2025-09-10 17:01:54,582:INFO:            lightgbm: 4.6.0
2025-09-10 17:01:54,582:INFO:               numba: 0.61.0
2025-09-10 17:01:54,582:INFO:            requests: 2.32.3
2025-09-10 17:01:54,582:INFO:          matplotlib: 3.7.5
2025-09-10 17:01:54,582:INFO:          scikitplot: 0.3.7
2025-09-10 17:01:54,582:INFO:         yellowbrick: 1.5
2025-09-10 17:01:54,582:INFO:              plotly: 5.24.1
2025-09-10 17:01:54,582:INFO:    plotly-resampler: Not installed
2025-09-10 17:01:54,582:INFO:             kaleido: 0.2.1
2025-09-10 17:01:54,582:INFO:           schemdraw: 0.15
2025-09-10 17:01:54,582:INFO:         statsmodels: 0.14.4
2025-09-10 17:01:54,582:INFO:              sktime: 0.26.0
2025-09-10 17:01:54,582:INFO:               tbats: 1.1.3
2025-09-10 17:01:54,582:INFO:            pmdarima: 2.0.4
2025-09-10 17:01:54,582:INFO:              psutil: 7.0.0
2025-09-10 17:01:54,582:INFO:          markupsafe: 3.0.2
2025-09-10 17:01:54,582:INFO:             pickle5: Not installed
2025-09-10 17:01:54,582:INFO:         cloudpickle: 3.1.1
2025-09-10 17:01:54,582:INFO:         deprecation: 2.1.0
2025-09-10 17:01:54,582:INFO:              xxhash: 3.5.0
2025-09-10 17:01:54,582:INFO:           wurlitzer: Not installed
2025-09-10 17:01:54,582:INFO:PyCaret optional dependencies:
2025-09-10 17:01:54,582:INFO:                shap: 0.44.1
2025-09-10 17:01:54,582:INFO:           interpret: 0.6.11
2025-09-10 17:01:54,582:INFO:                umap: 0.5.7
2025-09-10 17:01:54,582:INFO:     ydata_profiling: 4.16.1
2025-09-10 17:01:54,582:INFO:  explainerdashboard: 0.5.1
2025-09-10 17:01:54,582:INFO:             autoviz: Not installed
2025-09-10 17:01:54,582:INFO:           fairlearn: 0.7.0
2025-09-10 17:01:54,582:INFO:          deepchecks: Not installed
2025-09-10 17:01:54,582:INFO:             xgboost: 3.0.2
2025-09-10 17:01:54,582:INFO:            catboost: 1.2.8
2025-09-10 17:01:54,583:INFO:              kmodes: 0.12.2
2025-09-10 17:01:54,583:INFO:             mlxtend: 0.23.4
2025-09-10 17:01:54,583:INFO:       statsforecast: 1.5.0
2025-09-10 17:01:54,583:INFO:        tune_sklearn: Not installed
2025-09-10 17:01:54,583:INFO:                 ray: Not installed
2025-09-10 17:01:54,583:INFO:            hyperopt: 0.2.7
2025-09-10 17:01:54,583:INFO:              optuna: 4.3.0
2025-09-10 17:01:54,583:INFO:               skopt: 0.10.2
2025-09-10 17:01:54,583:INFO:              mlflow: 3.1.0
2025-09-10 17:01:54,583:INFO:              gradio: 5.33.1
2025-09-10 17:01:54,583:INFO:             fastapi: 0.115.12
2025-09-10 17:01:54,583:INFO:             uvicorn: 0.34.3
2025-09-10 17:01:54,583:INFO:              m2cgen: 0.10.0
2025-09-10 17:01:54,583:INFO:           evidently: 0.4.40
2025-09-10 17:01:54,583:INFO:               fugue: 0.8.7
2025-09-10 17:01:54,583:INFO:           streamlit: 1.45.1
2025-09-10 17:01:54,583:INFO:             prophet: 1.1.7
2025-09-10 17:01:54,583:INFO:None
2025-09-10 17:01:54,583:INFO:Set up data.
2025-09-10 17:01:54,597:INFO:Set up folding strategy.
2025-09-10 17:01:54,597:INFO:Set up train/test split.
2025-09-10 17:01:54,615:INFO:Set up index.
2025-09-10 17:01:54,615:INFO:Assigning column types.
2025-09-10 17:01:54,618:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-09-10 17:01:54,619:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-09-10 17:01:54,621:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-09-10 17:01:54,624:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-09-10 17:01:54,645:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:01:54,677:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:01:54,677:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:01:54,677:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:01:54,677:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-09-10 17:01:54,677:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-09-10 17:01:54,677:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-09-10 17:01:54,721:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:01:54,745:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:01:54,748:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:01:54,748:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:01:54,750:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-09-10 17:01:54,752:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-09-10 17:01:54,754:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-09-10 17:01:54,789:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:01:54,810:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:01:54,810:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:01:54,810:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:01:54,810:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-09-10 17:01:54,810:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-09-10 17:01:54,855:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:01:54,887:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:01:54,888:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:01:54,889:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:01:54,890:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-09-10 17:01:54,893:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-09-10 17:01:54,926:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:01:54,943:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:01:54,943:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:01:54,943:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:01:54,943:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-09-10 17:01:54,991:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:01:55,015:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:01:55,015:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:01:55,017:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:01:55,017:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-09-10 17:01:55,055:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:01:55,082:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:01:55,082:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:01:55,084:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:01:55,127:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:01:55,150:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:01:55,152:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:01:55,152:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:01:55,154:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-09-10 17:01:55,194:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:01:55,211:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:01:55,211:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:01:55,262:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:01:55,292:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:01:55,294:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:01:55,295:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-09-10 17:01:55,363:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:01:55,365:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:01:55,426:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:01:55,426:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:01:55,426:INFO:Preparing preprocessing pipeline...
2025-09-10 17:01:55,426:INFO:Set up date feature engineering.
2025-09-10 17:01:55,426:INFO:Set up simple imputation.
2025-09-10 17:01:55,426:INFO:Set up encoding of categorical features.
2025-09-10 17:01:55,426:INFO:Set up removing multicollinearity.
2025-09-10 17:01:55,426:INFO:Set up column transformation.
2025-09-10 17:01:55,426:INFO:Set up feature normalization.
2025-09-10 17:01:55,426:INFO:Set up column name cleaning.
2025-09-10 17:01:56,461:INFO:Finished creating preprocessing pipeline.
2025-09-10 17:01:56,479:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\SBM_ME~1\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['TimeStart', 'TimeStop',
                                             'ProductionDate', 'ApproveDate',
                                             'CreateDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    inc...
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-09-10 17:01:56,479:INFO:Creating final display dataframe.
2025-09-10 17:01:57,247:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target         Man Power
2                   Target type        Regression
3           Original data shape        (7103, 26)
4        Transformed data shape       (7103, 121)
5   Transformed train set shape       (4972, 121)
6    Transformed test set shape       (2131, 121)
7              Numeric features                 3
8                 Date features                 5
9          Categorical features                17
10     Rows with missing values             93.4%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17     Remove multicollinearity              True
18  Multicollinearity threshold              0.95
19               Transformation              True
20        Transformation method       yeo-johnson
21                    Normalize              True
22             Normalize method            zscore
23               Fold Generator             KFold
24                  Fold Number                10
25                     CPU Jobs                -1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  reg-default-name
29                          USI              10ca
2025-09-10 17:01:57,325:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:01:57,327:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:01:57,391:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:01:57,393:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:01:57,393:INFO:setup() successfully completed in 2.85s...............
2025-09-10 17:02:25,590:INFO:Initializing compare_models()
2025-09-10 17:02:25,590:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-09-10 17:02:25,591:INFO:Checking exceptions
2025-09-10 17:02:36,049:INFO:Initializing compare_models()
2025-09-10 17:02:36,049:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-09-10 17:02:36,049:INFO:Checking exceptions
2025-09-10 17:02:36,050:INFO:Preparing display monitor
2025-09-10 17:02:36,080:INFO:Initializing Linear Regression
2025-09-10 17:02:36,088:INFO:Total runtime is 0.00013805230458577473 minutes
2025-09-10 17:02:36,095:INFO:SubProcess create_model() called ==================================
2025-09-10 17:02:36,095:INFO:Initializing create_model()
2025-09-10 17:02:36,096:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:02:36,096:INFO:Checking exceptions
2025-09-10 17:02:36,096:INFO:Importing libraries
2025-09-10 17:02:36,096:INFO:Copying training dataset
2025-09-10 17:02:36,105:INFO:Defining folds
2025-09-10 17:02:36,105:INFO:Declaring metric variables
2025-09-10 17:02:36,111:INFO:Importing untrained model
2025-09-10 17:02:36,118:INFO:Linear Regression Imported successfully
2025-09-10 17:02:36,130:INFO:Starting cross validation
2025-09-10 17:02:36,136:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:02:43,795:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:43,844:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:43,849:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:43,850:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:43,851:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:43,886:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:43,912:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:44,180:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:02:44,190:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:02:44,190:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:02:44,200:INFO:Calculating mean and std
2025-09-10 17:02:44,200:INFO:Creating metrics dataframe
2025-09-10 17:02:44,200:INFO:Uploading results into container
2025-09-10 17:02:44,200:INFO:Uploading model into container now
2025-09-10 17:02:44,200:INFO:_master_model_container: 1
2025-09-10 17:02:44,200:INFO:_display_container: 2
2025-09-10 17:02:44,206:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, positive=False)
2025-09-10 17:02:44,206:INFO:create_model() successfully completed......................................
2025-09-10 17:02:44,557:WARNING:create_model() for LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, positive=False) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:02:44,557:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:02:44,557:INFO:Initializing create_model()
2025-09-10 17:02:44,557:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:02:44,557:INFO:Checking exceptions
2025-09-10 17:02:44,557:INFO:Importing libraries
2025-09-10 17:02:44,557:INFO:Copying training dataset
2025-09-10 17:02:44,568:INFO:Defining folds
2025-09-10 17:02:44,568:INFO:Declaring metric variables
2025-09-10 17:02:44,574:INFO:Importing untrained model
2025-09-10 17:02:44,578:INFO:Linear Regression Imported successfully
2025-09-10 17:02:44,578:INFO:Starting cross validation
2025-09-10 17:02:44,591:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:02:46,207:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:46,215:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:46,270:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:46,272:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:46,272:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:46,277:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:46,313:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:46,484:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:02:46,484:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:02:46,484:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:02:48,756:INFO:Calculating mean and std
2025-09-10 17:02:48,758:INFO:Creating metrics dataframe
2025-09-10 17:02:48,762:INFO:Uploading results into container
2025-09-10 17:02:48,763:INFO:Uploading model into container now
2025-09-10 17:02:48,764:INFO:_master_model_container: 2
2025-09-10 17:02:48,764:INFO:_display_container: 2
2025-09-10 17:02:48,764:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, positive=False)
2025-09-10 17:02:48,764:INFO:create_model() successfully completed......................................
2025-09-10 17:02:48,921:ERROR:create_model() for LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, positive=False) raised an exception or returned all 0.0:
2025-09-10 17:02:48,921:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:02:48,921:INFO:Initializing Lasso Regression
2025-09-10 17:02:48,921:INFO:Total runtime is 0.2140224854151408 minutes
2025-09-10 17:02:48,937:INFO:SubProcess create_model() called ==================================
2025-09-10 17:02:48,937:INFO:Initializing create_model()
2025-09-10 17:02:48,937:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:02:48,937:INFO:Checking exceptions
2025-09-10 17:02:48,937:INFO:Importing libraries
2025-09-10 17:02:48,937:INFO:Copying training dataset
2025-09-10 17:02:48,937:INFO:Defining folds
2025-09-10 17:02:48,937:INFO:Declaring metric variables
2025-09-10 17:02:48,949:INFO:Importing untrained model
2025-09-10 17:02:48,957:INFO:Lasso Regression Imported successfully
2025-09-10 17:02:48,967:INFO:Starting cross validation
2025-09-10 17:02:48,967:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:02:50,544:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:50,560:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:50,580:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:50,587:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:50,609:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:50,655:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:50,704:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:50,823:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py", line 1120, in _decision_function
    return super()._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Lasso does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:02:50,823:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py", line 1120, in _decision_function
    return super()._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Lasso does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:02:50,823:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py", line 1120, in _decision_function
    return super()._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Lasso does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:02:50,833:INFO:Calculating mean and std
2025-09-10 17:02:50,833:INFO:Creating metrics dataframe
2025-09-10 17:02:50,833:INFO:Uploading results into container
2025-09-10 17:02:50,833:INFO:Uploading model into container now
2025-09-10 17:02:50,833:INFO:_master_model_container: 3
2025-09-10 17:02:50,833:INFO:_display_container: 2
2025-09-10 17:02:50,833:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-09-10 17:02:50,833:INFO:create_model() successfully completed......................................
2025-09-10 17:02:51,008:WARNING:create_model() for Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:02:51,010:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:02:51,010:INFO:Initializing create_model()
2025-09-10 17:02:51,010:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:02:51,010:INFO:Checking exceptions
2025-09-10 17:02:51,010:INFO:Importing libraries
2025-09-10 17:02:51,010:INFO:Copying training dataset
2025-09-10 17:02:51,014:INFO:Defining folds
2025-09-10 17:02:51,014:INFO:Declaring metric variables
2025-09-10 17:02:51,020:INFO:Importing untrained model
2025-09-10 17:02:51,025:INFO:Lasso Regression Imported successfully
2025-09-10 17:02:51,041:INFO:Starting cross validation
2025-09-10 17:02:51,045:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:02:52,579:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:52,599:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:52,640:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:52,693:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:52,710:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:52,723:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:52,724:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:52,776:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py", line 1120, in _decision_function
    return super()._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Lasso does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:02:52,776:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py", line 1120, in _decision_function
    return super()._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Lasso does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:02:52,776:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py", line 1120, in _decision_function
    return super()._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Lasso does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:02:52,860:INFO:Calculating mean and std
2025-09-10 17:02:52,861:INFO:Creating metrics dataframe
2025-09-10 17:02:52,863:INFO:Uploading results into container
2025-09-10 17:02:52,863:INFO:Uploading model into container now
2025-09-10 17:02:52,864:INFO:_master_model_container: 4
2025-09-10 17:02:52,864:INFO:_display_container: 2
2025-09-10 17:02:52,864:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-09-10 17:02:52,864:INFO:create_model() successfully completed......................................
2025-09-10 17:02:53,023:ERROR:create_model() for Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False) raised an exception or returned all 0.0:
2025-09-10 17:02:53,023:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:02:53,023:INFO:Initializing Ridge Regression
2025-09-10 17:02:53,023:INFO:Total runtime is 0.2823855638504028 minutes
2025-09-10 17:02:53,031:INFO:SubProcess create_model() called ==================================
2025-09-10 17:02:53,031:INFO:Initializing create_model()
2025-09-10 17:02:53,031:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:02:53,031:INFO:Checking exceptions
2025-09-10 17:02:53,031:INFO:Importing libraries
2025-09-10 17:02:53,031:INFO:Copying training dataset
2025-09-10 17:02:53,031:INFO:Defining folds
2025-09-10 17:02:53,031:INFO:Declaring metric variables
2025-09-10 17:02:53,041:INFO:Importing untrained model
2025-09-10 17:02:53,047:INFO:Ridge Regression Imported successfully
2025-09-10 17:02:53,062:INFO:Starting cross validation
2025-09-10 17:02:53,062:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:02:54,609:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:54,611:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:54,625:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:54,659:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:54,659:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:54,680:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:54,711:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:54,829:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Ridge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:02:54,831:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Ridge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:02:54,831:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Ridge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:02:54,836:INFO:Calculating mean and std
2025-09-10 17:02:54,836:INFO:Creating metrics dataframe
2025-09-10 17:02:54,838:INFO:Uploading results into container
2025-09-10 17:02:54,839:INFO:Uploading model into container now
2025-09-10 17:02:54,840:INFO:_master_model_container: 5
2025-09-10 17:02:54,840:INFO:_display_container: 2
2025-09-10 17:02:54,840:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=123, solver='auto', tol=0.0001)
2025-09-10 17:02:54,840:INFO:create_model() successfully completed......................................
2025-09-10 17:02:55,008:WARNING:create_model() for Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=123, solver='auto', tol=0.0001) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:02:55,008:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:02:55,008:INFO:Initializing create_model()
2025-09-10 17:02:55,008:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:02:55,008:INFO:Checking exceptions
2025-09-10 17:02:55,008:INFO:Importing libraries
2025-09-10 17:02:55,008:INFO:Copying training dataset
2025-09-10 17:02:55,013:INFO:Defining folds
2025-09-10 17:02:55,013:INFO:Declaring metric variables
2025-09-10 17:02:55,019:INFO:Importing untrained model
2025-09-10 17:02:55,025:INFO:Ridge Regression Imported successfully
2025-09-10 17:02:55,025:INFO:Starting cross validation
2025-09-10 17:02:55,025:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:02:56,558:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:56,574:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:56,576:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:56,648:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:56,683:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:56,687:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:56,783:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:56,877:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Ridge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:02:56,877:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Ridge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:02:56,877:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Ridge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:02:56,888:INFO:Calculating mean and std
2025-09-10 17:02:56,888:INFO:Creating metrics dataframe
2025-09-10 17:02:56,893:INFO:Uploading results into container
2025-09-10 17:02:56,893:INFO:Uploading model into container now
2025-09-10 17:02:56,893:INFO:_master_model_container: 6
2025-09-10 17:02:56,893:INFO:_display_container: 2
2025-09-10 17:02:56,893:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=123, solver='auto', tol=0.0001)
2025-09-10 17:02:56,893:INFO:create_model() successfully completed......................................
2025-09-10 17:02:57,041:ERROR:create_model() for Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=123, solver='auto', tol=0.0001) raised an exception or returned all 0.0:
2025-09-10 17:02:57,041:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:02:57,041:INFO:Initializing Elastic Net
2025-09-10 17:02:57,041:INFO:Total runtime is 0.34935374259948726 minutes
2025-09-10 17:02:57,057:INFO:SubProcess create_model() called ==================================
2025-09-10 17:02:57,057:INFO:Initializing create_model()
2025-09-10 17:02:57,057:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:02:57,057:INFO:Checking exceptions
2025-09-10 17:02:57,057:INFO:Importing libraries
2025-09-10 17:02:57,057:INFO:Copying training dataset
2025-09-10 17:02:57,057:INFO:Defining folds
2025-09-10 17:02:57,057:INFO:Declaring metric variables
2025-09-10 17:02:57,072:INFO:Importing untrained model
2025-09-10 17:02:57,075:INFO:Elastic Net Imported successfully
2025-09-10 17:02:57,089:INFO:Starting cross validation
2025-09-10 17:02:57,092:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:02:58,636:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:58,655:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:58,741:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:58,762:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:58,762:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:58,814:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:58,854:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:02:58,940:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py", line 1120, in _decision_function
    return super()._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:02:58,942:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py", line 1120, in _decision_function
    return super()._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:02:58,942:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py", line 1120, in _decision_function
    return super()._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:02:58,950:INFO:Calculating mean and std
2025-09-10 17:02:58,950:INFO:Creating metrics dataframe
2025-09-10 17:02:58,950:INFO:Uploading results into container
2025-09-10 17:02:58,950:INFO:Uploading model into container now
2025-09-10 17:02:58,950:INFO:_master_model_container: 7
2025-09-10 17:02:58,950:INFO:_display_container: 2
2025-09-10 17:02:58,950:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=123,
           selection='cyclic', tol=0.0001, warm_start=False)
2025-09-10 17:02:58,950:INFO:create_model() successfully completed......................................
2025-09-10 17:02:59,106:WARNING:create_model() for ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=123,
           selection='cyclic', tol=0.0001, warm_start=False) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:02:59,119:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:02:59,119:INFO:Initializing create_model()
2025-09-10 17:02:59,119:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:02:59,119:INFO:Checking exceptions
2025-09-10 17:02:59,119:INFO:Importing libraries
2025-09-10 17:02:59,119:INFO:Copying training dataset
2025-09-10 17:02:59,122:INFO:Defining folds
2025-09-10 17:02:59,122:INFO:Declaring metric variables
2025-09-10 17:02:59,128:INFO:Importing untrained model
2025-09-10 17:02:59,128:INFO:Elastic Net Imported successfully
2025-09-10 17:02:59,141:INFO:Starting cross validation
2025-09-10 17:02:59,141:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:03:00,806:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:00,848:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:00,863:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:00,878:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:00,881:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:00,931:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:00,956:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:01,066:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py", line 1120, in _decision_function
    return super()._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:01,066:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py", line 1120, in _decision_function
    return super()._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:01,066:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py", line 1120, in _decision_function
    return super()._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:01,076:INFO:Calculating mean and std
2025-09-10 17:03:01,076:INFO:Creating metrics dataframe
2025-09-10 17:03:01,076:INFO:Uploading results into container
2025-09-10 17:03:01,076:INFO:Uploading model into container now
2025-09-10 17:03:01,076:INFO:_master_model_container: 8
2025-09-10 17:03:01,076:INFO:_display_container: 2
2025-09-10 17:03:01,076:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=123,
           selection='cyclic', tol=0.0001, warm_start=False)
2025-09-10 17:03:01,076:INFO:create_model() successfully completed......................................
2025-09-10 17:03:01,222:ERROR:create_model() for ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=123,
           selection='cyclic', tol=0.0001, warm_start=False) raised an exception or returned all 0.0:
2025-09-10 17:03:01,222:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:03:01,222:INFO:Initializing Least Angle Regression
2025-09-10 17:03:01,222:INFO:Total runtime is 0.419039769967397 minutes
2025-09-10 17:03:01,237:INFO:SubProcess create_model() called ==================================
2025-09-10 17:03:01,237:INFO:Initializing create_model()
2025-09-10 17:03:01,237:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:03:01,237:INFO:Checking exceptions
2025-09-10 17:03:01,237:INFO:Importing libraries
2025-09-10 17:03:01,237:INFO:Copying training dataset
2025-09-10 17:03:01,237:INFO:Defining folds
2025-09-10 17:03:01,237:INFO:Declaring metric variables
2025-09-10 17:03:01,251:INFO:Importing untrained model
2025-09-10 17:03:01,260:INFO:Least Angle Regression Imported successfully
2025-09-10 17:03:01,269:INFO:Starting cross validation
2025-09-10 17:03:01,276:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:03:02,879:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:02,929:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:02,940:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:02,940:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:02,981:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:02,999:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:03,043:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:03,159:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Lars does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:03,159:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Lars does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:03,162:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Lars does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:03,168:INFO:Calculating mean and std
2025-09-10 17:03:03,169:INFO:Creating metrics dataframe
2025-09-10 17:03:03,169:INFO:Uploading results into container
2025-09-10 17:03:03,169:INFO:Uploading model into container now
2025-09-10 17:03:03,169:INFO:_master_model_container: 9
2025-09-10 17:03:03,169:INFO:_display_container: 2
2025-09-10 17:03:03,169:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False)
2025-09-10 17:03:03,169:INFO:create_model() successfully completed......................................
2025-09-10 17:03:03,326:WARNING:create_model() for Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:03:03,326:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:03:03,326:INFO:Initializing create_model()
2025-09-10 17:03:03,326:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:03:03,326:INFO:Checking exceptions
2025-09-10 17:03:03,326:INFO:Importing libraries
2025-09-10 17:03:03,326:INFO:Copying training dataset
2025-09-10 17:03:03,340:INFO:Defining folds
2025-09-10 17:03:03,340:INFO:Declaring metric variables
2025-09-10 17:03:03,347:INFO:Importing untrained model
2025-09-10 17:03:03,347:INFO:Least Angle Regression Imported successfully
2025-09-10 17:03:03,364:INFO:Starting cross validation
2025-09-10 17:03:03,366:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:03:05,028:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:05,074:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:05,090:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:05,090:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:05,110:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:05,130:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:05,234:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:05,265:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Lars does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:05,265:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Lars does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:05,265:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Lars does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:05,317:INFO:Calculating mean and std
2025-09-10 17:03:05,317:INFO:Creating metrics dataframe
2025-09-10 17:03:05,317:INFO:Uploading results into container
2025-09-10 17:03:05,317:INFO:Uploading model into container now
2025-09-10 17:03:05,317:INFO:_master_model_container: 10
2025-09-10 17:03:05,317:INFO:_display_container: 2
2025-09-10 17:03:05,317:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False)
2025-09-10 17:03:05,322:INFO:create_model() successfully completed......................................
2025-09-10 17:03:05,474:ERROR:create_model() for Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False) raised an exception or returned all 0.0:
2025-09-10 17:03:05,474:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:03:05,474:INFO:Initializing Lasso Least Angle Regression
2025-09-10 17:03:05,474:INFO:Total runtime is 0.4899062593777974 minutes
2025-09-10 17:03:05,474:INFO:SubProcess create_model() called ==================================
2025-09-10 17:03:05,474:INFO:Initializing create_model()
2025-09-10 17:03:05,474:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:03:05,474:INFO:Checking exceptions
2025-09-10 17:03:05,474:INFO:Importing libraries
2025-09-10 17:03:05,474:INFO:Copying training dataset
2025-09-10 17:03:05,474:INFO:Defining folds
2025-09-10 17:03:05,474:INFO:Declaring metric variables
2025-09-10 17:03:05,492:INFO:Importing untrained model
2025-09-10 17:03:05,492:INFO:Lasso Least Angle Regression Imported successfully
2025-09-10 17:03:05,511:INFO:Starting cross validation
2025-09-10 17:03:05,515:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:03:07,172:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:07,190:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:07,238:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:07,260:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:07,270:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:07,307:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:07,358:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:07,369:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LassoLars does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:07,373:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LassoLars does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:07,374:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LassoLars does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:07,447:INFO:Calculating mean and std
2025-09-10 17:03:07,447:INFO:Creating metrics dataframe
2025-09-10 17:03:07,447:INFO:Uploading results into container
2025-09-10 17:03:07,447:INFO:Uploading model into container now
2025-09-10 17:03:07,447:INFO:_master_model_container: 11
2025-09-10 17:03:07,447:INFO:_display_container: 2
2025-09-10 17:03:07,447:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False)
2025-09-10 17:03:07,447:INFO:create_model() successfully completed......................................
2025-09-10 17:03:07,608:WARNING:create_model() for LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:03:07,608:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:03:07,608:INFO:Initializing create_model()
2025-09-10 17:03:07,608:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:03:07,608:INFO:Checking exceptions
2025-09-10 17:03:07,608:INFO:Importing libraries
2025-09-10 17:03:07,608:INFO:Copying training dataset
2025-09-10 17:03:07,608:INFO:Defining folds
2025-09-10 17:03:07,608:INFO:Declaring metric variables
2025-09-10 17:03:07,621:INFO:Importing untrained model
2025-09-10 17:03:07,624:INFO:Lasso Least Angle Regression Imported successfully
2025-09-10 17:03:07,630:INFO:Starting cross validation
2025-09-10 17:03:07,639:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:03:09,257:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:09,334:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:09,342:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:09,371:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:09,377:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:09,426:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:09,432:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:09,624:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LassoLars does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:09,624:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LassoLars does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:09,624:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LassoLars does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:09,635:INFO:Calculating mean and std
2025-09-10 17:03:09,635:INFO:Creating metrics dataframe
2025-09-10 17:03:09,635:INFO:Uploading results into container
2025-09-10 17:03:09,635:INFO:Uploading model into container now
2025-09-10 17:03:09,639:INFO:_master_model_container: 12
2025-09-10 17:03:09,639:INFO:_display_container: 2
2025-09-10 17:03:09,640:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False)
2025-09-10 17:03:09,640:INFO:create_model() successfully completed......................................
2025-09-10 17:03:09,821:ERROR:create_model() for LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False) raised an exception or returned all 0.0:
2025-09-10 17:03:09,822:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:03:09,823:INFO:Initializing Orthogonal Matching Pursuit
2025-09-10 17:03:09,823:INFO:Total runtime is 0.5623767892519633 minutes
2025-09-10 17:03:09,829:INFO:SubProcess create_model() called ==================================
2025-09-10 17:03:09,830:INFO:Initializing create_model()
2025-09-10 17:03:09,830:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:03:09,830:INFO:Checking exceptions
2025-09-10 17:03:09,830:INFO:Importing libraries
2025-09-10 17:03:09,830:INFO:Copying training dataset
2025-09-10 17:03:09,835:INFO:Defining folds
2025-09-10 17:03:09,835:INFO:Declaring metric variables
2025-09-10 17:03:09,841:INFO:Importing untrained model
2025-09-10 17:03:09,847:INFO:Orthogonal Matching Pursuit Imported successfully
2025-09-10 17:03:09,858:INFO:Starting cross validation
2025-09-10 17:03:09,861:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:03:11,625:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:11,656:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:11,673:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:11,675:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:11,704:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:11,739:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:11,780:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:11,956:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
OrthogonalMatchingPursuit does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:11,956:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
OrthogonalMatchingPursuit does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:11,956:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
OrthogonalMatchingPursuit does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:11,967:INFO:Calculating mean and std
2025-09-10 17:03:11,967:INFO:Creating metrics dataframe
2025-09-10 17:03:11,967:INFO:Uploading results into container
2025-09-10 17:03:11,967:INFO:Uploading model into container now
2025-09-10 17:03:11,967:INFO:_master_model_container: 13
2025-09-10 17:03:11,967:INFO:_display_container: 2
2025-09-10 17:03:11,967:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None)
2025-09-10 17:03:11,967:INFO:create_model() successfully completed......................................
2025-09-10 17:03:12,125:WARNING:create_model() for OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:03:12,125:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:03:12,125:INFO:Initializing create_model()
2025-09-10 17:03:12,125:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:03:12,125:INFO:Checking exceptions
2025-09-10 17:03:12,125:INFO:Importing libraries
2025-09-10 17:03:12,125:INFO:Copying training dataset
2025-09-10 17:03:12,139:INFO:Defining folds
2025-09-10 17:03:12,139:INFO:Declaring metric variables
2025-09-10 17:03:12,143:INFO:Importing untrained model
2025-09-10 17:03:12,143:INFO:Orthogonal Matching Pursuit Imported successfully
2025-09-10 17:03:12,157:INFO:Starting cross validation
2025-09-10 17:03:12,157:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:03:13,910:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:13,918:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:14,024:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:14,034:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:14,045:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:14,056:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:14,075:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:14,217:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
OrthogonalMatchingPursuit does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:14,217:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
OrthogonalMatchingPursuit does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:14,217:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
OrthogonalMatchingPursuit does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:14,221:INFO:Calculating mean and std
2025-09-10 17:03:14,222:INFO:Creating metrics dataframe
2025-09-10 17:03:14,225:INFO:Uploading results into container
2025-09-10 17:03:14,225:INFO:Uploading model into container now
2025-09-10 17:03:14,226:INFO:_master_model_container: 14
2025-09-10 17:03:14,226:INFO:_display_container: 2
2025-09-10 17:03:14,227:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None)
2025-09-10 17:03:14,227:INFO:create_model() successfully completed......................................
2025-09-10 17:03:14,389:ERROR:create_model() for OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None) raised an exception or returned all 0.0:
2025-09-10 17:03:14,389:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:03:14,389:INFO:Initializing Bayesian Ridge
2025-09-10 17:03:14,389:INFO:Total runtime is 0.6384895960489909 minutes
2025-09-10 17:03:14,389:INFO:SubProcess create_model() called ==================================
2025-09-10 17:03:14,405:INFO:Initializing create_model()
2025-09-10 17:03:14,405:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:03:14,405:INFO:Checking exceptions
2025-09-10 17:03:14,405:INFO:Importing libraries
2025-09-10 17:03:14,405:INFO:Copying training dataset
2025-09-10 17:03:14,406:INFO:Defining folds
2025-09-10 17:03:14,406:INFO:Declaring metric variables
2025-09-10 17:03:14,415:INFO:Importing untrained model
2025-09-10 17:03:14,424:INFO:Bayesian Ridge Imported successfully
2025-09-10 17:03:14,431:INFO:Starting cross validation
2025-09-10 17:03:14,439:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:03:16,182:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:16,202:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:16,210:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:16,239:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:16,272:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:16,289:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:16,373:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:16,440:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_bayes.py", line 421, in predict
    y_mean = self._decision_function(X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
BayesianRidge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:16,450:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_bayes.py", line 421, in predict
    y_mean = self._decision_function(X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
BayesianRidge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:16,450:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_bayes.py", line 421, in predict
    y_mean = self._decision_function(X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
BayesianRidge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:16,460:INFO:Calculating mean and std
2025-09-10 17:03:16,460:INFO:Creating metrics dataframe
2025-09-10 17:03:16,460:INFO:Uploading results into container
2025-09-10 17:03:16,460:INFO:Uploading model into container now
2025-09-10 17:03:16,460:INFO:_master_model_container: 15
2025-09-10 17:03:16,460:INFO:_display_container: 2
2025-09-10 17:03:16,460:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, max_iter=None,
              n_iter='deprecated', tol=0.001, verbose=False)
2025-09-10 17:03:16,460:INFO:create_model() successfully completed......................................
2025-09-10 17:03:16,622:WARNING:create_model() for BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, max_iter=None,
              n_iter='deprecated', tol=0.001, verbose=False) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:03:16,622:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:03:16,622:INFO:Initializing create_model()
2025-09-10 17:03:16,622:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:03:16,622:INFO:Checking exceptions
2025-09-10 17:03:16,622:INFO:Importing libraries
2025-09-10 17:03:16,622:INFO:Copying training dataset
2025-09-10 17:03:16,622:INFO:Defining folds
2025-09-10 17:03:16,622:INFO:Declaring metric variables
2025-09-10 17:03:16,635:INFO:Importing untrained model
2025-09-10 17:03:16,643:INFO:Bayesian Ridge Imported successfully
2025-09-10 17:03:16,643:INFO:Starting cross validation
2025-09-10 17:03:16,657:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:03:18,431:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:18,460:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:18,489:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:18,496:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:18,508:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:18,575:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:18,593:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:18,726:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_bayes.py", line 421, in predict
    y_mean = self._decision_function(X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
BayesianRidge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:18,726:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_bayes.py", line 421, in predict
    y_mean = self._decision_function(X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
BayesianRidge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:18,726:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_bayes.py", line 421, in predict
    y_mean = self._decision_function(X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
BayesianRidge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:18,735:INFO:Calculating mean and std
2025-09-10 17:03:18,735:INFO:Creating metrics dataframe
2025-09-10 17:03:18,738:INFO:Uploading results into container
2025-09-10 17:03:18,739:INFO:Uploading model into container now
2025-09-10 17:03:18,739:INFO:_master_model_container: 16
2025-09-10 17:03:18,739:INFO:_display_container: 2
2025-09-10 17:03:18,739:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, max_iter=None,
              n_iter='deprecated', tol=0.001, verbose=False)
2025-09-10 17:03:18,739:INFO:create_model() successfully completed......................................
2025-09-10 17:03:18,904:ERROR:create_model() for BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, max_iter=None,
              n_iter='deprecated', tol=0.001, verbose=False) raised an exception or returned all 0.0:
2025-09-10 17:03:18,905:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:03:18,905:INFO:Initializing Passive Aggressive Regressor
2025-09-10 17:03:18,905:INFO:Total runtime is 0.7137448986371359 minutes
2025-09-10 17:03:18,906:INFO:SubProcess create_model() called ==================================
2025-09-10 17:03:18,906:INFO:Initializing create_model()
2025-09-10 17:03:18,906:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:03:18,906:INFO:Checking exceptions
2025-09-10 17:03:18,906:INFO:Importing libraries
2025-09-10 17:03:18,906:INFO:Copying training dataset
2025-09-10 17:03:18,906:INFO:Defining folds
2025-09-10 17:03:18,906:INFO:Declaring metric variables
2025-09-10 17:03:18,918:INFO:Importing untrained model
2025-09-10 17:03:18,925:INFO:Passive Aggressive Regressor Imported successfully
2025-09-10 17:03:18,939:INFO:Starting cross validation
2025-09-10 17:03:18,943:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:03:20,626:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:20,667:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:20,769:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:20,784:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:20,789:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:20,805:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:20,805:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:20,972:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1658, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1640, in _decision_function
    X = self._validate_data(X, accept_sparse="csr", reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
PassiveAggressiveRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:20,981:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1658, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1640, in _decision_function
    X = self._validate_data(X, accept_sparse="csr", reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
PassiveAggressiveRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:20,981:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1658, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1640, in _decision_function
    X = self._validate_data(X, accept_sparse="csr", reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
PassiveAggressiveRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:20,991:INFO:Calculating mean and std
2025-09-10 17:03:20,991:INFO:Creating metrics dataframe
2025-09-10 17:03:20,991:INFO:Uploading results into container
2025-09-10 17:03:20,991:INFO:Uploading model into container now
2025-09-10 17:03:20,991:INFO:_master_model_container: 17
2025-09-10 17:03:20,991:INFO:_display_container: 2
2025-09-10 17:03:20,991:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=123, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-09-10 17:03:20,991:INFO:create_model() successfully completed......................................
2025-09-10 17:03:21,165:WARNING:create_model() for PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=123, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:03:21,167:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:03:21,167:INFO:Initializing create_model()
2025-09-10 17:03:21,167:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:03:21,167:INFO:Checking exceptions
2025-09-10 17:03:21,168:INFO:Importing libraries
2025-09-10 17:03:21,168:INFO:Copying training dataset
2025-09-10 17:03:21,175:INFO:Defining folds
2025-09-10 17:03:21,175:INFO:Declaring metric variables
2025-09-10 17:03:21,181:INFO:Importing untrained model
2025-09-10 17:03:21,186:INFO:Passive Aggressive Regressor Imported successfully
2025-09-10 17:03:21,195:INFO:Starting cross validation
2025-09-10 17:03:21,198:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:03:23,014:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:23,053:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:23,058:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:23,068:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:23,085:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:23,139:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:23,160:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:23,311:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1658, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1640, in _decision_function
    X = self._validate_data(X, accept_sparse="csr", reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
PassiveAggressiveRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:23,312:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1658, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1640, in _decision_function
    X = self._validate_data(X, accept_sparse="csr", reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
PassiveAggressiveRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:23,312:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1658, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1640, in _decision_function
    X = self._validate_data(X, accept_sparse="csr", reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
PassiveAggressiveRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:23,316:INFO:Calculating mean and std
2025-09-10 17:03:23,317:INFO:Creating metrics dataframe
2025-09-10 17:03:23,319:INFO:Uploading results into container
2025-09-10 17:03:23,319:INFO:Uploading model into container now
2025-09-10 17:03:23,320:INFO:_master_model_container: 18
2025-09-10 17:03:23,320:INFO:_display_container: 2
2025-09-10 17:03:23,320:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=123, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-09-10 17:03:23,320:INFO:create_model() successfully completed......................................
2025-09-10 17:03:23,487:ERROR:create_model() for PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=123, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False) raised an exception or returned all 0.0:
2025-09-10 17:03:23,489:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:03:23,489:INFO:Initializing Huber Regressor
2025-09-10 17:03:23,490:INFO:Total runtime is 0.7901596943537395 minutes
2025-09-10 17:03:23,494:INFO:SubProcess create_model() called ==================================
2025-09-10 17:03:23,494:INFO:Initializing create_model()
2025-09-10 17:03:23,494:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:03:23,494:INFO:Checking exceptions
2025-09-10 17:03:23,494:INFO:Importing libraries
2025-09-10 17:03:23,494:INFO:Copying training dataset
2025-09-10 17:03:23,499:INFO:Defining folds
2025-09-10 17:03:23,499:INFO:Declaring metric variables
2025-09-10 17:03:23,505:INFO:Importing untrained model
2025-09-10 17:03:23,507:INFO:Huber Regressor Imported successfully
2025-09-10 17:03:23,521:INFO:Starting cross validation
2025-09-10 17:03:23,524:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:03:25,175:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:25,212:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:25,249:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:25,260:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:25,263:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:25,345:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:25,348:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:25,674:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-09-10 17:03:25,741:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
HuberRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:25,741:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
HuberRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:25,741:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
HuberRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:25,754:INFO:Calculating mean and std
2025-09-10 17:03:25,754:INFO:Creating metrics dataframe
2025-09-10 17:03:25,754:INFO:Uploading results into container
2025-09-10 17:03:25,754:INFO:Uploading model into container now
2025-09-10 17:03:25,754:INFO:_master_model_container: 19
2025-09-10 17:03:25,754:INFO:_display_container: 2
2025-09-10 17:03:25,754:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2025-09-10 17:03:25,754:INFO:create_model() successfully completed......................................
2025-09-10 17:03:25,905:WARNING:create_model() for HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:03:25,905:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:03:25,905:INFO:Initializing create_model()
2025-09-10 17:03:25,905:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:03:25,905:INFO:Checking exceptions
2025-09-10 17:03:25,905:INFO:Importing libraries
2025-09-10 17:03:25,905:INFO:Copying training dataset
2025-09-10 17:03:25,921:INFO:Defining folds
2025-09-10 17:03:25,921:INFO:Declaring metric variables
2025-09-10 17:03:25,928:INFO:Importing untrained model
2025-09-10 17:03:25,928:INFO:Huber Regressor Imported successfully
2025-09-10 17:03:25,940:INFO:Starting cross validation
2025-09-10 17:03:25,940:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:03:27,560:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:27,637:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:27,675:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:27,710:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:27,718:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:27,723:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:27,725:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:28,113:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-09-10 17:03:28,176:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
HuberRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:28,176:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
HuberRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:28,176:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
HuberRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:28,186:INFO:Calculating mean and std
2025-09-10 17:03:28,186:INFO:Creating metrics dataframe
2025-09-10 17:03:28,188:INFO:Uploading results into container
2025-09-10 17:03:28,188:INFO:Uploading model into container now
2025-09-10 17:03:28,188:INFO:_master_model_container: 20
2025-09-10 17:03:28,188:INFO:_display_container: 2
2025-09-10 17:03:28,188:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2025-09-10 17:03:28,188:INFO:create_model() successfully completed......................................
2025-09-10 17:03:28,350:ERROR:create_model() for HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False) raised an exception or returned all 0.0:
2025-09-10 17:03:28,351:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:03:28,351:INFO:Initializing K Neighbors Regressor
2025-09-10 17:03:28,351:INFO:Total runtime is 0.8711846669514974 minutes
2025-09-10 17:03:28,358:INFO:SubProcess create_model() called ==================================
2025-09-10 17:03:28,359:INFO:Initializing create_model()
2025-09-10 17:03:28,359:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:03:28,359:INFO:Checking exceptions
2025-09-10 17:03:28,359:INFO:Importing libraries
2025-09-10 17:03:28,359:INFO:Copying training dataset
2025-09-10 17:03:28,365:INFO:Defining folds
2025-09-10 17:03:28,365:INFO:Declaring metric variables
2025-09-10 17:03:28,369:INFO:Importing untrained model
2025-09-10 17:03:28,373:INFO:K Neighbors Regressor Imported successfully
2025-09-10 17:03:28,388:INFO:Starting cross validation
2025-09-10 17:03:28,391:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:03:30,048:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:30,077:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:30,094:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:30,133:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:30,162:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:30,178:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:30,262:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:30,295:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\neighbors\_regression.py", line 242, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\neighbors\_base.py", line 826, in kneighbors
    X = self._validate_data(X, accept_sparse="csr", reset=False, order="C")
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
KNeighborsRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:30,298:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\neighbors\_regression.py", line 242, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\neighbors\_base.py", line 826, in kneighbors
    X = self._validate_data(X, accept_sparse="csr", reset=False, order="C")
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
KNeighborsRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:30,298:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\neighbors\_regression.py", line 242, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\neighbors\_base.py", line 826, in kneighbors
    X = self._validate_data(X, accept_sparse="csr", reset=False, order="C")
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
KNeighborsRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:30,347:INFO:Calculating mean and std
2025-09-10 17:03:30,348:INFO:Creating metrics dataframe
2025-09-10 17:03:30,350:INFO:Uploading results into container
2025-09-10 17:03:30,350:INFO:Uploading model into container now
2025-09-10 17:03:30,350:INFO:_master_model_container: 21
2025-09-10 17:03:30,351:INFO:_display_container: 2
2025-09-10 17:03:30,351:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2025-09-10 17:03:30,351:INFO:create_model() successfully completed......................................
2025-09-10 17:03:30,505:WARNING:create_model() for KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform') raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:03:30,505:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:03:30,505:INFO:Initializing create_model()
2025-09-10 17:03:30,505:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:03:30,505:INFO:Checking exceptions
2025-09-10 17:03:30,505:INFO:Importing libraries
2025-09-10 17:03:30,505:INFO:Copying training dataset
2025-09-10 17:03:30,523:INFO:Defining folds
2025-09-10 17:03:30,523:INFO:Declaring metric variables
2025-09-10 17:03:30,529:INFO:Importing untrained model
2025-09-10 17:03:30,533:INFO:K Neighbors Regressor Imported successfully
2025-09-10 17:03:30,548:INFO:Starting cross validation
2025-09-10 17:03:30,550:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:03:32,294:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:32,308:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:32,326:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:32,334:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:32,357:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:32,358:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:32,388:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:32,454:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\neighbors\_regression.py", line 242, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\neighbors\_base.py", line 826, in kneighbors
    X = self._validate_data(X, accept_sparse="csr", reset=False, order="C")
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
KNeighborsRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:32,461:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\neighbors\_regression.py", line 242, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\neighbors\_base.py", line 826, in kneighbors
    X = self._validate_data(X, accept_sparse="csr", reset=False, order="C")
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
KNeighborsRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:32,461:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\neighbors\_regression.py", line 242, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\neighbors\_base.py", line 826, in kneighbors
    X = self._validate_data(X, accept_sparse="csr", reset=False, order="C")
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
KNeighborsRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:32,516:INFO:Calculating mean and std
2025-09-10 17:03:32,516:INFO:Creating metrics dataframe
2025-09-10 17:03:32,518:INFO:Uploading results into container
2025-09-10 17:03:32,518:INFO:Uploading model into container now
2025-09-10 17:03:32,518:INFO:_master_model_container: 22
2025-09-10 17:03:32,518:INFO:_display_container: 2
2025-09-10 17:03:32,518:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2025-09-10 17:03:32,518:INFO:create_model() successfully completed......................................
2025-09-10 17:03:32,679:ERROR:create_model() for KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform') raised an exception or returned all 0.0:
2025-09-10 17:03:32,681:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:03:32,681:INFO:Initializing Decision Tree Regressor
2025-09-10 17:03:32,681:INFO:Total runtime is 0.9433560371398926 minutes
2025-09-10 17:03:32,681:INFO:SubProcess create_model() called ==================================
2025-09-10 17:03:32,681:INFO:Initializing create_model()
2025-09-10 17:03:32,681:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:03:32,681:INFO:Checking exceptions
2025-09-10 17:03:32,681:INFO:Importing libraries
2025-09-10 17:03:32,681:INFO:Copying training dataset
2025-09-10 17:03:32,690:INFO:Defining folds
2025-09-10 17:03:32,690:INFO:Declaring metric variables
2025-09-10 17:03:32,692:INFO:Importing untrained model
2025-09-10 17:03:32,699:INFO:Decision Tree Regressor Imported successfully
2025-09-10 17:03:32,711:INFO:Starting cross validation
2025-09-10 17:03:32,714:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:03:34,425:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:34,451:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:34,452:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:34,535:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:34,562:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:34,562:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:34,573:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:34,599:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:34,619:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:34,621:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:34,650:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:34,672:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:34,711:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:34,717:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:34,722:INFO:Calculating mean and std
2025-09-10 17:03:34,722:INFO:Creating metrics dataframe
2025-09-10 17:03:34,722:INFO:Uploading results into container
2025-09-10 17:03:34,722:INFO:Uploading model into container now
2025-09-10 17:03:34,722:INFO:_master_model_container: 23
2025-09-10 17:03:34,722:INFO:_display_container: 2
2025-09-10 17:03:34,722:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=123, splitter='best')
2025-09-10 17:03:34,722:INFO:create_model() successfully completed......................................
2025-09-10 17:03:34,887:WARNING:create_model() for DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=123, splitter='best') raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:03:34,887:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:03:34,888:INFO:Initializing create_model()
2025-09-10 17:03:34,888:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:03:34,888:INFO:Checking exceptions
2025-09-10 17:03:34,888:INFO:Importing libraries
2025-09-10 17:03:34,888:INFO:Copying training dataset
2025-09-10 17:03:34,888:INFO:Defining folds
2025-09-10 17:03:34,888:INFO:Declaring metric variables
2025-09-10 17:03:34,888:INFO:Importing untrained model
2025-09-10 17:03:34,888:INFO:Decision Tree Regressor Imported successfully
2025-09-10 17:03:34,910:INFO:Starting cross validation
2025-09-10 17:03:34,912:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:03:36,641:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:36,641:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:36,707:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:36,707:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:36,749:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:36,755:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:36,755:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:36,780:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:36,791:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:36,832:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:36,868:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:36,877:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:36,880:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:36,883:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:36,887:INFO:Calculating mean and std
2025-09-10 17:03:36,887:INFO:Creating metrics dataframe
2025-09-10 17:03:36,887:INFO:Uploading results into container
2025-09-10 17:03:36,887:INFO:Uploading model into container now
2025-09-10 17:03:36,887:INFO:_master_model_container: 24
2025-09-10 17:03:36,887:INFO:_display_container: 2
2025-09-10 17:03:36,887:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=123, splitter='best')
2025-09-10 17:03:36,887:INFO:create_model() successfully completed......................................
2025-09-10 17:03:37,044:ERROR:create_model() for DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=123, splitter='best') raised an exception or returned all 0.0:
2025-09-10 17:03:37,046:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:03:37,046:INFO:Initializing Random Forest Regressor
2025-09-10 17:03:37,046:INFO:Total runtime is 1.016101360321045 minutes
2025-09-10 17:03:37,048:INFO:SubProcess create_model() called ==================================
2025-09-10 17:03:37,048:INFO:Initializing create_model()
2025-09-10 17:03:37,048:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:03:37,048:INFO:Checking exceptions
2025-09-10 17:03:37,048:INFO:Importing libraries
2025-09-10 17:03:37,048:INFO:Copying training dataset
2025-09-10 17:03:37,054:INFO:Defining folds
2025-09-10 17:03:37,054:INFO:Declaring metric variables
2025-09-10 17:03:37,054:INFO:Importing untrained model
2025-09-10 17:03:37,054:INFO:Random Forest Regressor Imported successfully
2025-09-10 17:03:37,076:INFO:Starting cross validation
2025-09-10 17:03:37,080:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:03:38,792:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:38,847:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:38,871:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:38,903:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:38,915:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:38,917:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:38,918:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:38,952:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:38,974:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:39,013:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:39,031:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:39,037:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:39,041:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:39,095:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:39,268:INFO:Calculating mean and std
2025-09-10 17:03:39,268:INFO:Creating metrics dataframe
2025-09-10 17:03:39,268:INFO:Uploading results into container
2025-09-10 17:03:39,268:INFO:Uploading model into container now
2025-09-10 17:03:39,268:INFO:_master_model_container: 25
2025-09-10 17:03:39,268:INFO:_display_container: 2
2025-09-10 17:03:39,268:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, monotonic_cst=None,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=123, verbose=0, warm_start=False)
2025-09-10 17:03:39,268:INFO:create_model() successfully completed......................................
2025-09-10 17:03:39,422:WARNING:create_model() for RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, monotonic_cst=None,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=123, verbose=0, warm_start=False) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:03:39,422:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:03:39,422:INFO:Initializing create_model()
2025-09-10 17:03:39,422:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:03:39,422:INFO:Checking exceptions
2025-09-10 17:03:39,422:INFO:Importing libraries
2025-09-10 17:03:39,422:INFO:Copying training dataset
2025-09-10 17:03:39,438:INFO:Defining folds
2025-09-10 17:03:39,438:INFO:Declaring metric variables
2025-09-10 17:03:39,438:INFO:Importing untrained model
2025-09-10 17:03:39,438:INFO:Random Forest Regressor Imported successfully
2025-09-10 17:03:39,456:INFO:Starting cross validation
2025-09-10 17:03:39,458:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:03:41,241:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:41,293:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:41,295:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:41,303:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:41,303:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:41,366:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:41,412:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:41,412:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:41,432:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:41,435:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:41,435:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:41,445:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:41,561:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:41,586:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:41,670:INFO:Calculating mean and std
2025-09-10 17:03:41,670:INFO:Creating metrics dataframe
2025-09-10 17:03:41,670:INFO:Uploading results into container
2025-09-10 17:03:41,670:INFO:Uploading model into container now
2025-09-10 17:03:41,670:INFO:_master_model_container: 26
2025-09-10 17:03:41,670:INFO:_display_container: 2
2025-09-10 17:03:41,670:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, monotonic_cst=None,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=123, verbose=0, warm_start=False)
2025-09-10 17:03:41,670:INFO:create_model() successfully completed......................................
2025-09-10 17:03:41,833:ERROR:create_model() for RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, monotonic_cst=None,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=123, verbose=0, warm_start=False) raised an exception or returned all 0.0:
2025-09-10 17:03:41,835:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:03:41,835:INFO:Initializing Extra Trees Regressor
2025-09-10 17:03:41,835:INFO:Total runtime is 1.0959240794181824 minutes
2025-09-10 17:03:41,836:INFO:SubProcess create_model() called ==================================
2025-09-10 17:03:41,836:INFO:Initializing create_model()
2025-09-10 17:03:41,836:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:03:41,836:INFO:Checking exceptions
2025-09-10 17:03:41,836:INFO:Importing libraries
2025-09-10 17:03:41,836:INFO:Copying training dataset
2025-09-10 17:03:41,846:INFO:Defining folds
2025-09-10 17:03:41,846:INFO:Declaring metric variables
2025-09-10 17:03:41,846:INFO:Importing untrained model
2025-09-10 17:03:41,856:INFO:Extra Trees Regressor Imported successfully
2025-09-10 17:03:41,870:INFO:Starting cross validation
2025-09-10 17:03:41,875:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:03:43,621:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:43,666:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:43,717:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:43,719:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:43,727:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:43,729:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:43,760:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:43,829:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:43,862:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:43,905:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:43,928:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:43,944:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:43,979:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:43,989:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:44,006:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_forest.py", line 1064, in predict
    X = self._validate_X_predict(X)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_forest.py", line 641, in _validate_X_predict
    X = self._validate_data(
        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:44,009:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_forest.py", line 1064, in predict
    X = self._validate_X_predict(X)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_forest.py", line 641, in _validate_X_predict
    X = self._validate_data(
        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:44,009:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_forest.py", line 1064, in predict
    X = self._validate_X_predict(X)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_forest.py", line 641, in _validate_X_predict
    X = self._validate_data(
        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:44,020:INFO:Calculating mean and std
2025-09-10 17:03:44,020:INFO:Creating metrics dataframe
2025-09-10 17:03:44,020:INFO:Uploading results into container
2025-09-10 17:03:44,020:INFO:Uploading model into container now
2025-09-10 17:03:44,020:INFO:_master_model_container: 27
2025-09-10 17:03:44,020:INFO:_display_container: 2
2025-09-10 17:03:44,020:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False)
2025-09-10 17:03:44,020:INFO:create_model() successfully completed......................................
2025-09-10 17:03:44,170:WARNING:create_model() for ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:03:44,170:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:03:44,170:INFO:Initializing create_model()
2025-09-10 17:03:44,170:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:03:44,170:INFO:Checking exceptions
2025-09-10 17:03:44,170:INFO:Importing libraries
2025-09-10 17:03:44,170:INFO:Copying training dataset
2025-09-10 17:03:44,186:INFO:Defining folds
2025-09-10 17:03:44,186:INFO:Declaring metric variables
2025-09-10 17:03:44,190:INFO:Importing untrained model
2025-09-10 17:03:44,190:INFO:Extra Trees Regressor Imported successfully
2025-09-10 17:03:44,206:INFO:Starting cross validation
2025-09-10 17:03:44,210:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:03:45,947:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:46,065:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:46,065:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:46,084:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:46,088:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:46,131:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:46,139:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:46,156:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:46,172:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:46,199:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:46,204:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:46,254:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:46,262:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:46,297:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:46,404:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_forest.py", line 1064, in predict
    X = self._validate_X_predict(X)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_forest.py", line 641, in _validate_X_predict
    X = self._validate_data(
        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:46,414:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_forest.py", line 1064, in predict
    X = self._validate_X_predict(X)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_forest.py", line 641, in _validate_X_predict
    X = self._validate_data(
        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:46,414:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_forest.py", line 1064, in predict
    X = self._validate_X_predict(X)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_forest.py", line 641, in _validate_X_predict
    X = self._validate_data(
        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:46,424:INFO:Calculating mean and std
2025-09-10 17:03:46,424:INFO:Creating metrics dataframe
2025-09-10 17:03:46,426:INFO:Uploading results into container
2025-09-10 17:03:46,426:INFO:Uploading model into container now
2025-09-10 17:03:46,426:INFO:_master_model_container: 28
2025-09-10 17:03:46,426:INFO:_display_container: 2
2025-09-10 17:03:46,426:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False)
2025-09-10 17:03:46,426:INFO:create_model() successfully completed......................................
2025-09-10 17:03:46,590:ERROR:create_model() for ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False) raised an exception or returned all 0.0:
2025-09-10 17:03:46,590:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:03:46,590:INFO:Initializing AdaBoost Regressor
2025-09-10 17:03:46,590:INFO:Total runtime is 1.1751590053240457 minutes
2025-09-10 17:03:46,592:INFO:SubProcess create_model() called ==================================
2025-09-10 17:03:46,592:INFO:Initializing create_model()
2025-09-10 17:03:46,592:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:03:46,592:INFO:Checking exceptions
2025-09-10 17:03:46,592:INFO:Importing libraries
2025-09-10 17:03:46,592:INFO:Copying training dataset
2025-09-10 17:03:46,598:INFO:Defining folds
2025-09-10 17:03:46,598:INFO:Declaring metric variables
2025-09-10 17:03:46,602:INFO:Importing untrained model
2025-09-10 17:03:46,610:INFO:AdaBoost Regressor Imported successfully
2025-09-10 17:03:46,620:INFO:Starting cross validation
2025-09-10 17:03:46,625:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:03:48,254:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:48,439:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:48,476:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:48,489:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:48,514:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:48,530:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:48,555:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:48,935:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py", line 1238, in predict
    X = self._check_X(X)
        ^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py", line 98, in _check_X
    return self._validate_data(
           ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
AdaBoostRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:48,935:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py", line 1238, in predict
    X = self._check_X(X)
        ^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py", line 98, in _check_X
    return self._validate_data(
           ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
AdaBoostRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:48,935:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py", line 1238, in predict
    X = self._check_X(X)
        ^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py", line 98, in _check_X
    return self._validate_data(
           ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
AdaBoostRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:48,946:INFO:Calculating mean and std
2025-09-10 17:03:48,946:INFO:Creating metrics dataframe
2025-09-10 17:03:48,948:INFO:Uploading results into container
2025-09-10 17:03:48,948:INFO:Uploading model into container now
2025-09-10 17:03:48,948:INFO:_master_model_container: 29
2025-09-10 17:03:48,948:INFO:_display_container: 2
2025-09-10 17:03:48,948:INFO:AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=123)
2025-09-10 17:03:48,948:INFO:create_model() successfully completed......................................
2025-09-10 17:03:49,107:WARNING:create_model() for AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=123) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:03:49,107:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:03:49,107:INFO:Initializing create_model()
2025-09-10 17:03:49,107:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:03:49,107:INFO:Checking exceptions
2025-09-10 17:03:49,107:INFO:Importing libraries
2025-09-10 17:03:49,107:INFO:Copying training dataset
2025-09-10 17:03:49,111:INFO:Defining folds
2025-09-10 17:03:49,111:INFO:Declaring metric variables
2025-09-10 17:03:49,113:INFO:Importing untrained model
2025-09-10 17:03:49,120:INFO:AdaBoost Regressor Imported successfully
2025-09-10 17:03:49,131:INFO:Starting cross validation
2025-09-10 17:03:49,131:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:03:50,899:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:50,949:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:50,949:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:50,964:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:50,991:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:51,015:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:51,035:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:51,415:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py", line 1238, in predict
    X = self._check_X(X)
        ^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py", line 98, in _check_X
    return self._validate_data(
           ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
AdaBoostRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:51,417:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py", line 1238, in predict
    X = self._check_X(X)
        ^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py", line 98, in _check_X
    return self._validate_data(
           ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
AdaBoostRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:51,417:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py", line 1238, in predict
    X = self._check_X(X)
        ^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py", line 98, in _check_X
    return self._validate_data(
           ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
AdaBoostRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:51,425:INFO:Calculating mean and std
2025-09-10 17:03:51,425:INFO:Creating metrics dataframe
2025-09-10 17:03:51,427:INFO:Uploading results into container
2025-09-10 17:03:51,427:INFO:Uploading model into container now
2025-09-10 17:03:51,427:INFO:_master_model_container: 30
2025-09-10 17:03:51,427:INFO:_display_container: 2
2025-09-10 17:03:51,427:INFO:AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=123)
2025-09-10 17:03:51,427:INFO:create_model() successfully completed......................................
2025-09-10 17:03:51,597:ERROR:create_model() for AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=123) raised an exception or returned all 0.0:
2025-09-10 17:03:51,599:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:03:51,599:INFO:Initializing Gradient Boosting Regressor
2025-09-10 17:03:51,599:INFO:Total runtime is 1.2586440920829771 minutes
2025-09-10 17:03:51,599:INFO:SubProcess create_model() called ==================================
2025-09-10 17:03:51,599:INFO:Initializing create_model()
2025-09-10 17:03:51,603:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:03:51,603:INFO:Checking exceptions
2025-09-10 17:03:51,603:INFO:Importing libraries
2025-09-10 17:03:51,603:INFO:Copying training dataset
2025-09-10 17:03:51,603:INFO:Defining folds
2025-09-10 17:03:51,603:INFO:Declaring metric variables
2025-09-10 17:03:51,603:INFO:Importing untrained model
2025-09-10 17:03:51,603:INFO:Gradient Boosting Regressor Imported successfully
2025-09-10 17:03:51,628:INFO:Starting cross validation
2025-09-10 17:03:51,632:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:03:53,384:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:53,393:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:53,455:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:53,494:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:53,496:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:53,498:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:53,517:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:53,524:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:53,542:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:53,569:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:53,608:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:53,610:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:53,655:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:53,664:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:54,299:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_gb.py", line 2120, in predict
    X = self._validate_data(
        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GradientBoostingRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:54,303:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_gb.py", line 2120, in predict
    X = self._validate_data(
        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GradientBoostingRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:54,303:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_gb.py", line 2120, in predict
    X = self._validate_data(
        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GradientBoostingRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:54,310:INFO:Calculating mean and std
2025-09-10 17:03:54,310:INFO:Creating metrics dataframe
2025-09-10 17:03:54,310:INFO:Uploading results into container
2025-09-10 17:03:54,310:INFO:Uploading model into container now
2025-09-10 17:03:54,310:INFO:_master_model_container: 31
2025-09-10 17:03:54,310:INFO:_display_container: 2
2025-09-10 17:03:54,310:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=123, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-09-10 17:03:54,310:INFO:create_model() successfully completed......................................
2025-09-10 17:03:54,472:WARNING:create_model() for GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=123, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:03:54,472:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:03:54,472:INFO:Initializing create_model()
2025-09-10 17:03:54,472:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:03:54,472:INFO:Checking exceptions
2025-09-10 17:03:54,472:INFO:Importing libraries
2025-09-10 17:03:54,472:INFO:Copying training dataset
2025-09-10 17:03:54,472:INFO:Defining folds
2025-09-10 17:03:54,472:INFO:Declaring metric variables
2025-09-10 17:03:54,472:INFO:Importing untrained model
2025-09-10 17:03:54,483:INFO:Gradient Boosting Regressor Imported successfully
2025-09-10 17:03:54,496:INFO:Starting cross validation
2025-09-10 17:03:54,499:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:03:56,270:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:56,316:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:56,322:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:56,361:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:56,361:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:56,371:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:56,374:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:56,390:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:56,434:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:56,475:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:56,489:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:56,507:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:56,509:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:56,517:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:57,079:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_gb.py", line 2120, in predict
    X = self._validate_data(
        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GradientBoostingRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:57,079:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_gb.py", line 2120, in predict
    X = self._validate_data(
        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GradientBoostingRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:57,079:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_gb.py", line 2120, in predict
    X = self._validate_data(
        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GradientBoostingRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:03:57,089:INFO:Calculating mean and std
2025-09-10 17:03:57,089:INFO:Creating metrics dataframe
2025-09-10 17:03:57,089:INFO:Uploading results into container
2025-09-10 17:03:57,089:INFO:Uploading model into container now
2025-09-10 17:03:57,089:INFO:_master_model_container: 32
2025-09-10 17:03:57,089:INFO:_display_container: 2
2025-09-10 17:03:57,089:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=123, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-09-10 17:03:57,089:INFO:create_model() successfully completed......................................
2025-09-10 17:03:57,255:ERROR:create_model() for GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=123, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False) raised an exception or returned all 0.0:
2025-09-10 17:03:57,255:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:03:57,255:INFO:Initializing Extreme Gradient Boosting
2025-09-10 17:03:57,255:INFO:Total runtime is 1.3529085159301757 minutes
2025-09-10 17:03:57,255:INFO:SubProcess create_model() called ==================================
2025-09-10 17:03:57,255:INFO:Initializing create_model()
2025-09-10 17:03:57,255:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:03:57,255:INFO:Checking exceptions
2025-09-10 17:03:57,255:INFO:Importing libraries
2025-09-10 17:03:57,255:INFO:Copying training dataset
2025-09-10 17:03:57,270:INFO:Defining folds
2025-09-10 17:03:57,270:INFO:Declaring metric variables
2025-09-10 17:03:57,270:INFO:Importing untrained model
2025-09-10 17:03:57,280:INFO:Extreme Gradient Boosting Imported successfully
2025-09-10 17:03:57,293:INFO:Starting cross validation
2025-09-10 17:03:57,293:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:03:59,155:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:59,234:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:59,256:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:59,290:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:59,292:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:59,300:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:59,317:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\base.py:535: RuntimeWarning: overflow encountered in cast
  result = np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:59,373:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\base.py:535: RuntimeWarning: overflow encountered in cast
  result = np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:59,385:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:03:59,390:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\base.py:535: RuntimeWarning: overflow encountered in cast
  result = np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:59,437:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\base.py:535: RuntimeWarning: overflow encountered in cast
  result = np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:59,458:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\base.py:535: RuntimeWarning: overflow encountered in cast
  result = np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:59,458:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\base.py:535: RuntimeWarning: overflow encountered in cast
  result = np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:59,519:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\base.py:535: RuntimeWarning: overflow encountered in cast
  result = np.asarray(self._values, dtype=dtype)

2025-09-10 17:03:59,635:INFO:Calculating mean and std
2025-09-10 17:03:59,635:INFO:Creating metrics dataframe
2025-09-10 17:03:59,635:INFO:Uploading results into container
2025-09-10 17:03:59,635:INFO:Uploading model into container now
2025-09-10 17:03:59,635:INFO:_master_model_container: 33
2025-09-10 17:03:59,635:INFO:_display_container: 2
2025-09-10 17:03:59,635:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-09-10 17:03:59,635:INFO:create_model() successfully completed......................................
2025-09-10 17:03:59,803:WARNING:create_model() for XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:03:59,803:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:03:59,803:INFO:Initializing create_model()
2025-09-10 17:03:59,803:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:03:59,803:INFO:Checking exceptions
2025-09-10 17:03:59,803:INFO:Importing libraries
2025-09-10 17:03:59,803:INFO:Copying training dataset
2025-09-10 17:03:59,803:INFO:Defining folds
2025-09-10 17:03:59,803:INFO:Declaring metric variables
2025-09-10 17:03:59,803:INFO:Importing untrained model
2025-09-10 17:03:59,819:INFO:Extreme Gradient Boosting Imported successfully
2025-09-10 17:03:59,819:INFO:Starting cross validation
2025-09-10 17:03:59,833:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:04:01,601:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:01,631:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:01,655:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:01,762:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:01,764:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\base.py:535: RuntimeWarning: overflow encountered in cast
  result = np.asarray(self._values, dtype=dtype)

2025-09-10 17:04:01,773:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:01,773:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\base.py:535: RuntimeWarning: overflow encountered in cast
  result = np.asarray(self._values, dtype=dtype)

2025-09-10 17:04:01,783:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:01,814:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\base.py:535: RuntimeWarning: overflow encountered in cast
  result = np.asarray(self._values, dtype=dtype)

2025-09-10 17:04:01,850:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:01,892:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\base.py:535: RuntimeWarning: overflow encountered in cast
  result = np.asarray(self._values, dtype=dtype)

2025-09-10 17:04:01,902:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\base.py:535: RuntimeWarning: overflow encountered in cast
  result = np.asarray(self._values, dtype=dtype)

2025-09-10 17:04:01,917:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\base.py:535: RuntimeWarning: overflow encountered in cast
  result = np.asarray(self._values, dtype=dtype)

2025-09-10 17:04:01,965:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\base.py:535: RuntimeWarning: overflow encountered in cast
  result = np.asarray(self._values, dtype=dtype)

2025-09-10 17:04:02,029:INFO:Calculating mean and std
2025-09-10 17:04:02,029:INFO:Creating metrics dataframe
2025-09-10 17:04:02,029:INFO:Uploading results into container
2025-09-10 17:04:02,029:INFO:Uploading model into container now
2025-09-10 17:04:02,029:INFO:_master_model_container: 34
2025-09-10 17:04:02,029:INFO:_display_container: 2
2025-09-10 17:04:02,029:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-09-10 17:04:02,029:INFO:create_model() successfully completed......................................
2025-09-10 17:04:02,187:ERROR:create_model() for XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...) raised an exception or returned all 0.0:
2025-09-10 17:04:02,187:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:04:02,187:INFO:Initializing Light Gradient Boosting Machine
2025-09-10 17:04:02,187:INFO:Total runtime is 1.4351083834966023 minutes
2025-09-10 17:04:02,193:INFO:SubProcess create_model() called ==================================
2025-09-10 17:04:02,193:INFO:Initializing create_model()
2025-09-10 17:04:02,193:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:04:02,193:INFO:Checking exceptions
2025-09-10 17:04:02,193:INFO:Importing libraries
2025-09-10 17:04:02,193:INFO:Copying training dataset
2025-09-10 17:04:02,193:INFO:Defining folds
2025-09-10 17:04:02,193:INFO:Declaring metric variables
2025-09-10 17:04:02,203:INFO:Importing untrained model
2025-09-10 17:04:02,205:INFO:Light Gradient Boosting Machine Imported successfully
2025-09-10 17:04:02,222:INFO:Starting cross validation
2025-09-10 17:04:02,225:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:04:04,017:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:04,113:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:04,138:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:04,178:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:04,201:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:04,286:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:05,814:INFO:Calculating mean and std
2025-09-10 17:04:05,814:INFO:Creating metrics dataframe
2025-09-10 17:04:05,818:INFO:Uploading results into container
2025-09-10 17:04:05,819:INFO:Uploading model into container now
2025-09-10 17:04:05,819:INFO:_master_model_container: 35
2025-09-10 17:04:05,819:INFO:_display_container: 2
2025-09-10 17:04:05,821:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-09-10 17:04:05,821:INFO:create_model() successfully completed......................................
2025-09-10 17:04:06,019:WARNING:create_model() for LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:04:06,019:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:04:06,019:INFO:Initializing create_model()
2025-09-10 17:04:06,019:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:04:06,019:INFO:Checking exceptions
2025-09-10 17:04:06,019:INFO:Importing libraries
2025-09-10 17:04:06,019:INFO:Copying training dataset
2025-09-10 17:04:06,019:INFO:Defining folds
2025-09-10 17:04:06,019:INFO:Declaring metric variables
2025-09-10 17:04:06,038:INFO:Importing untrained model
2025-09-10 17:04:06,038:INFO:Light Gradient Boosting Machine Imported successfully
2025-09-10 17:04:06,038:INFO:Starting cross validation
2025-09-10 17:04:06,054:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:04:07,901:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:07,917:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:07,935:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:07,960:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:07,991:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:08,076:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:09,682:INFO:Calculating mean and std
2025-09-10 17:04:09,683:INFO:Creating metrics dataframe
2025-09-10 17:04:09,684:INFO:Uploading results into container
2025-09-10 17:04:09,686:INFO:Uploading model into container now
2025-09-10 17:04:09,686:INFO:_master_model_container: 36
2025-09-10 17:04:09,686:INFO:_display_container: 2
2025-09-10 17:04:09,687:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-09-10 17:04:09,687:INFO:create_model() successfully completed......................................
2025-09-10 17:04:09,869:ERROR:create_model() for LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0) raised an exception or returned all 0.0:
2025-09-10 17:04:09,869:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:04:09,871:INFO:Initializing CatBoost Regressor
2025-09-10 17:04:09,871:INFO:Total runtime is 1.5631746490796405 minutes
2025-09-10 17:04:09,875:INFO:SubProcess create_model() called ==================================
2025-09-10 17:04:09,875:INFO:Initializing create_model()
2025-09-10 17:04:09,875:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:04:09,875:INFO:Checking exceptions
2025-09-10 17:04:09,875:INFO:Importing libraries
2025-09-10 17:04:09,875:INFO:Copying training dataset
2025-09-10 17:04:09,881:INFO:Defining folds
2025-09-10 17:04:09,881:INFO:Declaring metric variables
2025-09-10 17:04:09,885:INFO:Importing untrained model
2025-09-10 17:04:09,890:INFO:CatBoost Regressor Imported successfully
2025-09-10 17:04:09,903:INFO:Starting cross validation
2025-09-10 17:04:09,908:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:04:12,682:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:12,688:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:12,690:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:12,739:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:12,745:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:12,832:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:12,839:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:20,535:INFO:Calculating mean and std
2025-09-10 17:04:20,535:INFO:Creating metrics dataframe
2025-09-10 17:04:20,537:INFO:Uploading results into container
2025-09-10 17:04:20,537:INFO:Uploading model into container now
2025-09-10 17:04:20,537:INFO:_master_model_container: 37
2025-09-10 17:04:20,537:INFO:_display_container: 2
2025-09-10 17:04:20,537:INFO:<catboost.core.CatBoostRegressor object at 0x000002C5B762D250>
2025-09-10 17:04:20,537:INFO:create_model() successfully completed......................................
2025-09-10 17:04:20,685:WARNING:create_model() for <catboost.core.CatBoostRegressor object at 0x000002C5B762D250> raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:04:20,701:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:04:20,701:INFO:Initializing create_model()
2025-09-10 17:04:20,701:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:04:20,701:INFO:Checking exceptions
2025-09-10 17:04:20,701:INFO:Importing libraries
2025-09-10 17:04:20,701:INFO:Copying training dataset
2025-09-10 17:04:20,701:INFO:Defining folds
2025-09-10 17:04:20,701:INFO:Declaring metric variables
2025-09-10 17:04:20,701:INFO:Importing untrained model
2025-09-10 17:04:20,714:INFO:CatBoost Regressor Imported successfully
2025-09-10 17:04:20,716:INFO:Starting cross validation
2025-09-10 17:04:20,729:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:04:23,014:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:23,067:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:23,122:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:23,191:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:23,206:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:23,221:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:23,230:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:31,911:INFO:Calculating mean and std
2025-09-10 17:04:31,911:INFO:Creating metrics dataframe
2025-09-10 17:04:31,911:INFO:Uploading results into container
2025-09-10 17:04:31,911:INFO:Uploading model into container now
2025-09-10 17:04:31,911:INFO:_master_model_container: 38
2025-09-10 17:04:31,911:INFO:_display_container: 2
2025-09-10 17:04:31,911:INFO:<catboost.core.CatBoostRegressor object at 0x000002C5A9A765D0>
2025-09-10 17:04:31,911:INFO:create_model() successfully completed......................................
2025-09-10 17:04:32,135:ERROR:create_model() for <catboost.core.CatBoostRegressor object at 0x000002C5A9A765D0> raised an exception or returned all 0.0:
2025-09-10 17:04:32,136:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:04:32,136:INFO:Initializing Dummy Regressor
2025-09-10 17:04:32,136:INFO:Total runtime is 1.9342661619186399 minutes
2025-09-10 17:04:32,136:INFO:SubProcess create_model() called ==================================
2025-09-10 17:04:32,136:INFO:Initializing create_model()
2025-09-10 17:04:32,136:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:04:32,136:INFO:Checking exceptions
2025-09-10 17:04:32,136:INFO:Importing libraries
2025-09-10 17:04:32,136:INFO:Copying training dataset
2025-09-10 17:04:32,152:INFO:Defining folds
2025-09-10 17:04:32,152:INFO:Declaring metric variables
2025-09-10 17:04:32,152:INFO:Importing untrained model
2025-09-10 17:04:32,170:INFO:Dummy Regressor Imported successfully
2025-09-10 17:04:32,189:INFO:Starting cross validation
2025-09-10 17:04:32,194:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:04:34,352:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:34,410:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:34,428:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:34,530:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:34,672:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:34,705:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:34,818:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:35,042:INFO:Calculating mean and std
2025-09-10 17:04:35,042:INFO:Creating metrics dataframe
2025-09-10 17:04:35,044:INFO:Uploading results into container
2025-09-10 17:04:35,044:INFO:Uploading model into container now
2025-09-10 17:04:35,045:INFO:_master_model_container: 39
2025-09-10 17:04:35,045:INFO:_display_container: 2
2025-09-10 17:04:35,045:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2025-09-10 17:04:35,045:INFO:create_model() successfully completed......................................
2025-09-10 17:04:35,228:WARNING:create_model() for DummyRegressor(constant=None, quantile=None, strategy='mean') raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:04:35,228:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:04:35,228:INFO:Initializing create_model()
2025-09-10 17:04:35,228:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BDD79510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:04:35,228:INFO:Checking exceptions
2025-09-10 17:04:35,228:INFO:Importing libraries
2025-09-10 17:04:35,228:INFO:Copying training dataset
2025-09-10 17:04:35,240:INFO:Defining folds
2025-09-10 17:04:35,240:INFO:Declaring metric variables
2025-09-10 17:04:35,246:INFO:Importing untrained model
2025-09-10 17:04:35,251:INFO:Dummy Regressor Imported successfully
2025-09-10 17:04:35,262:INFO:Starting cross validation
2025-09-10 17:04:35,265:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:04:37,295:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:37,325:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:37,357:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:37,385:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:37,389:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:37,422:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:37,576:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:04:37,762:INFO:Calculating mean and std
2025-09-10 17:04:37,762:INFO:Creating metrics dataframe
2025-09-10 17:04:37,764:INFO:Uploading results into container
2025-09-10 17:04:37,764:INFO:Uploading model into container now
2025-09-10 17:04:37,764:INFO:_master_model_container: 40
2025-09-10 17:04:37,764:INFO:_display_container: 2
2025-09-10 17:04:37,764:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2025-09-10 17:04:37,764:INFO:create_model() successfully completed......................................
2025-09-10 17:04:37,972:ERROR:create_model() for DummyRegressor(constant=None, quantile=None, strategy='mean') raised an exception or returned all 0.0:
2025-09-10 17:04:37,973:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:04:37,982:INFO:_master_model_container: 40
2025-09-10 17:04:37,982:INFO:_display_container: 2
2025-09-10 17:04:37,982:INFO:[]
2025-09-10 17:04:37,982:INFO:compare_models() successfully completed......................................
2025-09-10 17:06:12,883:INFO:Initializing compare_models()
2025-09-10 17:06:12,883:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=raise, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'raise', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-09-10 17:06:12,883:INFO:Checking exceptions
2025-09-10 17:06:12,888:INFO:Preparing display monitor
2025-09-10 17:06:12,921:INFO:Initializing Linear Regression
2025-09-10 17:06:12,922:INFO:Total runtime is 1.6621748606363933e-05 minutes
2025-09-10 17:06:12,928:INFO:SubProcess create_model() called ==================================
2025-09-10 17:06:12,928:INFO:Initializing create_model()
2025-09-10 17:06:12,929:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5B97D1F50>, model_only=True, return_train_score=False, error_score=raise, kwargs={})
2025-09-10 17:06:12,929:INFO:Checking exceptions
2025-09-10 17:06:12,929:INFO:Importing libraries
2025-09-10 17:06:12,929:INFO:Copying training dataset
2025-09-10 17:06:12,940:INFO:Defining folds
2025-09-10 17:06:12,940:INFO:Declaring metric variables
2025-09-10 17:06:12,945:INFO:Importing untrained model
2025-09-10 17:06:12,952:INFO:Linear Regression Imported successfully
2025-09-10 17:06:12,965:INFO:Starting cross validation
2025-09-10 17:06:12,970:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:06:14,740:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:06:14,856:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:06:14,877:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:06:14,893:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:06:14,938:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:10:37,629:INFO:Initializing create_model()
2025-09-10 17:10:37,629:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=dt, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=True, error_score=0.0, kwargs={})
2025-09-10 17:10:37,629:INFO:Checking exceptions
2025-09-10 17:10:37,647:INFO:Importing libraries
2025-09-10 17:10:37,647:INFO:Copying training dataset
2025-09-10 17:10:37,655:INFO:Defining folds
2025-09-10 17:10:37,655:INFO:Declaring metric variables
2025-09-10 17:10:37,660:INFO:Importing untrained model
2025-09-10 17:10:37,666:INFO:Decision Tree Regressor Imported successfully
2025-09-10 17:10:37,679:INFO:Starting cross validation
2025-09-10 17:10:37,684:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:10:43,677:INFO:Calculating mean and std
2025-09-10 17:10:43,677:INFO:Creating metrics dataframe
2025-09-10 17:10:43,685:INFO:Finalizing model
2025-09-10 17:10:44,546:INFO:Initializing predict_model()
2025-09-10 17:10:44,546:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['TimeStart', 'TimeStop',
                                             'ProductionDate', 'ApproveDate',
                                             'CreateDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Qty', 'Shift', 'isNC'],
                                    transformer=Sim...
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error',
                                       max_depth=None, max_features=None,
                                       max_leaf_nodes=None,
                                       min_impurity_decrease=0.0,
                                       min_samples_leaf=1, min_samples_split=2,
                                       min_weight_fraction_leaf=0.0,
                                       monotonic_cst=None, random_state=123,
                                       splitter='best'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C5BAA46160>)
2025-09-10 17:10:44,546:INFO:Checking exceptions
2025-09-10 17:10:44,546:INFO:Preloading libraries
2025-09-10 17:10:44,546:INFO:Set up data.
2025-09-10 17:10:44,549:INFO:Set up index.
2025-09-10 17:10:44,927:INFO:Uploading results into container
2025-09-10 17:10:44,927:INFO:Uploading model into container now
2025-09-10 17:10:44,935:INFO:_master_model_container: 41
2025-09-10 17:10:44,935:INFO:_display_container: 3
2025-09-10 17:10:44,935:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=123, splitter='best')
2025-09-10 17:10:44,935:INFO:create_model() successfully completed......................................
2025-09-10 17:12:18,904:INFO:Initializing create_model()
2025-09-10 17:12:18,904:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BDDDE410>, estimator=svm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=True, error_score=0.0, kwargs={})
2025-09-10 17:12:18,904:INFO:Checking exceptions
2025-09-10 17:12:18,931:INFO:Importing libraries
2025-09-10 17:12:18,931:INFO:Copying training dataset
2025-09-10 17:12:18,944:INFO:Defining folds
2025-09-10 17:12:18,944:INFO:Declaring metric variables
2025-09-10 17:12:18,952:INFO:Importing untrained model
2025-09-10 17:12:18,959:INFO:Support Vector Regression Imported successfully
2025-09-10 17:12:18,976:INFO:Starting cross validation
2025-09-10 17:12:18,980:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:12:24,854:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\svm\_base.py", line 429, in predict
    X = self._validate_for_predict(X)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\svm\_base.py", line 607, in _validate_for_predict
    X = self._validate_data(
        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SVR does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:12:24,856:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\svm\_base.py", line 429, in predict
    X = self._validate_for_predict(X)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\svm\_base.py", line 607, in _validate_for_predict
    X = self._validate_data(
        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SVR does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:12:24,857:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\svm\_base.py", line 429, in predict
    X = self._validate_for_predict(X)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\svm\_base.py", line 607, in _validate_for_predict
    X = self._validate_data(
        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SVR does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:12:25,547:INFO:Calculating mean and std
2025-09-10 17:12:25,547:INFO:Creating metrics dataframe
2025-09-10 17:12:25,556:INFO:Finalizing model
2025-09-10 17:23:14,507:INFO:PyCaret RegressionExperiment
2025-09-10 17:23:14,507:INFO:Logging name: reg-default-name
2025-09-10 17:23:14,507:INFO:ML Usecase: MLUsecase.REGRESSION
2025-09-10 17:23:14,507:INFO:version 3.3.2
2025-09-10 17:23:14,507:INFO:Initializing setup()
2025-09-10 17:23:14,507:INFO:self.USI: 9afd
2025-09-10 17:23:14,507:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y', 'transform_target_param', 'data', 'X_test', 'USI', 'html_param', 'target_param', 'n_jobs_param', 'X_train', 'pipeline', 'seed', 'exp_id', '_available_plots', 'y_train', 'idx', 'fold_groups_param', 'memory', 'gpu_param', 'y_test', 'fold_generator', 'exp_name_log', '_ml_usecase', 'logging_param', 'X', 'fold_shuffle_param', 'log_plots_param'}
2025-09-10 17:23:14,507:INFO:Checking environment
2025-09-10 17:23:14,507:INFO:python_version: 3.11.10
2025-09-10 17:23:14,507:INFO:python_build: ('main', 'Oct  3 2024 07:22:26')
2025-09-10 17:23:14,507:INFO:machine: AMD64
2025-09-10 17:23:14,507:INFO:platform: Windows-10-10.0.26100-SP0
2025-09-10 17:23:14,507:INFO:Memory: svmem(total=16837152768, available=4195037184, percent=75.1, used=12642115584, free=4195037184)
2025-09-10 17:23:14,507:INFO:Physical Core: 10
2025-09-10 17:23:14,507:INFO:Logical Core: 12
2025-09-10 17:23:14,514:INFO:Checking libraries
2025-09-10 17:23:14,514:INFO:System:
2025-09-10 17:23:14,514:INFO:    python: 3.11.10 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:26) [MSC v.1929 64 bit (AMD64)]
2025-09-10 17:23:14,514:INFO:executable: c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\python.exe
2025-09-10 17:23:14,514:INFO:   machine: Windows-10-10.0.26100-SP0
2025-09-10 17:23:14,514:INFO:PyCaret required dependencies:
2025-09-10 17:23:14,514:INFO:                 pip: 24.2
2025-09-10 17:23:14,514:INFO:          setuptools: 75.1.0
2025-09-10 17:23:14,514:INFO:             pycaret: 3.3.2
2025-09-10 17:23:14,514:INFO:             IPython: 9.2.0
2025-09-10 17:23:14,514:INFO:          ipywidgets: 8.1.7
2025-09-10 17:23:14,514:INFO:                tqdm: 4.67.1
2025-09-10 17:23:14,514:INFO:               numpy: 1.24.4
2025-09-10 17:23:14,514:INFO:              pandas: 1.5.3
2025-09-10 17:23:14,514:INFO:              jinja2: 3.1.6
2025-09-10 17:23:14,514:INFO:               scipy: 1.11.4
2025-09-10 17:23:14,514:INFO:              joblib: 1.3.2
2025-09-10 17:23:14,514:INFO:             sklearn: 1.4.2
2025-09-10 17:23:14,514:INFO:                pyod: 2.0.5
2025-09-10 17:23:14,514:INFO:            imblearn: 0.13.0
2025-09-10 17:23:14,514:INFO:   category_encoders: 2.7.0
2025-09-10 17:23:14,514:INFO:            lightgbm: 4.6.0
2025-09-10 17:23:14,514:INFO:               numba: 0.61.0
2025-09-10 17:23:14,514:INFO:            requests: 2.32.3
2025-09-10 17:23:14,514:INFO:          matplotlib: 3.7.5
2025-09-10 17:23:14,514:INFO:          scikitplot: 0.3.7
2025-09-10 17:23:14,514:INFO:         yellowbrick: 1.5
2025-09-10 17:23:14,514:INFO:              plotly: 5.24.1
2025-09-10 17:23:14,514:INFO:    plotly-resampler: Not installed
2025-09-10 17:23:14,514:INFO:             kaleido: 0.2.1
2025-09-10 17:23:14,514:INFO:           schemdraw: 0.15
2025-09-10 17:23:14,515:INFO:         statsmodels: 0.14.4
2025-09-10 17:23:14,515:INFO:              sktime: 0.26.0
2025-09-10 17:23:14,515:INFO:               tbats: 1.1.3
2025-09-10 17:23:14,515:INFO:            pmdarima: 2.0.4
2025-09-10 17:23:14,515:INFO:              psutil: 7.0.0
2025-09-10 17:23:14,515:INFO:          markupsafe: 3.0.2
2025-09-10 17:23:14,515:INFO:             pickle5: Not installed
2025-09-10 17:23:14,515:INFO:         cloudpickle: 3.1.1
2025-09-10 17:23:14,515:INFO:         deprecation: 2.1.0
2025-09-10 17:23:14,515:INFO:              xxhash: 3.5.0
2025-09-10 17:23:14,515:INFO:           wurlitzer: Not installed
2025-09-10 17:23:14,515:INFO:PyCaret optional dependencies:
2025-09-10 17:23:14,515:INFO:                shap: 0.44.1
2025-09-10 17:23:14,515:INFO:           interpret: 0.6.11
2025-09-10 17:23:14,515:INFO:                umap: 0.5.7
2025-09-10 17:23:14,515:INFO:     ydata_profiling: 4.16.1
2025-09-10 17:23:14,515:INFO:  explainerdashboard: 0.5.1
2025-09-10 17:23:14,515:INFO:             autoviz: Not installed
2025-09-10 17:23:14,515:INFO:           fairlearn: 0.7.0
2025-09-10 17:23:14,515:INFO:          deepchecks: Not installed
2025-09-10 17:23:14,515:INFO:             xgboost: 3.0.2
2025-09-10 17:23:14,515:INFO:            catboost: 1.2.8
2025-09-10 17:23:14,515:INFO:              kmodes: 0.12.2
2025-09-10 17:23:14,515:INFO:             mlxtend: 0.23.4
2025-09-10 17:23:14,515:INFO:       statsforecast: 1.5.0
2025-09-10 17:23:14,515:INFO:        tune_sklearn: Not installed
2025-09-10 17:23:14,515:INFO:                 ray: Not installed
2025-09-10 17:23:14,515:INFO:            hyperopt: 0.2.7
2025-09-10 17:23:14,515:INFO:              optuna: 4.3.0
2025-09-10 17:23:14,515:INFO:               skopt: 0.10.2
2025-09-10 17:23:14,515:INFO:              mlflow: 3.1.0
2025-09-10 17:23:14,515:INFO:              gradio: 5.33.1
2025-09-10 17:23:14,515:INFO:             fastapi: 0.115.12
2025-09-10 17:23:14,515:INFO:             uvicorn: 0.34.3
2025-09-10 17:23:14,515:INFO:              m2cgen: 0.10.0
2025-09-10 17:23:14,515:INFO:           evidently: 0.4.40
2025-09-10 17:23:14,515:INFO:               fugue: 0.8.7
2025-09-10 17:23:14,515:INFO:           streamlit: 1.45.1
2025-09-10 17:23:14,515:INFO:             prophet: 1.1.7
2025-09-10 17:23:14,515:INFO:None
2025-09-10 17:23:14,516:INFO:Set up data.
2025-09-10 17:23:14,531:INFO:Set up folding strategy.
2025-09-10 17:23:14,531:INFO:Set up train/test split.
2025-09-10 17:23:14,547:INFO:Set up index.
2025-09-10 17:23:14,547:INFO:Assigning column types.
2025-09-10 17:23:14,560:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-09-10 17:23:14,560:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-09-10 17:23:14,564:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-09-10 17:23:14,573:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-09-10 17:23:14,618:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:23:14,632:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:23:14,632:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:23:14,632:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:23:14,632:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-09-10 17:23:14,648:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-09-10 17:23:14,650:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-09-10 17:23:14,683:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:23:14,715:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:23:14,715:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:23:14,715:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:23:14,715:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-09-10 17:23:14,715:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-09-10 17:23:14,715:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-09-10 17:23:14,764:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:23:14,788:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:23:14,788:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:23:14,788:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:23:14,788:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-09-10 17:23:14,788:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-09-10 17:23:14,831:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:23:14,859:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:23:14,859:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:23:14,861:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:23:14,861:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-09-10 17:23:14,867:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-09-10 17:23:14,900:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:23:14,918:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:23:14,918:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:23:14,918:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:23:14,932:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-09-10 17:23:14,965:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:23:14,982:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:23:14,982:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:23:14,982:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:23:14,982:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-09-10 17:23:15,032:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:23:15,048:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:23:15,048:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:23:15,048:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:23:15,100:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:23:15,115:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:23:15,115:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:23:15,115:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:23:15,130:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-09-10 17:23:15,165:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:23:15,181:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:23:15,181:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:23:15,234:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:23:15,248:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:23:15,248:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:23:15,248:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-09-10 17:23:15,315:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:23:15,330:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:23:15,395:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:23:15,397:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:23:15,398:INFO:Preparing preprocessing pipeline...
2025-09-10 17:23:15,398:INFO:Set up date feature engineering.
2025-09-10 17:23:15,398:INFO:Set up iterative imputation.
2025-09-10 17:23:15,465:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:23:15,465:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:23:15,481:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-10 17:23:15,498:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:23:15,498:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:23:15,539:INFO:Set up encoding of categorical features.
2025-09-10 17:23:15,539:INFO:Set up removing multicollinearity.
2025-09-10 17:23:15,539:INFO:Set up column transformation.
2025-09-10 17:23:15,539:INFO:Set up feature normalization.
2025-09-10 17:23:15,539:INFO:Set up column name cleaning.
2025-09-10 17:23:36,734:INFO:PyCaret RegressionExperiment
2025-09-10 17:23:36,734:INFO:Logging name: reg-default-name
2025-09-10 17:23:36,735:INFO:ML Usecase: MLUsecase.REGRESSION
2025-09-10 17:23:36,735:INFO:version 3.3.2
2025-09-10 17:23:36,735:INFO:Initializing setup()
2025-09-10 17:23:36,735:INFO:self.USI: da1d
2025-09-10 17:23:36,735:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y', 'transform_target_param', 'data', 'X_test', 'USI', 'html_param', 'target_param', 'n_jobs_param', 'X_train', 'pipeline', 'seed', 'exp_id', '_available_plots', 'y_train', 'idx', 'fold_groups_param', 'memory', 'gpu_param', 'y_test', 'fold_generator', 'exp_name_log', '_ml_usecase', 'logging_param', 'X', 'fold_shuffle_param', 'log_plots_param'}
2025-09-10 17:23:36,735:INFO:Checking environment
2025-09-10 17:23:36,735:INFO:python_version: 3.11.10
2025-09-10 17:23:36,735:INFO:python_build: ('main', 'Oct  3 2024 07:22:26')
2025-09-10 17:23:36,735:INFO:machine: AMD64
2025-09-10 17:23:36,735:INFO:platform: Windows-10-10.0.26100-SP0
2025-09-10 17:23:36,742:INFO:Memory: svmem(total=16837152768, available=4144222208, percent=75.4, used=12692930560, free=4144222208)
2025-09-10 17:23:36,742:INFO:Physical Core: 10
2025-09-10 17:23:36,743:INFO:Logical Core: 12
2025-09-10 17:23:36,743:INFO:Checking libraries
2025-09-10 17:23:36,743:INFO:System:
2025-09-10 17:23:36,743:INFO:    python: 3.11.10 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:26) [MSC v.1929 64 bit (AMD64)]
2025-09-10 17:23:36,743:INFO:executable: c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\python.exe
2025-09-10 17:23:36,743:INFO:   machine: Windows-10-10.0.26100-SP0
2025-09-10 17:23:36,743:INFO:PyCaret required dependencies:
2025-09-10 17:23:36,743:INFO:                 pip: 24.2
2025-09-10 17:23:36,743:INFO:          setuptools: 75.1.0
2025-09-10 17:23:36,743:INFO:             pycaret: 3.3.2
2025-09-10 17:23:36,743:INFO:             IPython: 9.2.0
2025-09-10 17:23:36,743:INFO:          ipywidgets: 8.1.7
2025-09-10 17:23:36,743:INFO:                tqdm: 4.67.1
2025-09-10 17:23:36,743:INFO:               numpy: 1.24.4
2025-09-10 17:23:36,743:INFO:              pandas: 1.5.3
2025-09-10 17:23:36,744:INFO:              jinja2: 3.1.6
2025-09-10 17:23:36,744:INFO:               scipy: 1.11.4
2025-09-10 17:23:36,744:INFO:              joblib: 1.3.2
2025-09-10 17:23:36,744:INFO:             sklearn: 1.4.2
2025-09-10 17:23:36,744:INFO:                pyod: 2.0.5
2025-09-10 17:23:36,744:INFO:            imblearn: 0.13.0
2025-09-10 17:23:36,744:INFO:   category_encoders: 2.7.0
2025-09-10 17:23:36,744:INFO:            lightgbm: 4.6.0
2025-09-10 17:23:36,744:INFO:               numba: 0.61.0
2025-09-10 17:23:36,744:INFO:            requests: 2.32.3
2025-09-10 17:23:36,744:INFO:          matplotlib: 3.7.5
2025-09-10 17:23:36,744:INFO:          scikitplot: 0.3.7
2025-09-10 17:23:36,744:INFO:         yellowbrick: 1.5
2025-09-10 17:23:36,744:INFO:              plotly: 5.24.1
2025-09-10 17:23:36,744:INFO:    plotly-resampler: Not installed
2025-09-10 17:23:36,744:INFO:             kaleido: 0.2.1
2025-09-10 17:23:36,744:INFO:           schemdraw: 0.15
2025-09-10 17:23:36,744:INFO:         statsmodels: 0.14.4
2025-09-10 17:23:36,744:INFO:              sktime: 0.26.0
2025-09-10 17:23:36,744:INFO:               tbats: 1.1.3
2025-09-10 17:23:36,744:INFO:            pmdarima: 2.0.4
2025-09-10 17:23:36,744:INFO:              psutil: 7.0.0
2025-09-10 17:23:36,744:INFO:          markupsafe: 3.0.2
2025-09-10 17:23:36,744:INFO:             pickle5: Not installed
2025-09-10 17:23:36,744:INFO:         cloudpickle: 3.1.1
2025-09-10 17:23:36,744:INFO:         deprecation: 2.1.0
2025-09-10 17:23:36,744:INFO:              xxhash: 3.5.0
2025-09-10 17:23:36,745:INFO:           wurlitzer: Not installed
2025-09-10 17:23:36,745:INFO:PyCaret optional dependencies:
2025-09-10 17:23:36,745:INFO:                shap: 0.44.1
2025-09-10 17:23:36,745:INFO:           interpret: 0.6.11
2025-09-10 17:23:36,745:INFO:                umap: 0.5.7
2025-09-10 17:23:36,745:INFO:     ydata_profiling: 4.16.1
2025-09-10 17:23:36,745:INFO:  explainerdashboard: 0.5.1
2025-09-10 17:23:36,745:INFO:             autoviz: Not installed
2025-09-10 17:23:36,745:INFO:           fairlearn: 0.7.0
2025-09-10 17:23:36,745:INFO:          deepchecks: Not installed
2025-09-10 17:23:36,745:INFO:             xgboost: 3.0.2
2025-09-10 17:23:36,745:INFO:            catboost: 1.2.8
2025-09-10 17:23:36,745:INFO:              kmodes: 0.12.2
2025-09-10 17:23:36,745:INFO:             mlxtend: 0.23.4
2025-09-10 17:23:36,745:INFO:       statsforecast: 1.5.0
2025-09-10 17:23:36,745:INFO:        tune_sklearn: Not installed
2025-09-10 17:23:36,745:INFO:                 ray: Not installed
2025-09-10 17:23:36,745:INFO:            hyperopt: 0.2.7
2025-09-10 17:23:36,745:INFO:              optuna: 4.3.0
2025-09-10 17:23:36,745:INFO:               skopt: 0.10.2
2025-09-10 17:23:36,745:INFO:              mlflow: 3.1.0
2025-09-10 17:23:36,745:INFO:              gradio: 5.33.1
2025-09-10 17:23:36,745:INFO:             fastapi: 0.115.12
2025-09-10 17:23:36,745:INFO:             uvicorn: 0.34.3
2025-09-10 17:23:36,745:INFO:              m2cgen: 0.10.0
2025-09-10 17:23:36,746:INFO:           evidently: 0.4.40
2025-09-10 17:23:36,746:INFO:               fugue: 0.8.7
2025-09-10 17:23:36,746:INFO:           streamlit: 1.45.1
2025-09-10 17:23:36,746:INFO:             prophet: 1.1.7
2025-09-10 17:23:36,746:INFO:None
2025-09-10 17:23:36,746:INFO:Set up data.
2025-09-10 17:23:36,767:INFO:Set up folding strategy.
2025-09-10 17:23:36,767:INFO:Set up train/test split.
2025-09-10 17:23:36,767:INFO:Set up index.
2025-09-10 17:23:36,767:INFO:Assigning column types.
2025-09-10 17:23:36,781:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-09-10 17:23:36,781:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-09-10 17:23:36,784:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-09-10 17:23:36,786:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-09-10 17:23:36,815:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:23:36,845:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:23:36,845:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:23:36,847:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:23:36,847:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-09-10 17:23:36,850:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-09-10 17:23:36,853:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-09-10 17:23:36,882:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:23:36,897:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:23:36,897:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:23:36,913:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:23:36,914:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-09-10 17:23:36,916:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-09-10 17:23:36,916:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-09-10 17:23:36,955:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:23:36,980:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:23:36,981:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:23:36,982:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:23:36,984:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-09-10 17:23:36,987:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-09-10 17:23:37,024:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:23:37,049:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:23:37,049:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:23:37,049:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:23:37,049:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-09-10 17:23:37,049:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-09-10 17:23:37,082:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:23:37,116:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:23:37,116:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:23:37,116:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:23:37,116:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-09-10 17:23:37,158:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:23:37,182:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:23:37,182:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:23:37,184:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:23:37,185:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-09-10 17:23:37,214:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:23:37,252:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:23:37,252:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:23:37,252:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:23:37,297:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:23:37,314:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:23:37,314:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:23:37,314:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:23:37,314:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-09-10 17:23:37,364:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:23:37,388:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:23:37,390:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:23:37,432:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:23:37,447:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:23:37,447:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:23:37,447:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-09-10 17:23:37,514:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:23:37,514:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:23:37,580:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:23:37,580:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:23:37,580:INFO:Preparing preprocessing pipeline...
2025-09-10 17:23:37,580:INFO:Set up date feature engineering.
2025-09-10 17:23:37,580:INFO:Set up simple imputation.
2025-09-10 17:23:37,595:INFO:Set up encoding of categorical features.
2025-09-10 17:23:37,596:INFO:Set up removing multicollinearity.
2025-09-10 17:23:37,596:INFO:Set up column transformation.
2025-09-10 17:23:37,596:INFO:Set up feature normalization.
2025-09-10 17:23:37,597:INFO:Set up column name cleaning.
2025-09-10 17:23:38,058:INFO:Finished creating preprocessing pipeline.
2025-09-10 17:23:38,066:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\SBM_ME~1\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['TimeStart', 'TimeStop',
                                             'ProductionDate', 'ApproveDate',
                                             'CreateDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    inc...
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-09-10 17:23:38,066:INFO:Creating final display dataframe.
2025-09-10 17:23:38,247:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target         Man Power
2                   Target type        Regression
3           Original data shape        (7103, 26)
4        Transformed data shape       (7103, 121)
5   Transformed train set shape       (4972, 121)
6    Transformed test set shape       (2131, 121)
7              Numeric features                 3
8                 Date features                 5
9          Categorical features                17
10     Rows with missing values             93.4%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17     Remove multicollinearity              True
18  Multicollinearity threshold              0.95
19               Transformation              True
20        Transformation method       yeo-johnson
21                    Normalize              True
22             Normalize method            zscore
23               Fold Generator             KFold
24                  Fold Number                10
25                     CPU Jobs                -1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  reg-default-name
29                          USI              da1d
2025-09-10 17:23:38,337:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:23:38,338:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:23:38,420:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:23:38,423:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:23:38,423:INFO:setup() successfully completed in 1.74s...............
2025-09-10 17:23:59,076:INFO:Initializing compare_models()
2025-09-10 17:23:59,076:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-09-10 17:23:59,076:INFO:Checking exceptions
2025-09-10 17:23:59,079:INFO:Preparing display monitor
2025-09-10 17:23:59,100:INFO:Initializing Linear Regression
2025-09-10 17:23:59,100:INFO:Total runtime is 0.0 minutes
2025-09-10 17:23:59,112:INFO:SubProcess create_model() called ==================================
2025-09-10 17:23:59,112:INFO:Initializing create_model()
2025-09-10 17:23:59,112:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:23:59,113:INFO:Checking exceptions
2025-09-10 17:23:59,113:INFO:Importing libraries
2025-09-10 17:23:59,113:INFO:Copying training dataset
2025-09-10 17:23:59,118:INFO:Defining folds
2025-09-10 17:23:59,119:INFO:Declaring metric variables
2025-09-10 17:23:59,126:INFO:Importing untrained model
2025-09-10 17:23:59,132:INFO:Linear Regression Imported successfully
2025-09-10 17:23:59,145:INFO:Starting cross validation
2025-09-10 17:23:59,150:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:24:06,447:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:06,581:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:06,615:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:06,663:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:06,737:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:06,823:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:06,848:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:06,851:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:06,851:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:06,852:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:06,964:INFO:Calculating mean and std
2025-09-10 17:24:06,966:INFO:Creating metrics dataframe
2025-09-10 17:24:06,968:INFO:Uploading results into container
2025-09-10 17:24:06,968:INFO:Uploading model into container now
2025-09-10 17:24:06,970:INFO:_master_model_container: 1
2025-09-10 17:24:06,970:INFO:_display_container: 2
2025-09-10 17:24:06,970:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, positive=False)
2025-09-10 17:24:06,970:INFO:create_model() successfully completed......................................
2025-09-10 17:24:07,259:WARNING:create_model() for LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, positive=False) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:24:07,259:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:24:07,259:INFO:Initializing create_model()
2025-09-10 17:24:07,259:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:24:07,259:INFO:Checking exceptions
2025-09-10 17:24:07,259:INFO:Importing libraries
2025-09-10 17:24:07,259:INFO:Copying training dataset
2025-09-10 17:24:07,268:INFO:Defining folds
2025-09-10 17:24:07,268:INFO:Declaring metric variables
2025-09-10 17:24:07,272:INFO:Importing untrained model
2025-09-10 17:24:07,272:INFO:Linear Regression Imported successfully
2025-09-10 17:24:07,291:INFO:Starting cross validation
2025-09-10 17:24:07,293:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:24:09,074:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:09,082:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:09,095:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:09,105:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:09,107:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:09,107:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:09,115:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:09,363:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:09,365:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:09,365:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:11,813:INFO:Calculating mean and std
2025-09-10 17:24:11,815:INFO:Creating metrics dataframe
2025-09-10 17:24:11,817:INFO:Uploading results into container
2025-09-10 17:24:11,821:INFO:Uploading model into container now
2025-09-10 17:24:11,821:INFO:_master_model_container: 2
2025-09-10 17:24:11,821:INFO:_display_container: 2
2025-09-10 17:24:11,821:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, positive=False)
2025-09-10 17:24:11,821:INFO:create_model() successfully completed......................................
2025-09-10 17:24:12,033:ERROR:create_model() for LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, positive=False) raised an exception or returned all 0.0:
2025-09-10 17:24:12,033:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:24:12,033:INFO:Initializing Lasso Regression
2025-09-10 17:24:12,033:INFO:Total runtime is 0.21554551521937051 minutes
2025-09-10 17:24:12,046:INFO:SubProcess create_model() called ==================================
2025-09-10 17:24:12,047:INFO:Initializing create_model()
2025-09-10 17:24:12,047:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:24:12,047:INFO:Checking exceptions
2025-09-10 17:24:12,047:INFO:Importing libraries
2025-09-10 17:24:12,047:INFO:Copying training dataset
2025-09-10 17:24:12,050:INFO:Defining folds
2025-09-10 17:24:12,050:INFO:Declaring metric variables
2025-09-10 17:24:12,050:INFO:Importing untrained model
2025-09-10 17:24:12,067:INFO:Lasso Regression Imported successfully
2025-09-10 17:24:12,080:INFO:Starting cross validation
2025-09-10 17:24:12,083:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:24:13,998:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:14,022:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:14,041:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:14,041:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:14,054:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:14,079:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:14,083:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:14,216:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py", line 1120, in _decision_function
    return super()._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Lasso does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:14,218:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py", line 1120, in _decision_function
    return super()._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Lasso does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:14,218:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py", line 1120, in _decision_function
    return super()._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Lasso does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:14,231:INFO:Calculating mean and std
2025-09-10 17:24:14,231:INFO:Creating metrics dataframe
2025-09-10 17:24:14,234:INFO:Uploading results into container
2025-09-10 17:24:14,234:INFO:Uploading model into container now
2025-09-10 17:24:14,234:INFO:_master_model_container: 3
2025-09-10 17:24:14,234:INFO:_display_container: 2
2025-09-10 17:24:14,236:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-09-10 17:24:14,236:INFO:create_model() successfully completed......................................
2025-09-10 17:24:14,445:WARNING:create_model() for Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:24:14,445:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:24:14,445:INFO:Initializing create_model()
2025-09-10 17:24:14,445:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:24:14,445:INFO:Checking exceptions
2025-09-10 17:24:14,445:INFO:Importing libraries
2025-09-10 17:24:14,445:INFO:Copying training dataset
2025-09-10 17:24:14,445:INFO:Defining folds
2025-09-10 17:24:14,445:INFO:Declaring metric variables
2025-09-10 17:24:14,445:INFO:Importing untrained model
2025-09-10 17:24:14,463:INFO:Lasso Regression Imported successfully
2025-09-10 17:24:14,463:INFO:Starting cross validation
2025-09-10 17:24:14,474:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:24:16,222:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:16,269:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:16,269:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:16,293:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:16,403:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:16,406:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:16,410:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:16,482:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py", line 1120, in _decision_function
    return super()._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Lasso does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:16,486:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py", line 1120, in _decision_function
    return super()._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Lasso does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:16,486:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py", line 1120, in _decision_function
    return super()._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Lasso does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:16,529:INFO:Calculating mean and std
2025-09-10 17:24:16,530:INFO:Creating metrics dataframe
2025-09-10 17:24:16,531:INFO:Uploading results into container
2025-09-10 17:24:16,531:INFO:Uploading model into container now
2025-09-10 17:24:16,531:INFO:_master_model_container: 4
2025-09-10 17:24:16,531:INFO:_display_container: 2
2025-09-10 17:24:16,531:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-09-10 17:24:16,531:INFO:create_model() successfully completed......................................
2025-09-10 17:24:16,712:ERROR:create_model() for Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False) raised an exception or returned all 0.0:
2025-09-10 17:24:16,712:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:24:16,712:INFO:Initializing Ridge Regression
2025-09-10 17:24:16,712:INFO:Total runtime is 0.2935264547665914 minutes
2025-09-10 17:24:16,729:INFO:SubProcess create_model() called ==================================
2025-09-10 17:24:16,729:INFO:Initializing create_model()
2025-09-10 17:24:16,729:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:24:16,729:INFO:Checking exceptions
2025-09-10 17:24:16,729:INFO:Importing libraries
2025-09-10 17:24:16,729:INFO:Copying training dataset
2025-09-10 17:24:16,736:INFO:Defining folds
2025-09-10 17:24:16,736:INFO:Declaring metric variables
2025-09-10 17:24:16,740:INFO:Importing untrained model
2025-09-10 17:24:16,749:INFO:Ridge Regression Imported successfully
2025-09-10 17:24:16,756:INFO:Starting cross validation
2025-09-10 17:24:16,763:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:24:18,547:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:18,606:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:18,634:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:18,655:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:18,669:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:18,669:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:18,754:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:18,798:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Ridge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:18,801:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Ridge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:18,801:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Ridge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:18,841:INFO:Calculating mean and std
2025-09-10 17:24:18,841:INFO:Creating metrics dataframe
2025-09-10 17:24:18,844:INFO:Uploading results into container
2025-09-10 17:24:18,844:INFO:Uploading model into container now
2025-09-10 17:24:18,844:INFO:_master_model_container: 5
2025-09-10 17:24:18,845:INFO:_display_container: 2
2025-09-10 17:24:18,845:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=123, solver='auto', tol=0.0001)
2025-09-10 17:24:18,845:INFO:create_model() successfully completed......................................
2025-09-10 17:24:19,028:WARNING:create_model() for Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=123, solver='auto', tol=0.0001) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:24:19,028:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:24:19,028:INFO:Initializing create_model()
2025-09-10 17:24:19,028:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:24:19,028:INFO:Checking exceptions
2025-09-10 17:24:19,028:INFO:Importing libraries
2025-09-10 17:24:19,028:INFO:Copying training dataset
2025-09-10 17:24:19,028:INFO:Defining folds
2025-09-10 17:24:19,028:INFO:Declaring metric variables
2025-09-10 17:24:19,047:INFO:Importing untrained model
2025-09-10 17:24:19,048:INFO:Ridge Regression Imported successfully
2025-09-10 17:24:19,062:INFO:Starting cross validation
2025-09-10 17:24:19,062:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:24:20,738:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:20,776:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:20,888:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:20,908:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:20,957:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:20,959:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:20,978:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:21,151:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Ridge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:21,151:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Ridge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:21,151:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Ridge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:21,161:INFO:Calculating mean and std
2025-09-10 17:24:21,162:INFO:Creating metrics dataframe
2025-09-10 17:24:21,167:INFO:Uploading results into container
2025-09-10 17:24:21,167:INFO:Uploading model into container now
2025-09-10 17:24:21,168:INFO:_master_model_container: 6
2025-09-10 17:24:21,168:INFO:_display_container: 2
2025-09-10 17:24:21,168:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=123, solver='auto', tol=0.0001)
2025-09-10 17:24:21,168:INFO:create_model() successfully completed......................................
2025-09-10 17:24:21,346:ERROR:create_model() for Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=123, solver='auto', tol=0.0001) raised an exception or returned all 0.0:
2025-09-10 17:24:21,346:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:24:21,347:INFO:Initializing Elastic Net
2025-09-10 17:24:21,347:INFO:Total runtime is 0.3707722624142965 minutes
2025-09-10 17:24:21,350:INFO:SubProcess create_model() called ==================================
2025-09-10 17:24:21,350:INFO:Initializing create_model()
2025-09-10 17:24:21,350:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:24:21,350:INFO:Checking exceptions
2025-09-10 17:24:21,351:INFO:Importing libraries
2025-09-10 17:24:21,351:INFO:Copying training dataset
2025-09-10 17:24:21,356:INFO:Defining folds
2025-09-10 17:24:21,356:INFO:Declaring metric variables
2025-09-10 17:24:21,362:INFO:Importing untrained model
2025-09-10 17:24:21,368:INFO:Elastic Net Imported successfully
2025-09-10 17:24:21,380:INFO:Starting cross validation
2025-09-10 17:24:21,385:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:24:23,164:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:23,189:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:23,203:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:23,237:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:23,247:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:23,285:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:23,302:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:23,403:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py", line 1120, in _decision_function
    return super()._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:23,403:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py", line 1120, in _decision_function
    return super()._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:23,403:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py", line 1120, in _decision_function
    return super()._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:23,453:INFO:Calculating mean and std
2025-09-10 17:24:23,454:INFO:Creating metrics dataframe
2025-09-10 17:24:23,454:INFO:Uploading results into container
2025-09-10 17:24:23,454:INFO:Uploading model into container now
2025-09-10 17:24:23,454:INFO:_master_model_container: 7
2025-09-10 17:24:23,454:INFO:_display_container: 2
2025-09-10 17:24:23,454:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=123,
           selection='cyclic', tol=0.0001, warm_start=False)
2025-09-10 17:24:23,454:INFO:create_model() successfully completed......................................
2025-09-10 17:24:23,668:WARNING:create_model() for ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=123,
           selection='cyclic', tol=0.0001, warm_start=False) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:24:23,668:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:24:23,668:INFO:Initializing create_model()
2025-09-10 17:24:23,668:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:24:23,668:INFO:Checking exceptions
2025-09-10 17:24:23,668:INFO:Importing libraries
2025-09-10 17:24:23,668:INFO:Copying training dataset
2025-09-10 17:24:23,668:INFO:Defining folds
2025-09-10 17:24:23,668:INFO:Declaring metric variables
2025-09-10 17:24:23,684:INFO:Importing untrained model
2025-09-10 17:24:23,685:INFO:Elastic Net Imported successfully
2025-09-10 17:24:23,696:INFO:Starting cross validation
2025-09-10 17:24:23,696:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:24:25,610:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:25,615:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:25,641:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:25,667:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:25,669:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:25,679:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:25,698:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:25,868:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py", line 1120, in _decision_function
    return super()._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:25,869:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py", line 1120, in _decision_function
    return super()._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:25,869:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py", line 1120, in _decision_function
    return super()._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:25,879:INFO:Calculating mean and std
2025-09-10 17:24:25,879:INFO:Creating metrics dataframe
2025-09-10 17:24:25,879:INFO:Uploading results into container
2025-09-10 17:24:25,884:INFO:Uploading model into container now
2025-09-10 17:24:25,885:INFO:_master_model_container: 8
2025-09-10 17:24:25,885:INFO:_display_container: 2
2025-09-10 17:24:25,885:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=123,
           selection='cyclic', tol=0.0001, warm_start=False)
2025-09-10 17:24:25,885:INFO:create_model() successfully completed......................................
2025-09-10 17:24:26,062:ERROR:create_model() for ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=123,
           selection='cyclic', tol=0.0001, warm_start=False) raised an exception or returned all 0.0:
2025-09-10 17:24:26,062:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:24:26,062:INFO:Initializing Least Angle Regression
2025-09-10 17:24:26,062:INFO:Total runtime is 0.44936438004175827 minutes
2025-09-10 17:24:26,062:INFO:SubProcess create_model() called ==================================
2025-09-10 17:24:26,062:INFO:Initializing create_model()
2025-09-10 17:24:26,062:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:24:26,062:INFO:Checking exceptions
2025-09-10 17:24:26,062:INFO:Importing libraries
2025-09-10 17:24:26,062:INFO:Copying training dataset
2025-09-10 17:24:26,078:INFO:Defining folds
2025-09-10 17:24:26,078:INFO:Declaring metric variables
2025-09-10 17:24:26,087:INFO:Importing untrained model
2025-09-10 17:24:26,087:INFO:Least Angle Regression Imported successfully
2025-09-10 17:24:26,096:INFO:Starting cross validation
2025-09-10 17:24:26,096:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:24:27,834:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:27,872:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:27,912:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:27,954:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:27,975:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:27,996:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:28,018:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:28,102:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Lars does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:28,102:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Lars does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:28,102:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Lars does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:28,120:INFO:Calculating mean and std
2025-09-10 17:24:28,120:INFO:Creating metrics dataframe
2025-09-10 17:24:28,120:INFO:Uploading results into container
2025-09-10 17:24:28,120:INFO:Uploading model into container now
2025-09-10 17:24:28,120:INFO:_master_model_container: 9
2025-09-10 17:24:28,120:INFO:_display_container: 2
2025-09-10 17:24:28,120:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False)
2025-09-10 17:24:28,120:INFO:create_model() successfully completed......................................
2025-09-10 17:24:28,312:WARNING:create_model() for Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:24:28,312:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:24:28,313:INFO:Initializing create_model()
2025-09-10 17:24:28,313:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:24:28,313:INFO:Checking exceptions
2025-09-10 17:24:28,313:INFO:Importing libraries
2025-09-10 17:24:28,313:INFO:Copying training dataset
2025-09-10 17:24:28,317:INFO:Defining folds
2025-09-10 17:24:28,318:INFO:Declaring metric variables
2025-09-10 17:24:28,321:INFO:Importing untrained model
2025-09-10 17:24:28,329:INFO:Least Angle Regression Imported successfully
2025-09-10 17:24:28,329:INFO:Starting cross validation
2025-09-10 17:24:28,329:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:24:29,925:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:29,935:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:29,986:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:30,037:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:30,037:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:30,045:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:30,090:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:30,229:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Lars does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:30,231:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Lars does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:30,231:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
Lars does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:30,241:INFO:Calculating mean and std
2025-09-10 17:24:30,241:INFO:Creating metrics dataframe
2025-09-10 17:24:30,241:INFO:Uploading results into container
2025-09-10 17:24:30,245:INFO:Uploading model into container now
2025-09-10 17:24:30,245:INFO:_master_model_container: 10
2025-09-10 17:24:30,245:INFO:_display_container: 2
2025-09-10 17:24:30,245:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False)
2025-09-10 17:24:30,245:INFO:create_model() successfully completed......................................
2025-09-10 17:24:30,426:ERROR:create_model() for Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False) raised an exception or returned all 0.0:
2025-09-10 17:24:30,426:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:24:30,426:INFO:Initializing Lasso Least Angle Regression
2025-09-10 17:24:30,426:INFO:Total runtime is 0.5220978180567424 minutes
2025-09-10 17:24:30,426:INFO:SubProcess create_model() called ==================================
2025-09-10 17:24:30,426:INFO:Initializing create_model()
2025-09-10 17:24:30,426:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:24:30,426:INFO:Checking exceptions
2025-09-10 17:24:30,426:INFO:Importing libraries
2025-09-10 17:24:30,426:INFO:Copying training dataset
2025-09-10 17:24:30,426:INFO:Defining folds
2025-09-10 17:24:30,426:INFO:Declaring metric variables
2025-09-10 17:24:30,446:INFO:Importing untrained model
2025-09-10 17:24:30,446:INFO:Lasso Least Angle Regression Imported successfully
2025-09-10 17:24:30,460:INFO:Starting cross validation
2025-09-10 17:24:30,460:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:24:32,045:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:32,112:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:32,133:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:32,154:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:32,170:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:32,199:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:32,203:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:32,246:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LassoLars does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:32,256:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LassoLars does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:32,256:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LassoLars does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:32,329:INFO:Calculating mean and std
2025-09-10 17:24:32,329:INFO:Creating metrics dataframe
2025-09-10 17:24:32,329:INFO:Uploading results into container
2025-09-10 17:24:32,329:INFO:Uploading model into container now
2025-09-10 17:24:32,329:INFO:_master_model_container: 11
2025-09-10 17:24:32,329:INFO:_display_container: 2
2025-09-10 17:24:32,329:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False)
2025-09-10 17:24:32,329:INFO:create_model() successfully completed......................................
2025-09-10 17:24:32,510:WARNING:create_model() for LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:24:32,510:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:24:32,510:INFO:Initializing create_model()
2025-09-10 17:24:32,510:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:24:32,510:INFO:Checking exceptions
2025-09-10 17:24:32,510:INFO:Importing libraries
2025-09-10 17:24:32,510:INFO:Copying training dataset
2025-09-10 17:24:32,519:INFO:Defining folds
2025-09-10 17:24:32,519:INFO:Declaring metric variables
2025-09-10 17:24:32,527:INFO:Importing untrained model
2025-09-10 17:24:32,529:INFO:Lasso Least Angle Regression Imported successfully
2025-09-10 17:24:32,529:INFO:Starting cross validation
2025-09-10 17:24:32,544:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:24:34,131:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:34,154:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:34,163:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:34,163:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:34,190:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:34,241:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:34,251:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:34,377:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LassoLars does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:34,377:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LassoLars does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:34,377:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
LassoLars does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:34,386:INFO:Calculating mean and std
2025-09-10 17:24:34,386:INFO:Creating metrics dataframe
2025-09-10 17:24:34,386:INFO:Uploading results into container
2025-09-10 17:24:34,386:INFO:Uploading model into container now
2025-09-10 17:24:34,386:INFO:_master_model_container: 12
2025-09-10 17:24:34,386:INFO:_display_container: 2
2025-09-10 17:24:34,386:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False)
2025-09-10 17:24:34,386:INFO:create_model() successfully completed......................................
2025-09-10 17:24:34,556:ERROR:create_model() for LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False) raised an exception or returned all 0.0:
2025-09-10 17:24:34,556:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:24:34,556:INFO:Initializing Orthogonal Matching Pursuit
2025-09-10 17:24:34,556:INFO:Total runtime is 0.5909365018208822 minutes
2025-09-10 17:24:34,572:INFO:SubProcess create_model() called ==================================
2025-09-10 17:24:34,572:INFO:Initializing create_model()
2025-09-10 17:24:34,572:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:24:34,572:INFO:Checking exceptions
2025-09-10 17:24:34,572:INFO:Importing libraries
2025-09-10 17:24:34,572:INFO:Copying training dataset
2025-09-10 17:24:34,577:INFO:Defining folds
2025-09-10 17:24:34,577:INFO:Declaring metric variables
2025-09-10 17:24:34,586:INFO:Importing untrained model
2025-09-10 17:24:34,586:INFO:Orthogonal Matching Pursuit Imported successfully
2025-09-10 17:24:34,595:INFO:Starting cross validation
2025-09-10 17:24:34,595:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:24:36,210:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:36,210:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:36,214:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:36,226:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:36,238:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:36,278:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:36,292:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:36,463:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
OrthogonalMatchingPursuit does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:36,463:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
OrthogonalMatchingPursuit does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:36,463:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
OrthogonalMatchingPursuit does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:36,474:INFO:Calculating mean and std
2025-09-10 17:24:36,474:INFO:Creating metrics dataframe
2025-09-10 17:24:36,474:INFO:Uploading results into container
2025-09-10 17:24:36,474:INFO:Uploading model into container now
2025-09-10 17:24:36,478:INFO:_master_model_container: 13
2025-09-10 17:24:36,478:INFO:_display_container: 2
2025-09-10 17:24:36,478:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None)
2025-09-10 17:24:36,478:INFO:create_model() successfully completed......................................
2025-09-10 17:24:36,655:WARNING:create_model() for OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:24:36,655:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:24:36,655:INFO:Initializing create_model()
2025-09-10 17:24:36,655:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:24:36,655:INFO:Checking exceptions
2025-09-10 17:24:36,655:INFO:Importing libraries
2025-09-10 17:24:36,655:INFO:Copying training dataset
2025-09-10 17:24:36,663:INFO:Defining folds
2025-09-10 17:24:36,663:INFO:Declaring metric variables
2025-09-10 17:24:36,663:INFO:Importing untrained model
2025-09-10 17:24:36,677:INFO:Orthogonal Matching Pursuit Imported successfully
2025-09-10 17:24:36,679:INFO:Starting cross validation
2025-09-10 17:24:36,679:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:24:38,280:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:38,294:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:38,344:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:38,349:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:38,394:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:38,416:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:38,453:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:38,553:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
OrthogonalMatchingPursuit does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:38,555:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
OrthogonalMatchingPursuit does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:38,555:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
OrthogonalMatchingPursuit does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:38,561:INFO:Calculating mean and std
2025-09-10 17:24:38,561:INFO:Creating metrics dataframe
2025-09-10 17:24:38,565:INFO:Uploading results into container
2025-09-10 17:24:38,566:INFO:Uploading model into container now
2025-09-10 17:24:38,566:INFO:_master_model_container: 14
2025-09-10 17:24:38,566:INFO:_display_container: 2
2025-09-10 17:24:38,566:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None)
2025-09-10 17:24:38,566:INFO:create_model() successfully completed......................................
2025-09-10 17:24:38,745:ERROR:create_model() for OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None) raised an exception or returned all 0.0:
2025-09-10 17:24:38,746:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:24:38,746:INFO:Initializing Bayesian Ridge
2025-09-10 17:24:38,746:INFO:Total runtime is 0.6607629815737407 minutes
2025-09-10 17:24:38,749:INFO:SubProcess create_model() called ==================================
2025-09-10 17:24:38,750:INFO:Initializing create_model()
2025-09-10 17:24:38,750:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:24:38,750:INFO:Checking exceptions
2025-09-10 17:24:38,750:INFO:Importing libraries
2025-09-10 17:24:38,750:INFO:Copying training dataset
2025-09-10 17:24:38,756:INFO:Defining folds
2025-09-10 17:24:38,756:INFO:Declaring metric variables
2025-09-10 17:24:38,762:INFO:Importing untrained model
2025-09-10 17:24:38,762:INFO:Bayesian Ridge Imported successfully
2025-09-10 17:24:38,778:INFO:Starting cross validation
2025-09-10 17:24:38,779:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:24:40,472:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:40,487:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:40,494:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:40,494:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:40,527:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:40,532:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:40,561:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:40,698:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_bayes.py", line 421, in predict
    y_mean = self._decision_function(X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
BayesianRidge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:40,698:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_bayes.py", line 421, in predict
    y_mean = self._decision_function(X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
BayesianRidge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:40,698:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_bayes.py", line 421, in predict
    y_mean = self._decision_function(X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
BayesianRidge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:40,708:INFO:Calculating mean and std
2025-09-10 17:24:40,710:INFO:Creating metrics dataframe
2025-09-10 17:24:40,711:INFO:Uploading results into container
2025-09-10 17:24:40,711:INFO:Uploading model into container now
2025-09-10 17:24:40,711:INFO:_master_model_container: 15
2025-09-10 17:24:40,711:INFO:_display_container: 2
2025-09-10 17:24:40,711:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, max_iter=None,
              n_iter='deprecated', tol=0.001, verbose=False)
2025-09-10 17:24:40,711:INFO:create_model() successfully completed......................................
2025-09-10 17:24:40,916:WARNING:create_model() for BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, max_iter=None,
              n_iter='deprecated', tol=0.001, verbose=False) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:24:40,916:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:24:40,916:INFO:Initializing create_model()
2025-09-10 17:24:40,916:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:24:40,916:INFO:Checking exceptions
2025-09-10 17:24:40,916:INFO:Importing libraries
2025-09-10 17:24:40,916:INFO:Copying training dataset
2025-09-10 17:24:40,927:INFO:Defining folds
2025-09-10 17:24:40,927:INFO:Declaring metric variables
2025-09-10 17:24:40,932:INFO:Importing untrained model
2025-09-10 17:24:40,933:INFO:Bayesian Ridge Imported successfully
2025-09-10 17:24:40,944:INFO:Starting cross validation
2025-09-10 17:24:40,947:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:24:42,498:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:42,518:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:42,548:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:42,553:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:42,561:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:42,580:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:42,632:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:42,747:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_bayes.py", line 421, in predict
    y_mean = self._decision_function(X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
BayesianRidge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:42,749:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_bayes.py", line 421, in predict
    y_mean = self._decision_function(X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
BayesianRidge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:42,749:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_bayes.py", line 421, in predict
    y_mean = self._decision_function(X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
BayesianRidge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:42,757:INFO:Calculating mean and std
2025-09-10 17:24:42,758:INFO:Creating metrics dataframe
2025-09-10 17:24:42,761:INFO:Uploading results into container
2025-09-10 17:24:42,761:INFO:Uploading model into container now
2025-09-10 17:24:42,761:INFO:_master_model_container: 16
2025-09-10 17:24:42,764:INFO:_display_container: 2
2025-09-10 17:24:42,764:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, max_iter=None,
              n_iter='deprecated', tol=0.001, verbose=False)
2025-09-10 17:24:42,764:INFO:create_model() successfully completed......................................
2025-09-10 17:24:42,965:ERROR:create_model() for BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, max_iter=None,
              n_iter='deprecated', tol=0.001, verbose=False) raised an exception or returned all 0.0:
2025-09-10 17:24:42,965:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:24:42,965:INFO:Initializing Passive Aggressive Regressor
2025-09-10 17:24:42,965:INFO:Total runtime is 0.7310709754625957 minutes
2025-09-10 17:24:42,980:INFO:SubProcess create_model() called ==================================
2025-09-10 17:24:42,980:INFO:Initializing create_model()
2025-09-10 17:24:42,981:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:24:42,981:INFO:Checking exceptions
2025-09-10 17:24:42,981:INFO:Importing libraries
2025-09-10 17:24:42,981:INFO:Copying training dataset
2025-09-10 17:24:42,981:INFO:Defining folds
2025-09-10 17:24:42,981:INFO:Declaring metric variables
2025-09-10 17:24:42,981:INFO:Importing untrained model
2025-09-10 17:24:42,997:INFO:Passive Aggressive Regressor Imported successfully
2025-09-10 17:24:42,997:INFO:Starting cross validation
2025-09-10 17:24:43,011:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:24:44,815:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:44,815:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:44,815:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:44,850:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:44,867:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:44,867:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:44,901:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:45,065:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1658, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1640, in _decision_function
    X = self._validate_data(X, accept_sparse="csr", reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
PassiveAggressiveRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:45,065:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1658, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1640, in _decision_function
    X = self._validate_data(X, accept_sparse="csr", reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
PassiveAggressiveRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:45,065:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1658, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1640, in _decision_function
    X = self._validate_data(X, accept_sparse="csr", reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
PassiveAggressiveRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:45,075:INFO:Calculating mean and std
2025-09-10 17:24:45,077:INFO:Creating metrics dataframe
2025-09-10 17:24:45,080:INFO:Uploading results into container
2025-09-10 17:24:45,080:INFO:Uploading model into container now
2025-09-10 17:24:45,081:INFO:_master_model_container: 17
2025-09-10 17:24:45,081:INFO:_display_container: 2
2025-09-10 17:24:45,082:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=123, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-09-10 17:24:45,082:INFO:create_model() successfully completed......................................
2025-09-10 17:24:45,261:WARNING:create_model() for PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=123, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:24:45,261:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:24:45,261:INFO:Initializing create_model()
2025-09-10 17:24:45,261:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:24:45,261:INFO:Checking exceptions
2025-09-10 17:24:45,261:INFO:Importing libraries
2025-09-10 17:24:45,261:INFO:Copying training dataset
2025-09-10 17:24:45,261:INFO:Defining folds
2025-09-10 17:24:45,261:INFO:Declaring metric variables
2025-09-10 17:24:45,272:INFO:Importing untrained model
2025-09-10 17:24:45,278:INFO:Passive Aggressive Regressor Imported successfully
2025-09-10 17:24:45,278:INFO:Starting cross validation
2025-09-10 17:24:45,278:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:24:47,014:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:47,068:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:47,086:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:47,110:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:47,124:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:47,149:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:47,169:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:47,305:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1658, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1640, in _decision_function
    X = self._validate_data(X, accept_sparse="csr", reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
PassiveAggressiveRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:47,312:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1658, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1640, in _decision_function
    X = self._validate_data(X, accept_sparse="csr", reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
PassiveAggressiveRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:47,312:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1658, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1640, in _decision_function
    X = self._validate_data(X, accept_sparse="csr", reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
PassiveAggressiveRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:47,315:INFO:Calculating mean and std
2025-09-10 17:24:47,315:INFO:Creating metrics dataframe
2025-09-10 17:24:47,320:INFO:Uploading results into container
2025-09-10 17:24:47,321:INFO:Uploading model into container now
2025-09-10 17:24:47,322:INFO:_master_model_container: 18
2025-09-10 17:24:47,322:INFO:_display_container: 2
2025-09-10 17:24:47,322:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=123, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-09-10 17:24:47,322:INFO:create_model() successfully completed......................................
2025-09-10 17:24:47,494:ERROR:create_model() for PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=123, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False) raised an exception or returned all 0.0:
2025-09-10 17:24:47,509:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:24:47,509:INFO:Initializing Huber Regressor
2025-09-10 17:24:47,509:INFO:Total runtime is 0.8068135817845663 minutes
2025-09-10 17:24:47,510:INFO:SubProcess create_model() called ==================================
2025-09-10 17:24:47,510:INFO:Initializing create_model()
2025-09-10 17:24:47,510:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:24:47,510:INFO:Checking exceptions
2025-09-10 17:24:47,510:INFO:Importing libraries
2025-09-10 17:24:47,510:INFO:Copying training dataset
2025-09-10 17:24:47,510:INFO:Defining folds
2025-09-10 17:24:47,510:INFO:Declaring metric variables
2025-09-10 17:24:47,525:INFO:Importing untrained model
2025-09-10 17:24:47,530:INFO:Huber Regressor Imported successfully
2025-09-10 17:24:47,530:INFO:Starting cross validation
2025-09-10 17:24:47,546:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:24:49,320:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:49,357:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:49,377:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:49,382:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:49,410:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:49,434:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:49,472:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:49,844:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-09-10 17:24:49,912:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
HuberRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:49,923:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
HuberRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:49,923:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
HuberRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:49,933:INFO:Calculating mean and std
2025-09-10 17:24:49,934:INFO:Creating metrics dataframe
2025-09-10 17:24:49,934:INFO:Uploading results into container
2025-09-10 17:24:49,934:INFO:Uploading model into container now
2025-09-10 17:24:49,934:INFO:_master_model_container: 19
2025-09-10 17:24:49,934:INFO:_display_container: 2
2025-09-10 17:24:49,934:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2025-09-10 17:24:49,934:INFO:create_model() successfully completed......................................
2025-09-10 17:24:50,126:WARNING:create_model() for HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:24:50,127:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:24:50,127:INFO:Initializing create_model()
2025-09-10 17:24:50,127:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:24:50,127:INFO:Checking exceptions
2025-09-10 17:24:50,127:INFO:Importing libraries
2025-09-10 17:24:50,127:INFO:Copying training dataset
2025-09-10 17:24:50,134:INFO:Defining folds
2025-09-10 17:24:50,134:INFO:Declaring metric variables
2025-09-10 17:24:50,138:INFO:Importing untrained model
2025-09-10 17:24:50,144:INFO:Huber Regressor Imported successfully
2025-09-10 17:24:50,144:INFO:Starting cross validation
2025-09-10 17:24:50,161:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:24:51,985:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:51,985:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:51,996:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:52,055:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:52,093:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:52,104:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:52,151:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:52,599:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-09-10 17:24:52,672:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
HuberRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:52,676:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
HuberRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:52,676:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 286, in predict
    return self._decision_function(X)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_base.py", line 269, in _decision_function
    X = self._validate_data(X, accept_sparse=["csr", "csc", "coo"], reset=False)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
HuberRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:52,683:INFO:Calculating mean and std
2025-09-10 17:24:52,683:INFO:Creating metrics dataframe
2025-09-10 17:24:52,683:INFO:Uploading results into container
2025-09-10 17:24:52,683:INFO:Uploading model into container now
2025-09-10 17:24:52,683:INFO:_master_model_container: 20
2025-09-10 17:24:52,683:INFO:_display_container: 2
2025-09-10 17:24:52,683:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2025-09-10 17:24:52,683:INFO:create_model() successfully completed......................................
2025-09-10 17:24:52,877:ERROR:create_model() for HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False) raised an exception or returned all 0.0:
2025-09-10 17:24:52,877:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:24:52,877:INFO:Initializing K Neighbors Regressor
2025-09-10 17:24:52,877:INFO:Total runtime is 0.8962760329246522 minutes
2025-09-10 17:24:52,877:INFO:SubProcess create_model() called ==================================
2025-09-10 17:24:52,877:INFO:Initializing create_model()
2025-09-10 17:24:52,877:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:24:52,877:INFO:Checking exceptions
2025-09-10 17:24:52,877:INFO:Importing libraries
2025-09-10 17:24:52,877:INFO:Copying training dataset
2025-09-10 17:24:52,877:INFO:Defining folds
2025-09-10 17:24:52,877:INFO:Declaring metric variables
2025-09-10 17:24:52,895:INFO:Importing untrained model
2025-09-10 17:24:52,895:INFO:K Neighbors Regressor Imported successfully
2025-09-10 17:24:52,914:INFO:Starting cross validation
2025-09-10 17:24:52,917:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:24:54,813:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:54,827:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:54,857:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:54,885:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:54,908:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:54,911:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:54,961:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:55,054:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\neighbors\_regression.py", line 242, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\neighbors\_base.py", line 826, in kneighbors
    X = self._validate_data(X, accept_sparse="csr", reset=False, order="C")
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
KNeighborsRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:55,060:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\neighbors\_regression.py", line 242, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\neighbors\_base.py", line 826, in kneighbors
    X = self._validate_data(X, accept_sparse="csr", reset=False, order="C")
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
KNeighborsRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:55,060:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\neighbors\_regression.py", line 242, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\neighbors\_base.py", line 826, in kneighbors
    X = self._validate_data(X, accept_sparse="csr", reset=False, order="C")
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
KNeighborsRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:55,086:INFO:Calculating mean and std
2025-09-10 17:24:55,090:INFO:Creating metrics dataframe
2025-09-10 17:24:55,093:INFO:Uploading results into container
2025-09-10 17:24:55,094:INFO:Uploading model into container now
2025-09-10 17:24:55,094:INFO:_master_model_container: 21
2025-09-10 17:24:55,094:INFO:_display_container: 2
2025-09-10 17:24:55,094:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2025-09-10 17:24:55,094:INFO:create_model() successfully completed......................................
2025-09-10 17:24:55,277:WARNING:create_model() for KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform') raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:24:55,277:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:24:55,277:INFO:Initializing create_model()
2025-09-10 17:24:55,277:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:24:55,277:INFO:Checking exceptions
2025-09-10 17:24:55,277:INFO:Importing libraries
2025-09-10 17:24:55,277:INFO:Copying training dataset
2025-09-10 17:24:55,277:INFO:Defining folds
2025-09-10 17:24:55,277:INFO:Declaring metric variables
2025-09-10 17:24:55,294:INFO:Importing untrained model
2025-09-10 17:24:55,294:INFO:K Neighbors Regressor Imported successfully
2025-09-10 17:24:55,309:INFO:Starting cross validation
2025-09-10 17:24:55,313:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:24:57,138:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:57,199:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:57,222:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:57,252:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:57,303:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:57,314:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:57,324:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:57,444:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\neighbors\_regression.py", line 242, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\neighbors\_base.py", line 826, in kneighbors
    X = self._validate_data(X, accept_sparse="csr", reset=False, order="C")
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
KNeighborsRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:57,444:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\neighbors\_regression.py", line 242, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\neighbors\_base.py", line 826, in kneighbors
    X = self._validate_data(X, accept_sparse="csr", reset=False, order="C")
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
KNeighborsRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:57,444:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\neighbors\_regression.py", line 242, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\neighbors\_base.py", line 826, in kneighbors
    X = self._validate_data(X, accept_sparse="csr", reset=False, order="C")
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
KNeighborsRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:24:57,470:INFO:Calculating mean and std
2025-09-10 17:24:57,470:INFO:Creating metrics dataframe
2025-09-10 17:24:57,470:INFO:Uploading results into container
2025-09-10 17:24:57,470:INFO:Uploading model into container now
2025-09-10 17:24:57,470:INFO:_master_model_container: 22
2025-09-10 17:24:57,470:INFO:_display_container: 2
2025-09-10 17:24:57,470:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2025-09-10 17:24:57,470:INFO:create_model() successfully completed......................................
2025-09-10 17:24:57,660:ERROR:create_model() for KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform') raised an exception or returned all 0.0:
2025-09-10 17:24:57,660:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:24:57,660:INFO:Initializing Decision Tree Regressor
2025-09-10 17:24:57,660:INFO:Total runtime is 0.9759980320930481 minutes
2025-09-10 17:24:57,660:INFO:SubProcess create_model() called ==================================
2025-09-10 17:24:57,660:INFO:Initializing create_model()
2025-09-10 17:24:57,660:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:24:57,660:INFO:Checking exceptions
2025-09-10 17:24:57,660:INFO:Importing libraries
2025-09-10 17:24:57,660:INFO:Copying training dataset
2025-09-10 17:24:57,660:INFO:Defining folds
2025-09-10 17:24:57,660:INFO:Declaring metric variables
2025-09-10 17:24:57,677:INFO:Importing untrained model
2025-09-10 17:24:57,684:INFO:Decision Tree Regressor Imported successfully
2025-09-10 17:24:57,699:INFO:Starting cross validation
2025-09-10 17:24:57,701:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:24:59,413:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:59,464:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:59,495:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:59,510:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:24:59,516:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:59,516:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:59,578:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:59,578:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:24:59,613:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:24:59,620:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:24:59,646:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:24:59,651:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:24:59,682:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:24:59,703:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:24:59,723:INFO:Calculating mean and std
2025-09-10 17:24:59,723:INFO:Creating metrics dataframe
2025-09-10 17:24:59,723:INFO:Uploading results into container
2025-09-10 17:24:59,723:INFO:Uploading model into container now
2025-09-10 17:24:59,723:INFO:_master_model_container: 23
2025-09-10 17:24:59,723:INFO:_display_container: 2
2025-09-10 17:24:59,723:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=123, splitter='best')
2025-09-10 17:24:59,723:INFO:create_model() successfully completed......................................
2025-09-10 17:24:59,892:WARNING:create_model() for DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=123, splitter='best') raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:24:59,892:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:24:59,892:INFO:Initializing create_model()
2025-09-10 17:24:59,892:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:24:59,892:INFO:Checking exceptions
2025-09-10 17:24:59,892:INFO:Importing libraries
2025-09-10 17:24:59,892:INFO:Copying training dataset
2025-09-10 17:24:59,911:INFO:Defining folds
2025-09-10 17:24:59,911:INFO:Declaring metric variables
2025-09-10 17:24:59,913:INFO:Importing untrained model
2025-09-10 17:24:59,913:INFO:Decision Tree Regressor Imported successfully
2025-09-10 17:24:59,929:INFO:Starting cross validation
2025-09-10 17:24:59,931:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:25:01,841:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:01,852:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:01,901:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:01,905:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:01,909:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:01,928:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:01,949:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:01,980:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:01,991:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:02,049:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:02,050:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:02,057:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:02,078:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:02,096:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:02,116:INFO:Calculating mean and std
2025-09-10 17:25:02,116:INFO:Creating metrics dataframe
2025-09-10 17:25:02,116:INFO:Uploading results into container
2025-09-10 17:25:02,116:INFO:Uploading model into container now
2025-09-10 17:25:02,116:INFO:_master_model_container: 24
2025-09-10 17:25:02,116:INFO:_display_container: 2
2025-09-10 17:25:02,116:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=123, splitter='best')
2025-09-10 17:25:02,116:INFO:create_model() successfully completed......................................
2025-09-10 17:25:02,330:ERROR:create_model() for DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=123, splitter='best') raised an exception or returned all 0.0:
2025-09-10 17:25:02,330:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:25:02,330:INFO:Initializing Random Forest Regressor
2025-09-10 17:25:02,330:INFO:Total runtime is 1.0538350661595663 minutes
2025-09-10 17:25:02,339:INFO:SubProcess create_model() called ==================================
2025-09-10 17:25:02,339:INFO:Initializing create_model()
2025-09-10 17:25:02,339:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:25:02,339:INFO:Checking exceptions
2025-09-10 17:25:02,339:INFO:Importing libraries
2025-09-10 17:25:02,339:INFO:Copying training dataset
2025-09-10 17:25:02,350:INFO:Defining folds
2025-09-10 17:25:02,350:INFO:Declaring metric variables
2025-09-10 17:25:02,353:INFO:Importing untrained model
2025-09-10 17:25:02,359:INFO:Random Forest Regressor Imported successfully
2025-09-10 17:25:02,370:INFO:Starting cross validation
2025-09-10 17:25:02,372:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:25:04,199:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:04,226:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:04,277:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:04,318:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:04,318:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:04,342:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:04,366:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:04,388:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:04,394:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:04,394:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:04,430:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:04,454:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:04,522:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:04,551:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:04,640:INFO:Calculating mean and std
2025-09-10 17:25:04,640:INFO:Creating metrics dataframe
2025-09-10 17:25:04,642:INFO:Uploading results into container
2025-09-10 17:25:04,643:INFO:Uploading model into container now
2025-09-10 17:25:04,643:INFO:_master_model_container: 25
2025-09-10 17:25:04,643:INFO:_display_container: 2
2025-09-10 17:25:04,643:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, monotonic_cst=None,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=123, verbose=0, warm_start=False)
2025-09-10 17:25:04,643:INFO:create_model() successfully completed......................................
2025-09-10 17:25:04,826:WARNING:create_model() for RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, monotonic_cst=None,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=123, verbose=0, warm_start=False) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:25:04,827:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:25:04,827:INFO:Initializing create_model()
2025-09-10 17:25:04,827:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:25:04,827:INFO:Checking exceptions
2025-09-10 17:25:04,827:INFO:Importing libraries
2025-09-10 17:25:04,827:INFO:Copying training dataset
2025-09-10 17:25:04,827:INFO:Defining folds
2025-09-10 17:25:04,827:INFO:Declaring metric variables
2025-09-10 17:25:04,827:INFO:Importing untrained model
2025-09-10 17:25:04,827:INFO:Random Forest Regressor Imported successfully
2025-09-10 17:25:04,852:INFO:Starting cross validation
2025-09-10 17:25:04,857:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:25:06,543:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:06,562:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:06,576:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:06,593:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:06,613:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:06,644:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:06,665:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:06,677:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:06,693:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:06,696:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:06,710:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:06,762:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:06,797:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:06,820:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:06,945:INFO:Calculating mean and std
2025-09-10 17:25:06,945:INFO:Creating metrics dataframe
2025-09-10 17:25:06,945:INFO:Uploading results into container
2025-09-10 17:25:06,945:INFO:Uploading model into container now
2025-09-10 17:25:06,945:INFO:_master_model_container: 26
2025-09-10 17:25:06,945:INFO:_display_container: 2
2025-09-10 17:25:06,945:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, monotonic_cst=None,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=123, verbose=0, warm_start=False)
2025-09-10 17:25:06,945:INFO:create_model() successfully completed......................................
2025-09-10 17:25:07,127:ERROR:create_model() for RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, monotonic_cst=None,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=123, verbose=0, warm_start=False) raised an exception or returned all 0.0:
2025-09-10 17:25:07,127:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:25:07,127:INFO:Initializing Extra Trees Regressor
2025-09-10 17:25:07,127:INFO:Total runtime is 1.1337769269943239 minutes
2025-09-10 17:25:07,127:INFO:SubProcess create_model() called ==================================
2025-09-10 17:25:07,127:INFO:Initializing create_model()
2025-09-10 17:25:07,127:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:25:07,127:INFO:Checking exceptions
2025-09-10 17:25:07,127:INFO:Importing libraries
2025-09-10 17:25:07,127:INFO:Copying training dataset
2025-09-10 17:25:07,127:INFO:Defining folds
2025-09-10 17:25:07,127:INFO:Declaring metric variables
2025-09-10 17:25:07,143:INFO:Importing untrained model
2025-09-10 17:25:07,143:INFO:Extra Trees Regressor Imported successfully
2025-09-10 17:25:07,158:INFO:Starting cross validation
2025-09-10 17:25:07,159:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:25:09,277:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:09,295:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:09,313:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:09,317:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:09,328:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:09,382:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:09,412:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:09,421:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:09,444:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:09,478:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:09,511:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:09,515:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:09,577:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:09,597:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:09,649:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_forest.py", line 1064, in predict
    X = self._validate_X_predict(X)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_forest.py", line 641, in _validate_X_predict
    X = self._validate_data(
        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:25:09,649:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_forest.py", line 1064, in predict
    X = self._validate_X_predict(X)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_forest.py", line 641, in _validate_X_predict
    X = self._validate_data(
        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:25:09,649:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_forest.py", line 1064, in predict
    X = self._validate_X_predict(X)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_forest.py", line 641, in _validate_X_predict
    X = self._validate_data(
        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:25:09,660:INFO:Calculating mean and std
2025-09-10 17:25:09,660:INFO:Creating metrics dataframe
2025-09-10 17:25:09,660:INFO:Uploading results into container
2025-09-10 17:25:09,660:INFO:Uploading model into container now
2025-09-10 17:25:09,663:INFO:_master_model_container: 27
2025-09-10 17:25:09,663:INFO:_display_container: 2
2025-09-10 17:25:09,663:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False)
2025-09-10 17:25:09,663:INFO:create_model() successfully completed......................................
2025-09-10 17:25:09,852:WARNING:create_model() for ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:25:09,852:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:25:09,852:INFO:Initializing create_model()
2025-09-10 17:25:09,852:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:25:09,852:INFO:Checking exceptions
2025-09-10 17:25:09,852:INFO:Importing libraries
2025-09-10 17:25:09,852:INFO:Copying training dataset
2025-09-10 17:25:09,858:INFO:Defining folds
2025-09-10 17:25:09,858:INFO:Declaring metric variables
2025-09-10 17:25:09,863:INFO:Importing untrained model
2025-09-10 17:25:09,868:INFO:Extra Trees Regressor Imported successfully
2025-09-10 17:25:09,876:INFO:Starting cross validation
2025-09-10 17:25:09,876:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:25:11,805:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:11,828:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:11,838:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:11,869:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:11,925:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:11,944:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:11,953:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:11,975:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:11,987:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:12,020:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:12,027:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:12,103:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:12,112:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:12,127:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:12,332:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_forest.py", line 1064, in predict
    X = self._validate_X_predict(X)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_forest.py", line 641, in _validate_X_predict
    X = self._validate_data(
        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:25:12,344:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_forest.py", line 1064, in predict
    X = self._validate_X_predict(X)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_forest.py", line 641, in _validate_X_predict
    X = self._validate_data(
        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:25:12,345:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_forest.py", line 1064, in predict
    X = self._validate_X_predict(X)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_forest.py", line 641, in _validate_X_predict
    X = self._validate_data(
        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
ExtraTreesRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:25:12,351:INFO:Calculating mean and std
2025-09-10 17:25:12,351:INFO:Creating metrics dataframe
2025-09-10 17:25:12,354:INFO:Uploading results into container
2025-09-10 17:25:12,354:INFO:Uploading model into container now
2025-09-10 17:25:12,354:INFO:_master_model_container: 28
2025-09-10 17:25:12,354:INFO:_display_container: 2
2025-09-10 17:25:12,355:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False)
2025-09-10 17:25:12,355:INFO:create_model() successfully completed......................................
2025-09-10 17:25:12,582:ERROR:create_model() for ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False) raised an exception or returned all 0.0:
2025-09-10 17:25:12,582:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:25:12,582:INFO:Initializing AdaBoost Regressor
2025-09-10 17:25:12,582:INFO:Total runtime is 1.2246957818667095 minutes
2025-09-10 17:25:12,582:INFO:SubProcess create_model() called ==================================
2025-09-10 17:25:12,582:INFO:Initializing create_model()
2025-09-10 17:25:12,582:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:25:12,582:INFO:Checking exceptions
2025-09-10 17:25:12,582:INFO:Importing libraries
2025-09-10 17:25:12,582:INFO:Copying training dataset
2025-09-10 17:25:12,594:INFO:Defining folds
2025-09-10 17:25:12,594:INFO:Declaring metric variables
2025-09-10 17:25:12,598:INFO:Importing untrained model
2025-09-10 17:25:12,598:INFO:AdaBoost Regressor Imported successfully
2025-09-10 17:25:12,612:INFO:Starting cross validation
2025-09-10 17:25:12,616:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:25:14,699:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:14,733:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:14,734:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:14,741:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:14,775:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:14,844:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:15,276:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py", line 1238, in predict
    X = self._check_X(X)
        ^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py", line 98, in _check_X
    return self._validate_data(
           ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
AdaBoostRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:25:15,276:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py", line 1238, in predict
    X = self._check_X(X)
        ^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py", line 98, in _check_X
    return self._validate_data(
           ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
AdaBoostRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:25:15,276:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py", line 1238, in predict
    X = self._check_X(X)
        ^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py", line 98, in _check_X
    return self._validate_data(
           ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
AdaBoostRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:25:15,286:INFO:Calculating mean and std
2025-09-10 17:25:15,286:INFO:Creating metrics dataframe
2025-09-10 17:25:15,286:INFO:Uploading results into container
2025-09-10 17:25:15,286:INFO:Uploading model into container now
2025-09-10 17:25:15,286:INFO:_master_model_container: 29
2025-09-10 17:25:15,286:INFO:_display_container: 2
2025-09-10 17:25:15,286:INFO:AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=123)
2025-09-10 17:25:15,286:INFO:create_model() successfully completed......................................
2025-09-10 17:25:15,465:WARNING:create_model() for AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=123) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:25:15,465:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:25:15,474:INFO:Initializing create_model()
2025-09-10 17:25:15,474:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:25:15,474:INFO:Checking exceptions
2025-09-10 17:25:15,474:INFO:Importing libraries
2025-09-10 17:25:15,475:INFO:Copying training dataset
2025-09-10 17:25:15,477:INFO:Defining folds
2025-09-10 17:25:15,477:INFO:Declaring metric variables
2025-09-10 17:25:15,477:INFO:Importing untrained model
2025-09-10 17:25:15,477:INFO:AdaBoost Regressor Imported successfully
2025-09-10 17:25:15,492:INFO:Starting cross validation
2025-09-10 17:25:15,492:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:25:17,144:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:17,371:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:17,381:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:17,383:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:17,450:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:17,465:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:17,515:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:17,868:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py", line 1238, in predict
    X = self._check_X(X)
        ^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py", line 98, in _check_X
    return self._validate_data(
           ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
AdaBoostRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:25:17,870:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py", line 1238, in predict
    X = self._check_X(X)
        ^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py", line 98, in _check_X
    return self._validate_data(
           ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
AdaBoostRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:25:17,870:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py", line 1238, in predict
    X = self._check_X(X)
        ^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py", line 98, in _check_X
    return self._validate_data(
           ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
AdaBoostRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:25:17,880:INFO:Calculating mean and std
2025-09-10 17:25:17,880:INFO:Creating metrics dataframe
2025-09-10 17:25:17,882:INFO:Uploading results into container
2025-09-10 17:25:17,883:INFO:Uploading model into container now
2025-09-10 17:25:17,883:INFO:_master_model_container: 30
2025-09-10 17:25:17,883:INFO:_display_container: 2
2025-09-10 17:25:17,883:INFO:AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=123)
2025-09-10 17:25:17,883:INFO:create_model() successfully completed......................................
2025-09-10 17:25:18,078:ERROR:create_model() for AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=123) raised an exception or returned all 0.0:
2025-09-10 17:25:18,078:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:25:18,078:INFO:Initializing Gradient Boosting Regressor
2025-09-10 17:25:18,078:INFO:Total runtime is 1.3162948290507 minutes
2025-09-10 17:25:18,080:INFO:SubProcess create_model() called ==================================
2025-09-10 17:25:18,080:INFO:Initializing create_model()
2025-09-10 17:25:18,080:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:25:18,080:INFO:Checking exceptions
2025-09-10 17:25:18,080:INFO:Importing libraries
2025-09-10 17:25:18,080:INFO:Copying training dataset
2025-09-10 17:25:18,080:INFO:Defining folds
2025-09-10 17:25:18,080:INFO:Declaring metric variables
2025-09-10 17:25:18,092:INFO:Importing untrained model
2025-09-10 17:25:18,092:INFO:Gradient Boosting Regressor Imported successfully
2025-09-10 17:25:18,099:INFO:Starting cross validation
2025-09-10 17:25:18,109:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:25:19,838:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:19,903:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:19,965:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:19,965:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:19,992:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:19,995:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:20,013:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:20,017:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:20,043:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:20,110:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:20,114:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:20,137:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:20,145:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:20,145:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:20,803:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_gb.py", line 2120, in predict
    X = self._validate_data(
        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GradientBoostingRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:25:20,803:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_gb.py", line 2120, in predict
    X = self._validate_data(
        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GradientBoostingRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:25:20,803:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_gb.py", line 2120, in predict
    X = self._validate_data(
        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GradientBoostingRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:25:20,814:INFO:Calculating mean and std
2025-09-10 17:25:20,814:INFO:Creating metrics dataframe
2025-09-10 17:25:20,814:INFO:Uploading results into container
2025-09-10 17:25:20,814:INFO:Uploading model into container now
2025-09-10 17:25:20,814:INFO:_master_model_container: 31
2025-09-10 17:25:20,814:INFO:_display_container: 2
2025-09-10 17:25:20,814:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=123, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-09-10 17:25:20,814:INFO:create_model() successfully completed......................................
2025-09-10 17:25:20,992:WARNING:create_model() for GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=123, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:25:20,992:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:25:20,992:INFO:Initializing create_model()
2025-09-10 17:25:20,992:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:25:20,992:INFO:Checking exceptions
2025-09-10 17:25:20,992:INFO:Importing libraries
2025-09-10 17:25:20,992:INFO:Copying training dataset
2025-09-10 17:25:20,992:INFO:Defining folds
2025-09-10 17:25:20,992:INFO:Declaring metric variables
2025-09-10 17:25:20,992:INFO:Importing untrained model
2025-09-10 17:25:21,009:INFO:Gradient Boosting Regressor Imported successfully
2025-09-10 17:25:21,009:INFO:Starting cross validation
2025-09-10 17:25:21,025:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:25:22,746:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:22,759:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:22,780:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:22,866:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:22,866:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:22,879:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:22,880:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:22,883:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:22,887:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:22,915:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:22,959:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:22,985:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:23,006:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:23,016:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\generic.py:2070: RuntimeWarning: overflow encountered in cast
  return np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:23,664:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_gb.py", line 2120, in predict
    X = self._validate_data(
        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GradientBoostingRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:25:23,664:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_gb.py", line 2120, in predict
    X = self._validate_data(
        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GradientBoostingRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:25:23,664:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\_response.py", line 238, in _get_response_values
    y_pred, pos_label = prediction_method(X), None
                        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pipeline.py", line 330, in predict
    y = self.steps[-1][-1].predict(X, **params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\ensemble\_gb.py", line 2120, in predict
    X = self._validate_data(
        ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\base.py", line 633, in _validate_data
    out = check_array(X, input_name="X", **check_params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
GradientBoostingRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

  warnings.warn(

2025-09-10 17:25:23,675:INFO:Calculating mean and std
2025-09-10 17:25:23,675:INFO:Creating metrics dataframe
2025-09-10 17:25:23,675:INFO:Uploading results into container
2025-09-10 17:25:23,675:INFO:Uploading model into container now
2025-09-10 17:25:23,675:INFO:_master_model_container: 32
2025-09-10 17:25:23,675:INFO:_display_container: 2
2025-09-10 17:25:23,675:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=123, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-09-10 17:25:23,675:INFO:create_model() successfully completed......................................
2025-09-10 17:25:23,875:ERROR:create_model() for GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=123, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False) raised an exception or returned all 0.0:
2025-09-10 17:25:23,876:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:25:23,876:INFO:Initializing Extreme Gradient Boosting
2025-09-10 17:25:23,876:INFO:Total runtime is 1.4129231293996176 minutes
2025-09-10 17:25:23,881:INFO:SubProcess create_model() called ==================================
2025-09-10 17:25:23,882:INFO:Initializing create_model()
2025-09-10 17:25:23,882:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:25:23,883:INFO:Checking exceptions
2025-09-10 17:25:23,883:INFO:Importing libraries
2025-09-10 17:25:23,883:INFO:Copying training dataset
2025-09-10 17:25:23,892:INFO:Defining folds
2025-09-10 17:25:23,892:INFO:Declaring metric variables
2025-09-10 17:25:23,896:INFO:Importing untrained model
2025-09-10 17:25:23,902:INFO:Extreme Gradient Boosting Imported successfully
2025-09-10 17:25:23,909:INFO:Starting cross validation
2025-09-10 17:25:23,909:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:25:25,789:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:25,798:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:25,800:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:25,802:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:25,826:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:25,833:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:25,918:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:25,958:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\base.py:535: RuntimeWarning: overflow encountered in cast
  result = np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:25,970:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\base.py:535: RuntimeWarning: overflow encountered in cast
  result = np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:25,975:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\base.py:535: RuntimeWarning: overflow encountered in cast
  result = np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:25,976:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\base.py:535: RuntimeWarning: overflow encountered in cast
  result = np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:25,988:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\base.py:535: RuntimeWarning: overflow encountered in cast
  result = np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:25,999:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\base.py:535: RuntimeWarning: overflow encountered in cast
  result = np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:26,052:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\base.py:535: RuntimeWarning: overflow encountered in cast
  result = np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:26,178:INFO:Calculating mean and std
2025-09-10 17:25:26,178:INFO:Creating metrics dataframe
2025-09-10 17:25:26,180:INFO:Uploading results into container
2025-09-10 17:25:26,180:INFO:Uploading model into container now
2025-09-10 17:25:26,180:INFO:_master_model_container: 33
2025-09-10 17:25:26,180:INFO:_display_container: 2
2025-09-10 17:25:26,180:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-09-10 17:25:26,180:INFO:create_model() successfully completed......................................
2025-09-10 17:25:26,366:WARNING:create_model() for XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:25:26,367:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:25:26,367:INFO:Initializing create_model()
2025-09-10 17:25:26,367:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:25:26,367:INFO:Checking exceptions
2025-09-10 17:25:26,367:INFO:Importing libraries
2025-09-10 17:25:26,367:INFO:Copying training dataset
2025-09-10 17:25:26,372:INFO:Defining folds
2025-09-10 17:25:26,372:INFO:Declaring metric variables
2025-09-10 17:25:26,376:INFO:Importing untrained model
2025-09-10 17:25:26,381:INFO:Extreme Gradient Boosting Imported successfully
2025-09-10 17:25:26,392:INFO:Starting cross validation
2025-09-10 17:25:26,395:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:25:28,115:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:28,188:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:28,239:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:28,243:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:28,250:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:28,269:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\base.py:535: RuntimeWarning: overflow encountered in cast
  result = np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:28,281:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:28,311:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:28,326:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\base.py:535: RuntimeWarning: overflow encountered in cast
  result = np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:28,368:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\base.py:535: RuntimeWarning: overflow encountered in cast
  result = np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:28,394:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\base.py:535: RuntimeWarning: overflow encountered in cast
  result = np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:28,409:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\base.py:535: RuntimeWarning: overflow encountered in cast
  result = np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:28,429:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\base.py:535: RuntimeWarning: overflow encountered in cast
  result = np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:28,442:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pandas\core\base.py:535: RuntimeWarning: overflow encountered in cast
  result = np.asarray(self._values, dtype=dtype)

2025-09-10 17:25:28,540:INFO:Calculating mean and std
2025-09-10 17:25:28,541:INFO:Creating metrics dataframe
2025-09-10 17:25:28,542:INFO:Uploading results into container
2025-09-10 17:25:28,542:INFO:Uploading model into container now
2025-09-10 17:25:28,542:INFO:_master_model_container: 34
2025-09-10 17:25:28,542:INFO:_display_container: 2
2025-09-10 17:25:28,542:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-09-10 17:25:28,542:INFO:create_model() successfully completed......................................
2025-09-10 17:25:28,709:ERROR:create_model() for XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...) raised an exception or returned all 0.0:
2025-09-10 17:25:28,709:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:25:28,709:INFO:Initializing Light Gradient Boosting Machine
2025-09-10 17:25:28,709:INFO:Total runtime is 1.493476923306783 minutes
2025-09-10 17:25:28,726:INFO:SubProcess create_model() called ==================================
2025-09-10 17:25:28,726:INFO:Initializing create_model()
2025-09-10 17:25:28,726:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:25:28,726:INFO:Checking exceptions
2025-09-10 17:25:28,726:INFO:Importing libraries
2025-09-10 17:25:28,726:INFO:Copying training dataset
2025-09-10 17:25:28,726:INFO:Defining folds
2025-09-10 17:25:28,726:INFO:Declaring metric variables
2025-09-10 17:25:28,726:INFO:Importing untrained model
2025-09-10 17:25:28,741:INFO:Light Gradient Boosting Machine Imported successfully
2025-09-10 17:25:28,741:INFO:Starting cross validation
2025-09-10 17:25:28,741:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:25:30,428:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:30,440:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:30,479:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:30,482:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:30,534:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:30,538:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:30,654:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:32,166:INFO:Calculating mean and std
2025-09-10 17:25:32,166:INFO:Creating metrics dataframe
2025-09-10 17:25:32,168:INFO:Uploading results into container
2025-09-10 17:25:32,169:INFO:Uploading model into container now
2025-09-10 17:25:32,169:INFO:_master_model_container: 35
2025-09-10 17:25:32,169:INFO:_display_container: 2
2025-09-10 17:25:32,170:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-09-10 17:25:32,170:INFO:create_model() successfully completed......................................
2025-09-10 17:25:32,375:WARNING:create_model() for LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:25:32,375:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:25:32,375:INFO:Initializing create_model()
2025-09-10 17:25:32,375:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:25:32,375:INFO:Checking exceptions
2025-09-10 17:25:32,375:INFO:Importing libraries
2025-09-10 17:25:32,375:INFO:Copying training dataset
2025-09-10 17:25:32,380:INFO:Defining folds
2025-09-10 17:25:32,380:INFO:Declaring metric variables
2025-09-10 17:25:32,383:INFO:Importing untrained model
2025-09-10 17:25:32,388:INFO:Light Gradient Boosting Machine Imported successfully
2025-09-10 17:25:32,399:INFO:Starting cross validation
2025-09-10 17:25:32,402:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:25:34,108:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:34,152:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:34,158:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:34,168:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:34,171:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:34,283:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:34,347:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:35,827:INFO:Calculating mean and std
2025-09-10 17:25:35,827:INFO:Creating metrics dataframe
2025-09-10 17:25:35,829:INFO:Uploading results into container
2025-09-10 17:25:35,831:INFO:Uploading model into container now
2025-09-10 17:25:35,831:INFO:_master_model_container: 36
2025-09-10 17:25:35,831:INFO:_display_container: 2
2025-09-10 17:25:35,831:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-09-10 17:25:35,831:INFO:create_model() successfully completed......................................
2025-09-10 17:25:36,024:ERROR:create_model() for LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0) raised an exception or returned all 0.0:
2025-09-10 17:25:36,027:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:25:36,027:INFO:Initializing CatBoost Regressor
2025-09-10 17:25:36,027:INFO:Total runtime is 1.615444286664327 minutes
2025-09-10 17:25:36,029:INFO:SubProcess create_model() called ==================================
2025-09-10 17:25:36,029:INFO:Initializing create_model()
2025-09-10 17:25:36,029:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:25:36,029:INFO:Checking exceptions
2025-09-10 17:25:36,029:INFO:Importing libraries
2025-09-10 17:25:36,029:INFO:Copying training dataset
2025-09-10 17:25:36,029:INFO:Defining folds
2025-09-10 17:25:36,029:INFO:Declaring metric variables
2025-09-10 17:25:36,040:INFO:Importing untrained model
2025-09-10 17:25:36,041:INFO:CatBoost Regressor Imported successfully
2025-09-10 17:25:36,041:INFO:Starting cross validation
2025-09-10 17:25:36,041:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:25:38,630:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:38,630:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:38,650:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:38,686:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:38,708:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:38,734:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:38,861:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:46,164:INFO:Calculating mean and std
2025-09-10 17:25:46,164:INFO:Creating metrics dataframe
2025-09-10 17:25:46,166:INFO:Uploading results into container
2025-09-10 17:25:46,166:INFO:Uploading model into container now
2025-09-10 17:25:46,166:INFO:_master_model_container: 37
2025-09-10 17:25:46,166:INFO:_display_container: 2
2025-09-10 17:25:46,166:INFO:<catboost.core.CatBoostRegressor object at 0x000002C5BCDF8290>
2025-09-10 17:25:46,167:INFO:create_model() successfully completed......................................
2025-09-10 17:25:46,341:WARNING:create_model() for <catboost.core.CatBoostRegressor object at 0x000002C5BCDF8290> raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:25:46,341:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:25:46,356:INFO:Initializing create_model()
2025-09-10 17:25:46,356:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:25:46,356:INFO:Checking exceptions
2025-09-10 17:25:46,356:INFO:Importing libraries
2025-09-10 17:25:46,357:INFO:Copying training dataset
2025-09-10 17:25:46,361:INFO:Defining folds
2025-09-10 17:25:46,362:INFO:Declaring metric variables
2025-09-10 17:25:46,365:INFO:Importing untrained model
2025-09-10 17:25:46,369:INFO:CatBoost Regressor Imported successfully
2025-09-10 17:25:46,379:INFO:Starting cross validation
2025-09-10 17:25:46,382:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:25:48,417:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:48,447:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:48,458:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:48,472:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:48,533:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:48,584:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:48,674:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:55,924:INFO:Calculating mean and std
2025-09-10 17:25:55,924:INFO:Creating metrics dataframe
2025-09-10 17:25:55,924:INFO:Uploading results into container
2025-09-10 17:25:55,924:INFO:Uploading model into container now
2025-09-10 17:25:55,924:INFO:_master_model_container: 38
2025-09-10 17:25:55,924:INFO:_display_container: 2
2025-09-10 17:25:55,924:INFO:<catboost.core.CatBoostRegressor object at 0x000002C5B8D63F50>
2025-09-10 17:25:55,924:INFO:create_model() successfully completed......................................
2025-09-10 17:25:56,124:ERROR:create_model() for <catboost.core.CatBoostRegressor object at 0x000002C5B8D63F50> raised an exception or returned all 0.0:
2025-09-10 17:25:56,124:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:25:56,124:INFO:Initializing Dummy Regressor
2025-09-10 17:25:56,124:INFO:Total runtime is 1.9503908872604372 minutes
2025-09-10 17:25:56,124:INFO:SubProcess create_model() called ==================================
2025-09-10 17:25:56,124:INFO:Initializing create_model()
2025-09-10 17:25:56,124:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:25:56,124:INFO:Checking exceptions
2025-09-10 17:25:56,124:INFO:Importing libraries
2025-09-10 17:25:56,124:INFO:Copying training dataset
2025-09-10 17:25:56,124:INFO:Defining folds
2025-09-10 17:25:56,124:INFO:Declaring metric variables
2025-09-10 17:25:56,124:INFO:Importing untrained model
2025-09-10 17:25:56,141:INFO:Dummy Regressor Imported successfully
2025-09-10 17:25:56,141:INFO:Starting cross validation
2025-09-10 17:25:56,156:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:25:58,313:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:58,331:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:58,356:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:58,367:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:58,538:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:58,545:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:58,595:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:25:58,904:INFO:Calculating mean and std
2025-09-10 17:25:58,904:INFO:Creating metrics dataframe
2025-09-10 17:25:58,906:INFO:Uploading results into container
2025-09-10 17:25:58,907:INFO:Uploading model into container now
2025-09-10 17:25:58,907:INFO:_master_model_container: 39
2025-09-10 17:25:58,907:INFO:_display_container: 2
2025-09-10 17:25:58,907:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2025-09-10 17:25:58,907:INFO:create_model() successfully completed......................................
2025-09-10 17:25:59,141:WARNING:create_model() for DummyRegressor(constant=None, quantile=None, strategy='mean') raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-10 17:25:59,141:WARNING:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-09-10 17:25:59,141:INFO:Initializing create_model()
2025-09-10 17:25:59,141:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5B97D1090>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD5ED0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:25:59,141:INFO:Checking exceptions
2025-09-10 17:25:59,141:INFO:Importing libraries
2025-09-10 17:25:59,141:INFO:Copying training dataset
2025-09-10 17:25:59,158:INFO:Defining folds
2025-09-10 17:25:59,158:INFO:Declaring metric variables
2025-09-10 17:25:59,158:INFO:Importing untrained model
2025-09-10 17:25:59,158:INFO:Dummy Regressor Imported successfully
2025-09-10 17:25:59,174:INFO:Starting cross validation
2025-09-10 17:25:59,174:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:26:01,292:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:26:01,334:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:26:01,400:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:26:01,509:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:26:01,509:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:26:01,644:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:26:01,690:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\numpy\core\_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-09-10 17:26:01,831:INFO:Calculating mean and std
2025-09-10 17:26:01,831:INFO:Creating metrics dataframe
2025-09-10 17:26:01,831:INFO:Uploading results into container
2025-09-10 17:26:01,831:INFO:Uploading model into container now
2025-09-10 17:26:01,831:INFO:_master_model_container: 40
2025-09-10 17:26:01,831:INFO:_display_container: 2
2025-09-10 17:26:01,831:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2025-09-10 17:26:01,831:INFO:create_model() successfully completed......................................
2025-09-10 17:26:02,024:ERROR:create_model() for DummyRegressor(constant=None, quantile=None, strategy='mean') raised an exception or returned all 0.0:
2025-09-10 17:26:02,024:ERROR:Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-09-10 17:26:02,024:INFO:_master_model_container: 40
2025-09-10 17:26:02,024:INFO:_display_container: 2
2025-09-10 17:26:02,024:INFO:[]
2025-09-10 17:26:02,024:INFO:compare_models() successfully completed......................................
2025-09-10 17:45:50,217:INFO:PyCaret RegressionExperiment
2025-09-10 17:45:50,217:INFO:Logging name: reg-default-name
2025-09-10 17:45:50,217:INFO:ML Usecase: MLUsecase.REGRESSION
2025-09-10 17:45:50,217:INFO:version 3.3.2
2025-09-10 17:45:50,217:INFO:Initializing setup()
2025-09-10 17:45:50,217:INFO:self.USI: eaa6
2025-09-10 17:45:50,217:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y', 'transform_target_param', 'data', 'X_test', 'USI', 'html_param', 'target_param', 'n_jobs_param', 'X_train', 'pipeline', 'seed', 'exp_id', '_available_plots', 'y_train', 'idx', 'fold_groups_param', 'memory', 'gpu_param', 'y_test', 'fold_generator', 'exp_name_log', '_ml_usecase', 'logging_param', 'X', 'fold_shuffle_param', 'log_plots_param'}
2025-09-10 17:45:50,217:INFO:Checking environment
2025-09-10 17:45:50,217:INFO:python_version: 3.11.10
2025-09-10 17:45:50,217:INFO:python_build: ('main', 'Oct  3 2024 07:22:26')
2025-09-10 17:45:50,217:INFO:machine: AMD64
2025-09-10 17:45:50,217:INFO:platform: Windows-10-10.0.26100-SP0
2025-09-10 17:45:50,217:INFO:Memory: svmem(total=16837152768, available=4046274560, percent=76.0, used=12790878208, free=4046274560)
2025-09-10 17:45:50,217:INFO:Physical Core: 10
2025-09-10 17:45:50,217:INFO:Logical Core: 12
2025-09-10 17:45:50,217:INFO:Checking libraries
2025-09-10 17:45:50,217:INFO:System:
2025-09-10 17:45:50,217:INFO:    python: 3.11.10 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:26) [MSC v.1929 64 bit (AMD64)]
2025-09-10 17:45:50,217:INFO:executable: c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\python.exe
2025-09-10 17:45:50,217:INFO:   machine: Windows-10-10.0.26100-SP0
2025-09-10 17:45:50,217:INFO:PyCaret required dependencies:
2025-09-10 17:45:50,217:INFO:                 pip: 24.2
2025-09-10 17:45:50,217:INFO:          setuptools: 75.1.0
2025-09-10 17:45:50,217:INFO:             pycaret: 3.3.2
2025-09-10 17:45:50,217:INFO:             IPython: 9.2.0
2025-09-10 17:45:50,217:INFO:          ipywidgets: 8.1.7
2025-09-10 17:45:50,217:INFO:                tqdm: 4.67.1
2025-09-10 17:45:50,217:INFO:               numpy: 1.24.4
2025-09-10 17:45:50,217:INFO:              pandas: 1.5.3
2025-09-10 17:45:50,217:INFO:              jinja2: 3.1.6
2025-09-10 17:45:50,217:INFO:               scipy: 1.11.4
2025-09-10 17:45:50,217:INFO:              joblib: 1.3.2
2025-09-10 17:45:50,217:INFO:             sklearn: 1.4.2
2025-09-10 17:45:50,217:INFO:                pyod: 2.0.5
2025-09-10 17:45:50,217:INFO:            imblearn: 0.13.0
2025-09-10 17:45:50,217:INFO:   category_encoders: 2.7.0
2025-09-10 17:45:50,217:INFO:            lightgbm: 4.6.0
2025-09-10 17:45:50,217:INFO:               numba: 0.61.0
2025-09-10 17:45:50,217:INFO:            requests: 2.32.3
2025-09-10 17:45:50,217:INFO:          matplotlib: 3.7.5
2025-09-10 17:45:50,217:INFO:          scikitplot: 0.3.7
2025-09-10 17:45:50,217:INFO:         yellowbrick: 1.5
2025-09-10 17:45:50,217:INFO:              plotly: 5.24.1
2025-09-10 17:45:50,217:INFO:    plotly-resampler: Not installed
2025-09-10 17:45:50,217:INFO:             kaleido: 0.2.1
2025-09-10 17:45:50,217:INFO:           schemdraw: 0.15
2025-09-10 17:45:50,217:INFO:         statsmodels: 0.14.4
2025-09-10 17:45:50,217:INFO:              sktime: 0.26.0
2025-09-10 17:45:50,217:INFO:               tbats: 1.1.3
2025-09-10 17:45:50,217:INFO:            pmdarima: 2.0.4
2025-09-10 17:45:50,217:INFO:              psutil: 7.0.0
2025-09-10 17:45:50,217:INFO:          markupsafe: 3.0.2
2025-09-10 17:45:50,217:INFO:             pickle5: Not installed
2025-09-10 17:45:50,217:INFO:         cloudpickle: 3.1.1
2025-09-10 17:45:50,217:INFO:         deprecation: 2.1.0
2025-09-10 17:45:50,217:INFO:              xxhash: 3.5.0
2025-09-10 17:45:50,217:INFO:           wurlitzer: Not installed
2025-09-10 17:45:50,217:INFO:PyCaret optional dependencies:
2025-09-10 17:45:50,217:INFO:                shap: 0.44.1
2025-09-10 17:45:50,217:INFO:           interpret: 0.6.11
2025-09-10 17:45:50,217:INFO:                umap: 0.5.7
2025-09-10 17:45:50,217:INFO:     ydata_profiling: 4.16.1
2025-09-10 17:45:50,217:INFO:  explainerdashboard: 0.5.1
2025-09-10 17:45:50,217:INFO:             autoviz: Not installed
2025-09-10 17:45:50,217:INFO:           fairlearn: 0.7.0
2025-09-10 17:45:50,217:INFO:          deepchecks: Not installed
2025-09-10 17:45:50,217:INFO:             xgboost: 3.0.2
2025-09-10 17:45:50,217:INFO:            catboost: 1.2.8
2025-09-10 17:45:50,217:INFO:              kmodes: 0.12.2
2025-09-10 17:45:50,217:INFO:             mlxtend: 0.23.4
2025-09-10 17:45:50,217:INFO:       statsforecast: 1.5.0
2025-09-10 17:45:50,217:INFO:        tune_sklearn: Not installed
2025-09-10 17:45:50,217:INFO:                 ray: Not installed
2025-09-10 17:45:50,217:INFO:            hyperopt: 0.2.7
2025-09-10 17:45:50,217:INFO:              optuna: 4.3.0
2025-09-10 17:45:50,217:INFO:               skopt: 0.10.2
2025-09-10 17:45:50,217:INFO:              mlflow: 3.1.0
2025-09-10 17:45:50,217:INFO:              gradio: 5.33.1
2025-09-10 17:45:50,217:INFO:             fastapi: 0.115.12
2025-09-10 17:45:50,217:INFO:             uvicorn: 0.34.3
2025-09-10 17:45:50,217:INFO:              m2cgen: 0.10.0
2025-09-10 17:45:50,217:INFO:           evidently: 0.4.40
2025-09-10 17:45:50,217:INFO:               fugue: 0.8.7
2025-09-10 17:45:50,217:INFO:           streamlit: 1.45.1
2025-09-10 17:45:50,217:INFO:             prophet: 1.1.7
2025-09-10 17:45:50,217:INFO:None
2025-09-10 17:45:50,217:INFO:Set up data.
2025-09-10 17:45:50,233:INFO:Set up folding strategy.
2025-09-10 17:45:50,233:INFO:Set up train/test split.
2025-09-10 17:45:50,254:INFO:Set up index.
2025-09-10 17:45:50,254:INFO:Assigning column types.
2025-09-10 17:45:50,254:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-09-10 17:45:50,254:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-09-10 17:45:50,254:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-09-10 17:45:50,254:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-09-10 17:45:50,287:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:45:50,318:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:45:50,318:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:45:50,318:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:45:50,318:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-09-10 17:45:50,332:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-09-10 17:45:50,335:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-09-10 17:45:50,372:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:45:50,385:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:45:50,385:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:45:50,400:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:45:50,400:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-09-10 17:45:50,402:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-09-10 17:45:50,402:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-09-10 17:45:50,434:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:45:50,467:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:45:50,467:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:45:50,467:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:45:50,467:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-09-10 17:45:50,467:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-09-10 17:45:50,511:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:45:50,536:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:45:50,536:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:45:50,536:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:45:50,536:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-09-10 17:45:50,536:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-09-10 17:45:50,583:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:45:50,604:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:45:50,604:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:45:50,604:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:45:50,617:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-09-10 17:45:50,651:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:45:50,667:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:45:50,667:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:45:50,667:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:45:50,667:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-09-10 17:45:50,716:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:45:50,744:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:45:50,745:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:45:50,747:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:45:50,794:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:45:50,824:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:45:50,824:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:45:50,826:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:45:50,826:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-09-10 17:45:50,868:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:45:50,888:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:45:50,888:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:45:50,936:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:45:50,953:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:45:50,953:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:45:50,953:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-09-10 17:45:51,016:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:45:51,016:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:45:51,083:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:45:51,098:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:45:51,099:INFO:Preparing preprocessing pipeline...
2025-09-10 17:45:51,099:INFO:Set up date feature engineering.
2025-09-10 17:45:51,099:INFO:Set up simple imputation.
2025-09-10 17:45:51,102:INFO:Set up encoding of categorical features.
2025-09-10 17:45:51,102:INFO:Set up removing multicollinearity.
2025-09-10 17:45:51,102:INFO:Set up column transformation.
2025-09-10 17:45:51,102:INFO:Set up feature normalization.
2025-09-10 17:45:51,102:INFO:Set up column name cleaning.
2025-09-10 17:45:52,267:INFO:Finished creating preprocessing pipeline.
2025-09-10 17:45:52,283:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\SBM_ME~1\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['TimeStart', 'TimeStop',
                                             'ProductionDate', 'ApproveDate',
                                             'CreateDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, inc...
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-09-10 17:45:52,283:INFO:Creating final display dataframe.
2025-09-10 17:45:53,069:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target         Man Power
2                   Target type        Regression
3           Original data shape        (7102, 26)
4        Transformed data shape       (7102, 117)
5   Transformed train set shape       (4971, 117)
6    Transformed test set shape       (2131, 117)
7              Numeric features                 2
8                 Date features                 5
9          Categorical features                18
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold              0.95
18               Transformation              True
19        Transformation method       yeo-johnson
20                    Normalize              True
21             Normalize method            zscore
22               Fold Generator             KFold
23                  Fold Number                10
24                     CPU Jobs                -1
25                      Use GPU             False
26               Log Experiment             False
27              Experiment Name  reg-default-name
28                          USI              eaa6
2025-09-10 17:45:53,151:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:45:53,154:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:45:53,231:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:45:53,232:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:45:53,233:INFO:setup() successfully completed in 3.05s...............
2025-09-10 17:45:56,504:INFO:Initializing compare_models()
2025-09-10 17:45:56,504:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BACB3150>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002C5BACB3150>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-09-10 17:45:56,504:INFO:Checking exceptions
2025-09-10 17:45:56,504:INFO:Preparing display monitor
2025-09-10 17:45:56,540:INFO:Initializing Linear Regression
2025-09-10 17:45:56,540:INFO:Total runtime is 0.0 minutes
2025-09-10 17:45:56,547:INFO:SubProcess create_model() called ==================================
2025-09-10 17:45:56,547:INFO:Initializing create_model()
2025-09-10 17:45:56,548:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BACB3150>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD933890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:45:56,548:INFO:Checking exceptions
2025-09-10 17:45:56,548:INFO:Importing libraries
2025-09-10 17:45:56,548:INFO:Copying training dataset
2025-09-10 17:45:56,556:INFO:Defining folds
2025-09-10 17:45:56,557:INFO:Declaring metric variables
2025-09-10 17:45:56,562:INFO:Importing untrained model
2025-09-10 17:45:56,570:INFO:Linear Regression Imported successfully
2025-09-10 17:45:56,589:INFO:Starting cross validation
2025-09-10 17:45:56,598:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:46:04,865:INFO:Calculating mean and std
2025-09-10 17:46:04,866:INFO:Creating metrics dataframe
2025-09-10 17:46:04,871:INFO:Uploading results into container
2025-09-10 17:46:04,872:INFO:Uploading model into container now
2025-09-10 17:46:04,873:INFO:_master_model_container: 1
2025-09-10 17:46:04,873:INFO:_display_container: 2
2025-09-10 17:46:04,874:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, positive=False)
2025-09-10 17:46:04,874:INFO:create_model() successfully completed......................................
2025-09-10 17:46:05,226:INFO:SubProcess create_model() end ==================================
2025-09-10 17:46:05,226:INFO:Creating metrics dataframe
2025-09-10 17:46:05,234:INFO:Initializing Lasso Regression
2025-09-10 17:46:05,234:INFO:Total runtime is 0.14491244554519653 minutes
2025-09-10 17:46:05,234:INFO:SubProcess create_model() called ==================================
2025-09-10 17:46:05,234:INFO:Initializing create_model()
2025-09-10 17:46:05,234:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BACB3150>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD933890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:46:05,234:INFO:Checking exceptions
2025-09-10 17:46:05,234:INFO:Importing libraries
2025-09-10 17:46:05,234:INFO:Copying training dataset
2025-09-10 17:46:05,246:INFO:Defining folds
2025-09-10 17:46:05,246:INFO:Declaring metric variables
2025-09-10 17:46:05,247:INFO:Importing untrained model
2025-09-10 17:46:05,254:INFO:Lasso Regression Imported successfully
2025-09-10 17:46:05,263:INFO:Starting cross validation
2025-09-10 17:46:05,268:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:46:09,892:INFO:Calculating mean and std
2025-09-10 17:46:09,892:INFO:Creating metrics dataframe
2025-09-10 17:46:09,898:INFO:Uploading results into container
2025-09-10 17:46:09,899:INFO:Uploading model into container now
2025-09-10 17:46:09,899:INFO:_master_model_container: 2
2025-09-10 17:46:09,899:INFO:_display_container: 2
2025-09-10 17:46:09,899:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-09-10 17:46:09,899:INFO:create_model() successfully completed......................................
2025-09-10 17:46:10,135:INFO:SubProcess create_model() end ==================================
2025-09-10 17:46:10,135:INFO:Creating metrics dataframe
2025-09-10 17:46:10,135:INFO:Initializing Ridge Regression
2025-09-10 17:46:10,135:INFO:Total runtime is 0.22658323446909584 minutes
2025-09-10 17:46:10,135:INFO:SubProcess create_model() called ==================================
2025-09-10 17:46:10,135:INFO:Initializing create_model()
2025-09-10 17:46:10,135:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BACB3150>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD933890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:46:10,135:INFO:Checking exceptions
2025-09-10 17:46:10,135:INFO:Importing libraries
2025-09-10 17:46:10,135:INFO:Copying training dataset
2025-09-10 17:46:10,148:INFO:Defining folds
2025-09-10 17:46:10,148:INFO:Declaring metric variables
2025-09-10 17:46:10,158:INFO:Importing untrained model
2025-09-10 17:46:10,162:INFO:Ridge Regression Imported successfully
2025-09-10 17:46:10,173:INFO:Starting cross validation
2025-09-10 17:46:10,173:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:46:12,363:INFO:Calculating mean and std
2025-09-10 17:46:12,364:INFO:Creating metrics dataframe
2025-09-10 17:46:12,367:INFO:Uploading results into container
2025-09-10 17:46:12,367:INFO:Uploading model into container now
2025-09-10 17:46:12,367:INFO:_master_model_container: 3
2025-09-10 17:46:12,368:INFO:_display_container: 2
2025-09-10 17:46:12,368:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=123, solver='auto', tol=0.0001)
2025-09-10 17:46:12,368:INFO:create_model() successfully completed......................................
2025-09-10 17:46:12,565:INFO:SubProcess create_model() end ==================================
2025-09-10 17:46:12,565:INFO:Creating metrics dataframe
2025-09-10 17:46:12,565:INFO:Initializing Elastic Net
2025-09-10 17:46:12,565:INFO:Total runtime is 0.26708557605743405 minutes
2025-09-10 17:46:12,579:INFO:SubProcess create_model() called ==================================
2025-09-10 17:46:12,579:INFO:Initializing create_model()
2025-09-10 17:46:12,579:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BACB3150>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD933890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:46:12,579:INFO:Checking exceptions
2025-09-10 17:46:12,579:INFO:Importing libraries
2025-09-10 17:46:12,579:INFO:Copying training dataset
2025-09-10 17:46:12,581:INFO:Defining folds
2025-09-10 17:46:12,581:INFO:Declaring metric variables
2025-09-10 17:46:12,589:INFO:Importing untrained model
2025-09-10 17:46:12,592:INFO:Elastic Net Imported successfully
2025-09-10 17:46:12,611:INFO:Starting cross validation
2025-09-10 17:46:12,615:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:46:14,825:INFO:Calculating mean and std
2025-09-10 17:46:14,825:INFO:Creating metrics dataframe
2025-09-10 17:46:14,825:INFO:Uploading results into container
2025-09-10 17:46:14,825:INFO:Uploading model into container now
2025-09-10 17:46:14,825:INFO:_master_model_container: 4
2025-09-10 17:46:14,825:INFO:_display_container: 2
2025-09-10 17:46:14,825:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=123,
           selection='cyclic', tol=0.0001, warm_start=False)
2025-09-10 17:46:14,825:INFO:create_model() successfully completed......................................
2025-09-10 17:46:15,016:INFO:SubProcess create_model() end ==================================
2025-09-10 17:46:15,016:INFO:Creating metrics dataframe
2025-09-10 17:46:15,016:INFO:Initializing Least Angle Regression
2025-09-10 17:46:15,016:INFO:Total runtime is 0.30793234109878537 minutes
2025-09-10 17:46:15,016:INFO:SubProcess create_model() called ==================================
2025-09-10 17:46:15,016:INFO:Initializing create_model()
2025-09-10 17:46:15,016:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BACB3150>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD933890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:46:15,016:INFO:Checking exceptions
2025-09-10 17:46:15,016:INFO:Importing libraries
2025-09-10 17:46:15,016:INFO:Copying training dataset
2025-09-10 17:46:15,032:INFO:Defining folds
2025-09-10 17:46:15,032:INFO:Declaring metric variables
2025-09-10 17:46:15,040:INFO:Importing untrained model
2025-09-10 17:46:15,043:INFO:Least Angle Regression Imported successfully
2025-09-10 17:46:15,058:INFO:Starting cross validation
2025-09-10 17:46:15,058:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:46:17,200:INFO:Calculating mean and std
2025-09-10 17:46:17,201:INFO:Creating metrics dataframe
2025-09-10 17:46:17,201:INFO:Uploading results into container
2025-09-10 17:46:17,201:INFO:Uploading model into container now
2025-09-10 17:46:17,201:INFO:_master_model_container: 5
2025-09-10 17:46:17,201:INFO:_display_container: 2
2025-09-10 17:46:17,201:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False)
2025-09-10 17:46:17,201:INFO:create_model() successfully completed......................................
2025-09-10 17:46:17,384:INFO:SubProcess create_model() end ==================================
2025-09-10 17:46:17,384:INFO:Creating metrics dataframe
2025-09-10 17:46:17,384:INFO:Initializing Lasso Least Angle Regression
2025-09-10 17:46:17,384:INFO:Total runtime is 0.34740327994028725 minutes
2025-09-10 17:46:17,384:INFO:SubProcess create_model() called ==================================
2025-09-10 17:46:17,384:INFO:Initializing create_model()
2025-09-10 17:46:17,384:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BACB3150>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD933890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:46:17,384:INFO:Checking exceptions
2025-09-10 17:46:17,384:INFO:Importing libraries
2025-09-10 17:46:17,384:INFO:Copying training dataset
2025-09-10 17:46:17,400:INFO:Defining folds
2025-09-10 17:46:17,400:INFO:Declaring metric variables
2025-09-10 17:46:17,407:INFO:Importing untrained model
2025-09-10 17:46:17,408:INFO:Lasso Least Angle Regression Imported successfully
2025-09-10 17:46:17,425:INFO:Starting cross validation
2025-09-10 17:46:17,426:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:46:19,584:INFO:Calculating mean and std
2025-09-10 17:46:19,584:INFO:Creating metrics dataframe
2025-09-10 17:46:19,585:INFO:Uploading results into container
2025-09-10 17:46:19,585:INFO:Uploading model into container now
2025-09-10 17:46:19,585:INFO:_master_model_container: 6
2025-09-10 17:46:19,585:INFO:_display_container: 2
2025-09-10 17:46:19,585:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False)
2025-09-10 17:46:19,585:INFO:create_model() successfully completed......................................
2025-09-10 17:46:19,770:INFO:SubProcess create_model() end ==================================
2025-09-10 17:46:19,770:INFO:Creating metrics dataframe
2025-09-10 17:46:19,776:INFO:Initializing Orthogonal Matching Pursuit
2025-09-10 17:46:19,776:INFO:Total runtime is 0.38726701339085895 minutes
2025-09-10 17:46:19,779:INFO:SubProcess create_model() called ==================================
2025-09-10 17:46:19,780:INFO:Initializing create_model()
2025-09-10 17:46:19,780:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BACB3150>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD933890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:46:19,780:INFO:Checking exceptions
2025-09-10 17:46:19,780:INFO:Importing libraries
2025-09-10 17:46:19,780:INFO:Copying training dataset
2025-09-10 17:46:19,781:INFO:Defining folds
2025-09-10 17:46:19,781:INFO:Declaring metric variables
2025-09-10 17:46:19,790:INFO:Importing untrained model
2025-09-10 17:46:19,798:INFO:Orthogonal Matching Pursuit Imported successfully
2025-09-10 17:46:19,811:INFO:Starting cross validation
2025-09-10 17:46:19,815:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:46:22,021:INFO:Calculating mean and std
2025-09-10 17:46:22,021:INFO:Creating metrics dataframe
2025-09-10 17:46:22,025:INFO:Uploading results into container
2025-09-10 17:46:22,025:INFO:Uploading model into container now
2025-09-10 17:46:22,026:INFO:_master_model_container: 7
2025-09-10 17:46:22,026:INFO:_display_container: 2
2025-09-10 17:46:22,026:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None)
2025-09-10 17:46:22,026:INFO:create_model() successfully completed......................................
2025-09-10 17:46:22,198:INFO:SubProcess create_model() end ==================================
2025-09-10 17:46:22,198:INFO:Creating metrics dataframe
2025-09-10 17:46:22,213:INFO:Initializing Bayesian Ridge
2025-09-10 17:46:22,214:INFO:Total runtime is 0.4279084801673889 minutes
2025-09-10 17:46:22,215:INFO:SubProcess create_model() called ==================================
2025-09-10 17:46:22,215:INFO:Initializing create_model()
2025-09-10 17:46:22,215:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BACB3150>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD933890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:46:22,215:INFO:Checking exceptions
2025-09-10 17:46:22,215:INFO:Importing libraries
2025-09-10 17:46:22,215:INFO:Copying training dataset
2025-09-10 17:46:22,226:INFO:Defining folds
2025-09-10 17:46:22,226:INFO:Declaring metric variables
2025-09-10 17:46:22,232:INFO:Importing untrained model
2025-09-10 17:46:22,241:INFO:Bayesian Ridge Imported successfully
2025-09-10 17:46:22,254:INFO:Starting cross validation
2025-09-10 17:46:22,256:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:46:24,550:INFO:Calculating mean and std
2025-09-10 17:46:24,551:INFO:Creating metrics dataframe
2025-09-10 17:46:24,551:INFO:Uploading results into container
2025-09-10 17:46:24,554:INFO:Uploading model into container now
2025-09-10 17:46:24,554:INFO:_master_model_container: 8
2025-09-10 17:46:24,554:INFO:_display_container: 2
2025-09-10 17:46:24,554:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, max_iter=None,
              n_iter='deprecated', tol=0.001, verbose=False)
2025-09-10 17:46:24,554:INFO:create_model() successfully completed......................................
2025-09-10 17:46:24,731:INFO:SubProcess create_model() end ==================================
2025-09-10 17:46:24,731:INFO:Creating metrics dataframe
2025-09-10 17:46:24,731:INFO:Initializing Passive Aggressive Regressor
2025-09-10 17:46:24,731:INFO:Total runtime is 0.46985974311828616 minutes
2025-09-10 17:46:24,748:INFO:SubProcess create_model() called ==================================
2025-09-10 17:46:24,748:INFO:Initializing create_model()
2025-09-10 17:46:24,748:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BACB3150>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD933890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:46:24,748:INFO:Checking exceptions
2025-09-10 17:46:24,748:INFO:Importing libraries
2025-09-10 17:46:24,748:INFO:Copying training dataset
2025-09-10 17:46:24,754:INFO:Defining folds
2025-09-10 17:46:24,754:INFO:Declaring metric variables
2025-09-10 17:46:24,761:INFO:Importing untrained model
2025-09-10 17:46:24,767:INFO:Passive Aggressive Regressor Imported successfully
2025-09-10 17:46:24,780:INFO:Starting cross validation
2025-09-10 17:46:24,784:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:46:26,957:INFO:Calculating mean and std
2025-09-10 17:46:26,957:INFO:Creating metrics dataframe
2025-09-10 17:46:26,958:INFO:Uploading results into container
2025-09-10 17:46:26,958:INFO:Uploading model into container now
2025-09-10 17:46:26,958:INFO:_master_model_container: 9
2025-09-10 17:46:26,958:INFO:_display_container: 2
2025-09-10 17:46:26,958:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=123, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-09-10 17:46:26,958:INFO:create_model() successfully completed......................................
2025-09-10 17:46:27,164:INFO:SubProcess create_model() end ==================================
2025-09-10 17:46:27,164:INFO:Creating metrics dataframe
2025-09-10 17:46:27,164:INFO:Initializing Huber Regressor
2025-09-10 17:46:27,164:INFO:Total runtime is 0.5104116678237915 minutes
2025-09-10 17:46:27,181:INFO:SubProcess create_model() called ==================================
2025-09-10 17:46:27,181:INFO:Initializing create_model()
2025-09-10 17:46:27,181:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BACB3150>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD933890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:46:27,181:INFO:Checking exceptions
2025-09-10 17:46:27,181:INFO:Importing libraries
2025-09-10 17:46:27,181:INFO:Copying training dataset
2025-09-10 17:46:27,181:INFO:Defining folds
2025-09-10 17:46:27,181:INFO:Declaring metric variables
2025-09-10 17:46:27,192:INFO:Importing untrained model
2025-09-10 17:46:27,201:INFO:Huber Regressor Imported successfully
2025-09-10 17:46:27,216:INFO:Starting cross validation
2025-09-10 17:46:27,219:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:46:30,699:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-09-10 17:46:30,910:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-09-10 17:46:31,019:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-09-10 17:46:31,085:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-09-10 17:46:31,100:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-09-10 17:46:31,100:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-09-10 17:46:31,107:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-09-10 17:46:31,119:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-09-10 17:46:31,232:INFO:Calculating mean and std
2025-09-10 17:46:31,232:INFO:Creating metrics dataframe
2025-09-10 17:46:31,232:INFO:Uploading results into container
2025-09-10 17:46:31,232:INFO:Uploading model into container now
2025-09-10 17:46:31,232:INFO:_master_model_container: 10
2025-09-10 17:46:31,232:INFO:_display_container: 2
2025-09-10 17:46:31,232:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2025-09-10 17:46:31,232:INFO:create_model() successfully completed......................................
2025-09-10 17:46:31,413:INFO:SubProcess create_model() end ==================================
2025-09-10 17:46:31,413:INFO:Creating metrics dataframe
2025-09-10 17:46:31,413:INFO:Initializing K Neighbors Regressor
2025-09-10 17:46:31,413:INFO:Total runtime is 0.5812228878339132 minutes
2025-09-10 17:46:31,429:INFO:SubProcess create_model() called ==================================
2025-09-10 17:46:31,429:INFO:Initializing create_model()
2025-09-10 17:46:31,430:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BACB3150>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD933890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:46:31,430:INFO:Checking exceptions
2025-09-10 17:46:31,430:INFO:Importing libraries
2025-09-10 17:46:31,430:INFO:Copying training dataset
2025-09-10 17:46:31,436:INFO:Defining folds
2025-09-10 17:46:31,436:INFO:Declaring metric variables
2025-09-10 17:46:31,442:INFO:Importing untrained model
2025-09-10 17:46:31,450:INFO:K Neighbors Regressor Imported successfully
2025-09-10 17:46:31,463:INFO:Starting cross validation
2025-09-10 17:46:31,466:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:46:33,810:INFO:Calculating mean and std
2025-09-10 17:46:33,810:INFO:Creating metrics dataframe
2025-09-10 17:46:33,813:INFO:Uploading results into container
2025-09-10 17:46:33,813:INFO:Uploading model into container now
2025-09-10 17:46:33,813:INFO:_master_model_container: 11
2025-09-10 17:46:33,813:INFO:_display_container: 2
2025-09-10 17:46:33,813:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2025-09-10 17:46:33,813:INFO:create_model() successfully completed......................................
2025-09-10 17:46:34,018:INFO:SubProcess create_model() end ==================================
2025-09-10 17:46:34,018:INFO:Creating metrics dataframe
2025-09-10 17:46:34,024:INFO:Initializing Decision Tree Regressor
2025-09-10 17:46:34,024:INFO:Total runtime is 0.624741800626119 minutes
2025-09-10 17:46:34,030:INFO:SubProcess create_model() called ==================================
2025-09-10 17:46:34,030:INFO:Initializing create_model()
2025-09-10 17:46:34,030:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BACB3150>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD933890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:46:34,030:INFO:Checking exceptions
2025-09-10 17:46:34,030:INFO:Importing libraries
2025-09-10 17:46:34,030:INFO:Copying training dataset
2025-09-10 17:46:34,030:INFO:Defining folds
2025-09-10 17:46:34,030:INFO:Declaring metric variables
2025-09-10 17:46:34,041:INFO:Importing untrained model
2025-09-10 17:46:34,049:INFO:Decision Tree Regressor Imported successfully
2025-09-10 17:46:34,060:INFO:Starting cross validation
2025-09-10 17:46:34,067:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:46:36,400:INFO:Calculating mean and std
2025-09-10 17:46:36,400:INFO:Creating metrics dataframe
2025-09-10 17:46:36,400:INFO:Uploading results into container
2025-09-10 17:46:36,400:INFO:Uploading model into container now
2025-09-10 17:46:36,400:INFO:_master_model_container: 12
2025-09-10 17:46:36,400:INFO:_display_container: 2
2025-09-10 17:46:36,400:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=123, splitter='best')
2025-09-10 17:46:36,400:INFO:create_model() successfully completed......................................
2025-09-10 17:46:36,587:INFO:SubProcess create_model() end ==================================
2025-09-10 17:46:36,587:INFO:Creating metrics dataframe
2025-09-10 17:46:36,593:INFO:Initializing Random Forest Regressor
2025-09-10 17:46:36,593:INFO:Total runtime is 0.6675579786300659 minutes
2025-09-10 17:46:36,596:INFO:SubProcess create_model() called ==================================
2025-09-10 17:46:36,596:INFO:Initializing create_model()
2025-09-10 17:46:36,596:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BACB3150>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD933890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:46:36,596:INFO:Checking exceptions
2025-09-10 17:46:36,596:INFO:Importing libraries
2025-09-10 17:46:36,596:INFO:Copying training dataset
2025-09-10 17:46:36,606:INFO:Defining folds
2025-09-10 17:46:36,606:INFO:Declaring metric variables
2025-09-10 17:46:36,613:INFO:Importing untrained model
2025-09-10 17:46:36,618:INFO:Random Forest Regressor Imported successfully
2025-09-10 17:46:36,631:INFO:Starting cross validation
2025-09-10 17:46:36,636:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:46:39,892:INFO:Calculating mean and std
2025-09-10 17:46:39,892:INFO:Creating metrics dataframe
2025-09-10 17:46:39,892:INFO:Uploading results into container
2025-09-10 17:46:39,892:INFO:Uploading model into container now
2025-09-10 17:46:39,892:INFO:_master_model_container: 13
2025-09-10 17:46:39,892:INFO:_display_container: 2
2025-09-10 17:46:39,892:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, monotonic_cst=None,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=123, verbose=0, warm_start=False)
2025-09-10 17:46:39,892:INFO:create_model() successfully completed......................................
2025-09-10 17:46:40,080:INFO:SubProcess create_model() end ==================================
2025-09-10 17:46:40,080:INFO:Creating metrics dataframe
2025-09-10 17:46:40,095:INFO:Initializing Extra Trees Regressor
2025-09-10 17:46:40,095:INFO:Total runtime is 0.7259282072385153 minutes
2025-09-10 17:46:40,095:INFO:SubProcess create_model() called ==================================
2025-09-10 17:46:40,095:INFO:Initializing create_model()
2025-09-10 17:46:40,095:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BACB3150>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD933890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:46:40,095:INFO:Checking exceptions
2025-09-10 17:46:40,095:INFO:Importing libraries
2025-09-10 17:46:40,095:INFO:Copying training dataset
2025-09-10 17:46:40,095:INFO:Defining folds
2025-09-10 17:46:40,095:INFO:Declaring metric variables
2025-09-10 17:46:40,114:INFO:Importing untrained model
2025-09-10 17:46:40,120:INFO:Extra Trees Regressor Imported successfully
2025-09-10 17:46:40,135:INFO:Starting cross validation
2025-09-10 17:46:40,139:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:46:43,306:INFO:Calculating mean and std
2025-09-10 17:46:43,306:INFO:Creating metrics dataframe
2025-09-10 17:46:43,306:INFO:Uploading results into container
2025-09-10 17:46:43,306:INFO:Uploading model into container now
2025-09-10 17:46:43,306:INFO:_master_model_container: 14
2025-09-10 17:46:43,306:INFO:_display_container: 2
2025-09-10 17:46:43,306:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False)
2025-09-10 17:46:43,306:INFO:create_model() successfully completed......................................
2025-09-10 17:46:43,482:INFO:SubProcess create_model() end ==================================
2025-09-10 17:46:43,482:INFO:Creating metrics dataframe
2025-09-10 17:46:43,503:INFO:Initializing AdaBoost Regressor
2025-09-10 17:46:43,503:INFO:Total runtime is 0.7827257513999939 minutes
2025-09-10 17:46:43,503:INFO:SubProcess create_model() called ==================================
2025-09-10 17:46:43,503:INFO:Initializing create_model()
2025-09-10 17:46:43,503:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BACB3150>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD933890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:46:43,503:INFO:Checking exceptions
2025-09-10 17:46:43,503:INFO:Importing libraries
2025-09-10 17:46:43,503:INFO:Copying training dataset
2025-09-10 17:46:43,518:INFO:Defining folds
2025-09-10 17:46:43,518:INFO:Declaring metric variables
2025-09-10 17:46:43,525:INFO:Importing untrained model
2025-09-10 17:46:43,531:INFO:AdaBoost Regressor Imported successfully
2025-09-10 17:46:43,541:INFO:Starting cross validation
2025-09-10 17:46:43,548:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:46:46,641:INFO:Calculating mean and std
2025-09-10 17:46:46,641:INFO:Creating metrics dataframe
2025-09-10 17:46:46,644:INFO:Uploading results into container
2025-09-10 17:46:46,644:INFO:Uploading model into container now
2025-09-10 17:46:46,644:INFO:_master_model_container: 15
2025-09-10 17:46:46,644:INFO:_display_container: 2
2025-09-10 17:46:46,644:INFO:AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=123)
2025-09-10 17:46:46,644:INFO:create_model() successfully completed......................................
2025-09-10 17:46:46,829:INFO:SubProcess create_model() end ==================================
2025-09-10 17:46:46,829:INFO:Creating metrics dataframe
2025-09-10 17:46:46,841:INFO:Initializing Gradient Boosting Regressor
2025-09-10 17:46:46,841:INFO:Total runtime is 0.8383586208025614 minutes
2025-09-10 17:46:46,846:INFO:SubProcess create_model() called ==================================
2025-09-10 17:46:46,847:INFO:Initializing create_model()
2025-09-10 17:46:46,847:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BACB3150>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD933890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:46:46,847:INFO:Checking exceptions
2025-09-10 17:46:46,847:INFO:Importing libraries
2025-09-10 17:46:46,847:INFO:Copying training dataset
2025-09-10 17:46:46,853:INFO:Defining folds
2025-09-10 17:46:46,853:INFO:Declaring metric variables
2025-09-10 17:46:46,861:INFO:Importing untrained model
2025-09-10 17:46:46,868:INFO:Gradient Boosting Regressor Imported successfully
2025-09-10 17:46:46,879:INFO:Starting cross validation
2025-09-10 17:46:46,881:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:46:50,312:INFO:Calculating mean and std
2025-09-10 17:46:50,312:INFO:Creating metrics dataframe
2025-09-10 17:46:50,317:INFO:Uploading results into container
2025-09-10 17:46:50,318:INFO:Uploading model into container now
2025-09-10 17:46:50,318:INFO:_master_model_container: 16
2025-09-10 17:46:50,319:INFO:_display_container: 2
2025-09-10 17:46:50,319:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=123, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-09-10 17:46:50,319:INFO:create_model() successfully completed......................................
2025-09-10 17:46:50,496:INFO:SubProcess create_model() end ==================================
2025-09-10 17:46:50,512:INFO:Creating metrics dataframe
2025-09-10 17:46:50,512:INFO:Initializing Extreme Gradient Boosting
2025-09-10 17:46:50,512:INFO:Total runtime is 0.8995340903600056 minutes
2025-09-10 17:46:50,512:INFO:SubProcess create_model() called ==================================
2025-09-10 17:46:50,512:INFO:Initializing create_model()
2025-09-10 17:46:50,512:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BACB3150>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD933890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:46:50,512:INFO:Checking exceptions
2025-09-10 17:46:50,512:INFO:Importing libraries
2025-09-10 17:46:50,512:INFO:Copying training dataset
2025-09-10 17:46:50,531:INFO:Defining folds
2025-09-10 17:46:50,531:INFO:Declaring metric variables
2025-09-10 17:46:50,539:INFO:Importing untrained model
2025-09-10 17:46:50,543:INFO:Extreme Gradient Boosting Imported successfully
2025-09-10 17:46:50,559:INFO:Starting cross validation
2025-09-10 17:46:50,564:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:46:53,172:INFO:Calculating mean and std
2025-09-10 17:46:53,172:INFO:Creating metrics dataframe
2025-09-10 17:46:53,172:INFO:Uploading results into container
2025-09-10 17:46:53,172:INFO:Uploading model into container now
2025-09-10 17:46:53,172:INFO:_master_model_container: 17
2025-09-10 17:46:53,172:INFO:_display_container: 2
2025-09-10 17:46:53,172:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-09-10 17:46:53,172:INFO:create_model() successfully completed......................................
2025-09-10 17:46:53,376:INFO:SubProcess create_model() end ==================================
2025-09-10 17:46:53,376:INFO:Creating metrics dataframe
2025-09-10 17:46:53,384:INFO:Initializing Light Gradient Boosting Machine
2025-09-10 17:46:53,385:INFO:Total runtime is 0.947413961092631 minutes
2025-09-10 17:46:53,388:INFO:SubProcess create_model() called ==================================
2025-09-10 17:46:53,388:INFO:Initializing create_model()
2025-09-10 17:46:53,388:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BACB3150>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD933890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:46:53,389:INFO:Checking exceptions
2025-09-10 17:46:53,389:INFO:Importing libraries
2025-09-10 17:46:53,389:INFO:Copying training dataset
2025-09-10 17:46:53,393:INFO:Defining folds
2025-09-10 17:46:53,394:INFO:Declaring metric variables
2025-09-10 17:46:53,397:INFO:Importing untrained model
2025-09-10 17:46:53,404:INFO:Light Gradient Boosting Machine Imported successfully
2025-09-10 17:46:53,416:INFO:Starting cross validation
2025-09-10 17:46:53,418:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:46:57,342:INFO:Calculating mean and std
2025-09-10 17:46:57,342:INFO:Creating metrics dataframe
2025-09-10 17:46:57,347:INFO:Uploading results into container
2025-09-10 17:46:57,348:INFO:Uploading model into container now
2025-09-10 17:46:57,348:INFO:_master_model_container: 18
2025-09-10 17:46:57,348:INFO:_display_container: 2
2025-09-10 17:46:57,349:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-09-10 17:46:57,350:INFO:create_model() successfully completed......................................
2025-09-10 17:46:57,545:INFO:SubProcess create_model() end ==================================
2025-09-10 17:46:57,545:INFO:Creating metrics dataframe
2025-09-10 17:46:57,564:INFO:Initializing CatBoost Regressor
2025-09-10 17:46:57,565:INFO:Total runtime is 1.0170847415924071 minutes
2025-09-10 17:46:57,565:INFO:SubProcess create_model() called ==================================
2025-09-10 17:46:57,565:INFO:Initializing create_model()
2025-09-10 17:46:57,565:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BACB3150>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD933890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:46:57,565:INFO:Checking exceptions
2025-09-10 17:46:57,565:INFO:Importing libraries
2025-09-10 17:46:57,565:INFO:Copying training dataset
2025-09-10 17:46:57,574:INFO:Defining folds
2025-09-10 17:46:57,574:INFO:Declaring metric variables
2025-09-10 17:46:57,581:INFO:Importing untrained model
2025-09-10 17:46:57,587:INFO:CatBoost Regressor Imported successfully
2025-09-10 17:46:57,598:INFO:Starting cross validation
2025-09-10 17:46:57,602:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:47:10,167:INFO:Calculating mean and std
2025-09-10 17:47:10,167:INFO:Creating metrics dataframe
2025-09-10 17:47:10,170:INFO:Uploading results into container
2025-09-10 17:47:10,170:INFO:Uploading model into container now
2025-09-10 17:47:10,170:INFO:_master_model_container: 19
2025-09-10 17:47:10,170:INFO:_display_container: 2
2025-09-10 17:47:10,170:INFO:<catboost.core.CatBoostRegressor object at 0x000002C5BE2F5250>
2025-09-10 17:47:10,170:INFO:create_model() successfully completed......................................
2025-09-10 17:47:10,370:INFO:SubProcess create_model() end ==================================
2025-09-10 17:47:10,371:INFO:Creating metrics dataframe
2025-09-10 17:47:10,379:INFO:Initializing Dummy Regressor
2025-09-10 17:47:10,379:INFO:Total runtime is 1.230651009082794 minutes
2025-09-10 17:47:10,384:INFO:SubProcess create_model() called ==================================
2025-09-10 17:47:10,385:INFO:Initializing create_model()
2025-09-10 17:47:10,385:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BACB3150>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C5BD933890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:47:10,385:INFO:Checking exceptions
2025-09-10 17:47:10,385:INFO:Importing libraries
2025-09-10 17:47:10,385:INFO:Copying training dataset
2025-09-10 17:47:10,390:INFO:Defining folds
2025-09-10 17:47:10,390:INFO:Declaring metric variables
2025-09-10 17:47:10,397:INFO:Importing untrained model
2025-09-10 17:47:10,401:INFO:Dummy Regressor Imported successfully
2025-09-10 17:47:10,415:INFO:Starting cross validation
2025-09-10 17:47:10,419:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:47:13,262:INFO:Calculating mean and std
2025-09-10 17:47:13,265:INFO:Creating metrics dataframe
2025-09-10 17:47:13,270:INFO:Uploading results into container
2025-09-10 17:47:13,270:INFO:Uploading model into container now
2025-09-10 17:47:13,270:INFO:_master_model_container: 20
2025-09-10 17:47:13,270:INFO:_display_container: 2
2025-09-10 17:47:13,270:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2025-09-10 17:47:13,270:INFO:create_model() successfully completed......................................
2025-09-10 17:47:13,501:INFO:SubProcess create_model() end ==================================
2025-09-10 17:47:13,501:INFO:Creating metrics dataframe
2025-09-10 17:47:13,519:INFO:Initializing create_model()
2025-09-10 17:47:13,519:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BACB3150>, estimator=KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform'), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:47:13,519:INFO:Checking exceptions
2025-09-10 17:47:13,519:INFO:Importing libraries
2025-09-10 17:47:13,519:INFO:Copying training dataset
2025-09-10 17:47:13,532:INFO:Defining folds
2025-09-10 17:47:13,532:INFO:Declaring metric variables
2025-09-10 17:47:13,534:INFO:Importing untrained model
2025-09-10 17:47:13,534:INFO:Declaring custom model
2025-09-10 17:47:13,534:INFO:K Neighbors Regressor Imported successfully
2025-09-10 17:47:13,536:INFO:Cross validation set to False
2025-09-10 17:47:13,536:INFO:Fitting Model
2025-09-10 17:47:14,415:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2025-09-10 17:47:14,416:INFO:create_model() successfully completed......................................
2025-09-10 17:47:14,656:INFO:_master_model_container: 20
2025-09-10 17:47:14,656:INFO:_display_container: 2
2025-09-10 17:47:14,656:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2025-09-10 17:47:14,656:INFO:compare_models() successfully completed......................................
2025-09-10 17:52:06,022:INFO:Initializing create_model()
2025-09-10 17:52:06,022:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BACB3150>, estimator=knn, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=True, error_score=0.0, kwargs={})
2025-09-10 17:52:06,022:INFO:Checking exceptions
2025-09-10 17:52:06,040:INFO:Importing libraries
2025-09-10 17:52:06,041:INFO:Copying training dataset
2025-09-10 17:52:06,049:INFO:Defining folds
2025-09-10 17:52:06,049:INFO:Declaring metric variables
2025-09-10 17:52:06,054:INFO:Importing untrained model
2025-09-10 17:52:06,060:INFO:K Neighbors Regressor Imported successfully
2025-09-10 17:52:06,075:INFO:Starting cross validation
2025-09-10 17:52:06,078:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 17:52:09,575:INFO:Calculating mean and std
2025-09-10 17:52:09,575:INFO:Creating metrics dataframe
2025-09-10 17:52:09,581:INFO:Finalizing model
2025-09-10 17:52:10,487:INFO:Initializing predict_model()
2025-09-10 17:52:10,487:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BACB3150>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None,
                                    include=['TimeStart', 'TimeStop',
                                             'ProductionDate', 'ApproveDate',
                                             'CreateDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['Qty', 'isNC'],
                                    transformer=SimpleImput...
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 KNeighborsRegressor(algorithm='auto', leaf_size=30,
                                     metric='minkowski', metric_params=None,
                                     n_jobs=-1, n_neighbors=5, p=2,
                                     weights='uniform'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C5BE510360>)
2025-09-10 17:52:10,487:INFO:Checking exceptions
2025-09-10 17:52:10,487:INFO:Preloading libraries
2025-09-10 17:52:10,487:INFO:Set up data.
2025-09-10 17:52:10,493:INFO:Set up index.
2025-09-10 17:52:11,559:INFO:Uploading results into container
2025-09-10 17:52:11,561:INFO:Uploading model into container now
2025-09-10 17:52:11,577:INFO:_master_model_container: 21
2025-09-10 17:52:11,577:INFO:_display_container: 3
2025-09-10 17:52:11,577:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2025-09-10 17:52:11,577:INFO:create_model() successfully completed......................................
2025-09-10 17:57:40,994:INFO:Initializing tune_model()
2025-09-10 17:57:40,994:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002C5BACB3150>, estimator=KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform'), fold=None, round=4, n_iter=25, custom_grid=None, optimize=MAE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-09-10 17:57:40,994:INFO:Checking exceptions
2025-09-10 17:57:40,994:INFO:Soft dependency imported: optuna: 4.3.0
2025-09-10 17:57:41,143:INFO:Copying training dataset
2025-09-10 17:57:41,149:INFO:Checking base model
2025-09-10 17:57:41,150:INFO:Base model : K Neighbors Regressor
2025-09-10 17:57:41,155:INFO:Declaring metric variables
2025-09-10 17:57:41,162:INFO:Defining Hyperparameters
2025-09-10 17:57:41,415:INFO:Tuning with n_jobs=-1
2025-09-10 17:57:41,416:INFO:Initializing optuna.integration.OptunaSearchCV
2025-09-10 17:59:31,464:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 17:59:31,464:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 17:59:31,464:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 17:59:31,464:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-10 17:59:48,208:INFO:PyCaret RegressionExperiment
2025-09-10 17:59:48,208:INFO:Logging name: reg-default-name
2025-09-10 17:59:48,209:INFO:ML Usecase: MLUsecase.REGRESSION
2025-09-10 17:59:48,209:INFO:version 3.3.2
2025-09-10 17:59:48,209:INFO:Initializing setup()
2025-09-10 17:59:48,209:INFO:self.USI: e756
2025-09-10 17:59:48,209:INFO:self._variable_keys: {'data', 'fold_generator', 'y', 'idx', 'gpu_param', 'y_test', 'pipeline', 'logging_param', '_available_plots', 'seed', 'fold_shuffle_param', 'y_train', 'X_test', 'target_param', 'X', 'html_param', 'exp_id', 'USI', '_ml_usecase', 'log_plots_param', 'fold_groups_param', 'X_train', 'transform_target_param', 'gpu_n_jobs_param', 'memory', 'exp_name_log', 'n_jobs_param'}
2025-09-10 17:59:48,210:INFO:Checking environment
2025-09-10 17:59:48,210:INFO:python_version: 3.11.10
2025-09-10 17:59:48,210:INFO:python_build: ('main', 'Oct  3 2024 07:22:26')
2025-09-10 17:59:48,210:INFO:machine: AMD64
2025-09-10 17:59:48,210:INFO:platform: Windows-10-10.0.26100-SP0
2025-09-10 17:59:48,220:INFO:Memory: svmem(total=16837152768, available=2824712192, percent=83.2, used=14012440576, free=2824712192)
2025-09-10 17:59:48,220:INFO:Physical Core: 10
2025-09-10 17:59:48,220:INFO:Logical Core: 12
2025-09-10 17:59:48,220:INFO:Checking libraries
2025-09-10 17:59:48,220:INFO:System:
2025-09-10 17:59:48,220:INFO:    python: 3.11.10 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:26) [MSC v.1929 64 bit (AMD64)]
2025-09-10 17:59:48,220:INFO:executable: c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\python.exe
2025-09-10 17:59:48,220:INFO:   machine: Windows-10-10.0.26100-SP0
2025-09-10 17:59:48,220:INFO:PyCaret required dependencies:
2025-09-10 17:59:48,732:INFO:                 pip: 24.2
2025-09-10 17:59:48,732:INFO:          setuptools: 75.1.0
2025-09-10 17:59:48,732:INFO:             pycaret: 3.3.2
2025-09-10 17:59:48,733:INFO:             IPython: 9.2.0
2025-09-10 17:59:48,733:INFO:          ipywidgets: 8.1.7
2025-09-10 17:59:48,733:INFO:                tqdm: 4.67.1
2025-09-10 17:59:48,733:INFO:               numpy: 1.24.4
2025-09-10 17:59:48,733:INFO:              pandas: 1.5.3
2025-09-10 17:59:48,733:INFO:              jinja2: 3.1.6
2025-09-10 17:59:48,733:INFO:               scipy: 1.11.4
2025-09-10 17:59:48,733:INFO:              joblib: 1.3.2
2025-09-10 17:59:48,733:INFO:             sklearn: 1.4.2
2025-09-10 17:59:48,733:INFO:                pyod: 2.0.5
2025-09-10 17:59:48,733:INFO:            imblearn: 0.13.0
2025-09-10 17:59:48,733:INFO:   category_encoders: 2.7.0
2025-09-10 17:59:48,733:INFO:            lightgbm: 4.6.0
2025-09-10 17:59:48,733:INFO:               numba: 0.61.0
2025-09-10 17:59:48,733:INFO:            requests: 2.32.3
2025-09-10 17:59:48,733:INFO:          matplotlib: 3.7.5
2025-09-10 17:59:48,733:INFO:          scikitplot: 0.3.7
2025-09-10 17:59:48,733:INFO:         yellowbrick: 1.5
2025-09-10 17:59:48,733:INFO:              plotly: 5.24.1
2025-09-10 17:59:48,733:INFO:    plotly-resampler: Not installed
2025-09-10 17:59:48,733:INFO:             kaleido: 0.2.1
2025-09-10 17:59:48,733:INFO:           schemdraw: 0.15
2025-09-10 17:59:48,733:INFO:         statsmodels: 0.14.4
2025-09-10 17:59:48,733:INFO:              sktime: 0.26.0
2025-09-10 17:59:48,733:INFO:               tbats: 1.1.3
2025-09-10 17:59:48,733:INFO:            pmdarima: 2.0.4
2025-09-10 17:59:48,733:INFO:              psutil: 7.0.0
2025-09-10 17:59:48,733:INFO:          markupsafe: 3.0.2
2025-09-10 17:59:48,733:INFO:             pickle5: Not installed
2025-09-10 17:59:48,733:INFO:         cloudpickle: 3.1.1
2025-09-10 17:59:48,733:INFO:         deprecation: 2.1.0
2025-09-10 17:59:48,733:INFO:              xxhash: 3.5.0
2025-09-10 17:59:48,733:INFO:           wurlitzer: Not installed
2025-09-10 17:59:48,733:INFO:PyCaret optional dependencies:
2025-09-10 17:59:52,171:INFO:                shap: 0.44.1
2025-09-10 17:59:52,171:INFO:           interpret: 0.6.11
2025-09-10 17:59:52,171:INFO:                umap: 0.5.7
2025-09-10 17:59:52,172:INFO:     ydata_profiling: 4.16.1
2025-09-10 17:59:52,172:INFO:  explainerdashboard: 0.5.1
2025-09-10 17:59:52,172:INFO:             autoviz: Not installed
2025-09-10 17:59:52,172:INFO:           fairlearn: 0.7.0
2025-09-10 17:59:52,172:INFO:          deepchecks: Not installed
2025-09-10 17:59:52,172:INFO:             xgboost: 3.0.2
2025-09-10 17:59:52,172:INFO:            catboost: 1.2.8
2025-09-10 17:59:52,172:INFO:              kmodes: 0.12.2
2025-09-10 17:59:52,172:INFO:             mlxtend: 0.23.4
2025-09-10 17:59:52,172:INFO:       statsforecast: 1.5.0
2025-09-10 17:59:52,172:INFO:        tune_sklearn: Not installed
2025-09-10 17:59:52,172:INFO:                 ray: Not installed
2025-09-10 17:59:52,172:INFO:            hyperopt: 0.2.7
2025-09-10 17:59:52,172:INFO:              optuna: 4.3.0
2025-09-10 17:59:52,172:INFO:               skopt: 0.10.2
2025-09-10 17:59:52,172:INFO:              mlflow: 3.1.0
2025-09-10 17:59:52,172:INFO:              gradio: 5.33.1
2025-09-10 17:59:52,172:INFO:             fastapi: 0.115.12
2025-09-10 17:59:52,172:INFO:             uvicorn: 0.34.3
2025-09-10 17:59:52,172:INFO:              m2cgen: 0.10.0
2025-09-10 17:59:52,172:INFO:           evidently: 0.4.40
2025-09-10 17:59:52,172:INFO:               fugue: 0.8.7
2025-09-10 17:59:52,172:INFO:           streamlit: 1.45.1
2025-09-10 17:59:52,173:INFO:             prophet: 1.1.7
2025-09-10 17:59:52,173:INFO:None
2025-09-10 17:59:52,173:INFO:Set up data.
2025-09-10 17:59:52,197:INFO:Set up folding strategy.
2025-09-10 17:59:52,197:INFO:Set up train/test split.
2025-09-10 17:59:52,205:INFO:Set up index.
2025-09-10 17:59:52,205:INFO:Assigning column types.
2025-09-10 17:59:52,209:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-09-10 17:59:52,209:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-09-10 17:59:52,211:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-09-10 17:59:52,214:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-09-10 17:59:52,248:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:59:52,275:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:59:52,276:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:59:52,278:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:59:52,306:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-09-10 17:59:52,309:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-09-10 17:59:52,312:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-09-10 17:59:52,348:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:59:52,375:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:59:52,375:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:59:52,377:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:59:52,378:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-09-10 17:59:52,381:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-09-10 17:59:52,383:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-09-10 17:59:52,418:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:59:52,443:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:59:52,444:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:59:52,446:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:59:52,450:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-09-10 17:59:52,453:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-09-10 17:59:52,487:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:59:52,516:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:59:52,516:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:59:52,518:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:59:52,518:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-09-10 17:59:52,523:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-09-10 17:59:52,559:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:59:52,577:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:59:52,577:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:59:52,577:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:59:52,593:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-09-10 17:59:52,626:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:59:52,644:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:59:52,644:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:59:52,644:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:59:52,644:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-09-10 17:59:52,692:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:59:52,709:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:59:52,709:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:59:52,709:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:59:52,759:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:59:52,785:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-10 17:59:52,785:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:59:52,785:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:59:52,785:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-09-10 17:59:52,828:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:59:52,845:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:59:52,860:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:59:52,894:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-09-10 17:59:52,926:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:59:52,928:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:59:52,929:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-09-10 17:59:52,994:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:59:52,994:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:59:53,060:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:59:53,060:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:59:53,060:INFO:Preparing preprocessing pipeline...
2025-09-10 17:59:53,060:INFO:Set up date feature engineering.
2025-09-10 17:59:53,060:INFO:Set up simple imputation.
2025-09-10 17:59:53,060:INFO:Set up encoding of categorical features.
2025-09-10 17:59:53,060:INFO:Set up removing multicollinearity.
2025-09-10 17:59:53,060:INFO:Set up column transformation.
2025-09-10 17:59:53,060:INFO:Set up feature normalization.
2025-09-10 17:59:53,060:INFO:Set up column name cleaning.
2025-09-10 17:59:53,530:INFO:Finished creating preprocessing pipeline.
2025-09-10 17:59:53,553:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\SBM_ME~1\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['TimeStart', 'TimeStop',
                                             'ProductionDate', 'ApproveDate',
                                             'CreateDate'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Qty', 'isNC'],
                                    transformer=SimpleImputer())),
                ('categ...
                                                              handle_missing='return_nan'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-09-10 17:59:53,553:INFO:Creating final display dataframe.
2025-09-10 17:59:54,368:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target         Man Power
2                   Target type        Regression
3           Original data shape        (7102, 26)
4        Transformed data shape       (7102, 117)
5   Transformed train set shape       (4971, 117)
6    Transformed test set shape       (2131, 117)
7              Numeric features                 2
8                 Date features                 5
9          Categorical features                18
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold              0.95
18               Transformation              True
19        Transformation method       yeo-johnson
20                    Normalize              True
21             Normalize method            zscore
22               Fold Generator             KFold
23                  Fold Number                10
24                     CPU Jobs                -1
25                      Use GPU             False
26               Log Experiment             False
27              Experiment Name  reg-default-name
28                          USI              e756
2025-09-10 17:59:54,481:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:59:54,482:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:59:54,622:INFO:Soft dependency imported: xgboost: 3.0.2
2025-09-10 17:59:54,626:INFO:Soft dependency imported: catboost: 1.2.8
2025-09-10 17:59:54,629:INFO:setup() successfully completed in 6.48s...............
2025-09-10 17:59:54,872:INFO:Initializing compare_models()
2025-09-10 17:59:54,873:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023288562D90>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000023288562D90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-09-10 17:59:54,873:INFO:Checking exceptions
2025-09-10 17:59:54,879:INFO:Preparing display monitor
2025-09-10 17:59:54,950:INFO:Initializing Linear Regression
2025-09-10 17:59:54,950:INFO:Total runtime is 0.0 minutes
2025-09-10 17:59:54,963:INFO:SubProcess create_model() called ==================================
2025-09-10 17:59:54,965:INFO:Initializing create_model()
2025-09-10 17:59:54,965:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023288562D90>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002328826F150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 17:59:54,965:INFO:Checking exceptions
2025-09-10 17:59:54,965:INFO:Importing libraries
2025-09-10 17:59:54,965:INFO:Copying training dataset
2025-09-10 17:59:54,978:INFO:Defining folds
2025-09-10 17:59:54,979:INFO:Declaring metric variables
2025-09-10 17:59:54,984:INFO:Importing untrained model
2025-09-10 17:59:54,992:INFO:Linear Regression Imported successfully
2025-09-10 17:59:55,009:INFO:Starting cross validation
2025-09-10 17:59:55,026:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 18:00:05,408:INFO:Calculating mean and std
2025-09-10 18:00:05,410:INFO:Creating metrics dataframe
2025-09-10 18:00:05,414:INFO:Uploading results into container
2025-09-10 18:00:05,416:INFO:Uploading model into container now
2025-09-10 18:00:05,416:INFO:_master_model_container: 1
2025-09-10 18:00:05,418:INFO:_display_container: 2
2025-09-10 18:00:05,419:INFO:LinearRegression(n_jobs=-1)
2025-09-10 18:00:05,419:INFO:create_model() successfully completed......................................
2025-09-10 18:00:05,584:INFO:SubProcess create_model() end ==================================
2025-09-10 18:00:05,586:INFO:Creating metrics dataframe
2025-09-10 18:00:05,592:INFO:Initializing Lasso Regression
2025-09-10 18:00:05,593:INFO:Total runtime is 0.17736729780832927 minutes
2025-09-10 18:00:05,598:INFO:SubProcess create_model() called ==================================
2025-09-10 18:00:05,598:INFO:Initializing create_model()
2025-09-10 18:00:05,598:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023288562D90>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002328826F150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 18:00:05,598:INFO:Checking exceptions
2025-09-10 18:00:05,598:INFO:Importing libraries
2025-09-10 18:00:05,598:INFO:Copying training dataset
2025-09-10 18:00:05,604:INFO:Defining folds
2025-09-10 18:00:05,604:INFO:Declaring metric variables
2025-09-10 18:00:05,611:INFO:Importing untrained model
2025-09-10 18:00:05,619:INFO:Lasso Regression Imported successfully
2025-09-10 18:00:05,632:INFO:Starting cross validation
2025-09-10 18:00:05,636:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 18:00:10,762:INFO:Calculating mean and std
2025-09-10 18:00:10,762:INFO:Creating metrics dataframe
2025-09-10 18:00:10,762:INFO:Uploading results into container
2025-09-10 18:00:10,762:INFO:Uploading model into container now
2025-09-10 18:00:10,762:INFO:_master_model_container: 2
2025-09-10 18:00:10,762:INFO:_display_container: 2
2025-09-10 18:00:10,762:INFO:Lasso(random_state=123)
2025-09-10 18:00:10,762:INFO:create_model() successfully completed......................................
2025-09-10 18:00:10,889:INFO:SubProcess create_model() end ==================================
2025-09-10 18:00:10,889:INFO:Creating metrics dataframe
2025-09-10 18:00:10,892:INFO:Initializing Ridge Regression
2025-09-10 18:00:10,892:INFO:Total runtime is 0.26570515235265096 minutes
2025-09-10 18:00:10,892:INFO:SubProcess create_model() called ==================================
2025-09-10 18:00:10,892:INFO:Initializing create_model()
2025-09-10 18:00:10,892:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023288562D90>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002328826F150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 18:00:10,892:INFO:Checking exceptions
2025-09-10 18:00:10,892:INFO:Importing libraries
2025-09-10 18:00:10,892:INFO:Copying training dataset
2025-09-10 18:00:10,892:INFO:Defining folds
2025-09-10 18:00:10,908:INFO:Declaring metric variables
2025-09-10 18:00:10,914:INFO:Importing untrained model
2025-09-10 18:00:10,914:INFO:Ridge Regression Imported successfully
2025-09-10 18:00:10,931:INFO:Starting cross validation
2025-09-10 18:00:10,931:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 18:00:13,187:INFO:Calculating mean and std
2025-09-10 18:00:13,187:INFO:Creating metrics dataframe
2025-09-10 18:00:13,190:INFO:Uploading results into container
2025-09-10 18:00:13,190:INFO:Uploading model into container now
2025-09-10 18:00:13,190:INFO:_master_model_container: 3
2025-09-10 18:00:13,190:INFO:_display_container: 2
2025-09-10 18:00:13,190:INFO:Ridge(random_state=123)
2025-09-10 18:00:13,193:INFO:create_model() successfully completed......................................
2025-09-10 18:00:13,289:INFO:SubProcess create_model() end ==================================
2025-09-10 18:00:13,289:INFO:Creating metrics dataframe
2025-09-10 18:00:13,306:INFO:Initializing Elastic Net
2025-09-10 18:00:13,306:INFO:Total runtime is 0.3059275190035502 minutes
2025-09-10 18:00:13,306:INFO:SubProcess create_model() called ==================================
2025-09-10 18:00:13,306:INFO:Initializing create_model()
2025-09-10 18:00:13,306:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023288562D90>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002328826F150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 18:00:13,306:INFO:Checking exceptions
2025-09-10 18:00:13,306:INFO:Importing libraries
2025-09-10 18:00:13,306:INFO:Copying training dataset
2025-09-10 18:00:13,317:INFO:Defining folds
2025-09-10 18:00:13,317:INFO:Declaring metric variables
2025-09-10 18:00:13,324:INFO:Importing untrained model
2025-09-10 18:00:13,331:INFO:Elastic Net Imported successfully
2025-09-10 18:00:13,345:INFO:Starting cross validation
2025-09-10 18:00:13,348:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 18:00:15,738:INFO:Calculating mean and std
2025-09-10 18:00:15,738:INFO:Creating metrics dataframe
2025-09-10 18:00:15,738:INFO:Uploading results into container
2025-09-10 18:00:15,738:INFO:Uploading model into container now
2025-09-10 18:00:15,738:INFO:_master_model_container: 4
2025-09-10 18:00:15,738:INFO:_display_container: 2
2025-09-10 18:00:15,738:INFO:ElasticNet(random_state=123)
2025-09-10 18:00:15,738:INFO:create_model() successfully completed......................................
2025-09-10 18:00:15,844:INFO:SubProcess create_model() end ==================================
2025-09-10 18:00:15,858:INFO:Creating metrics dataframe
2025-09-10 18:00:15,866:INFO:Initializing Least Angle Regression
2025-09-10 18:00:15,866:INFO:Total runtime is 0.3485958178838094 minutes
2025-09-10 18:00:15,870:INFO:SubProcess create_model() called ==================================
2025-09-10 18:00:15,871:INFO:Initializing create_model()
2025-09-10 18:00:15,871:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023288562D90>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002328826F150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 18:00:15,871:INFO:Checking exceptions
2025-09-10 18:00:15,871:INFO:Importing libraries
2025-09-10 18:00:15,871:INFO:Copying training dataset
2025-09-10 18:00:15,877:INFO:Defining folds
2025-09-10 18:00:15,877:INFO:Declaring metric variables
2025-09-10 18:00:15,883:INFO:Importing untrained model
2025-09-10 18:00:15,888:INFO:Least Angle Regression Imported successfully
2025-09-10 18:00:15,900:INFO:Starting cross validation
2025-09-10 18:00:15,900:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 18:00:18,237:INFO:Calculating mean and std
2025-09-10 18:00:18,237:INFO:Creating metrics dataframe
2025-09-10 18:00:18,237:INFO:Uploading results into container
2025-09-10 18:00:18,237:INFO:Uploading model into container now
2025-09-10 18:00:18,237:INFO:_master_model_container: 5
2025-09-10 18:00:18,237:INFO:_display_container: 2
2025-09-10 18:00:18,237:INFO:Lars(random_state=123)
2025-09-10 18:00:18,237:INFO:create_model() successfully completed......................................
2025-09-10 18:00:18,362:INFO:SubProcess create_model() end ==================================
2025-09-10 18:00:18,362:INFO:Creating metrics dataframe
2025-09-10 18:00:18,368:INFO:Initializing Lasso Least Angle Regression
2025-09-10 18:00:18,368:INFO:Total runtime is 0.39029339551925657 minutes
2025-09-10 18:00:18,371:INFO:SubProcess create_model() called ==================================
2025-09-10 18:00:18,372:INFO:Initializing create_model()
2025-09-10 18:00:18,372:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023288562D90>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002328826F150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 18:00:18,372:INFO:Checking exceptions
2025-09-10 18:00:18,372:INFO:Importing libraries
2025-09-10 18:00:18,372:INFO:Copying training dataset
2025-09-10 18:00:18,378:INFO:Defining folds
2025-09-10 18:00:18,378:INFO:Declaring metric variables
2025-09-10 18:00:18,384:INFO:Importing untrained model
2025-09-10 18:00:18,389:INFO:Lasso Least Angle Regression Imported successfully
2025-09-10 18:00:18,400:INFO:Starting cross validation
2025-09-10 18:00:18,401:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 18:00:20,698:INFO:Calculating mean and std
2025-09-10 18:00:20,698:INFO:Creating metrics dataframe
2025-09-10 18:00:20,698:INFO:Uploading results into container
2025-09-10 18:00:20,698:INFO:Uploading model into container now
2025-09-10 18:00:20,698:INFO:_master_model_container: 6
2025-09-10 18:00:20,698:INFO:_display_container: 2
2025-09-10 18:00:20,698:INFO:LassoLars(random_state=123)
2025-09-10 18:00:20,698:INFO:create_model() successfully completed......................................
2025-09-10 18:00:20,810:INFO:SubProcess create_model() end ==================================
2025-09-10 18:00:20,810:INFO:Creating metrics dataframe
2025-09-10 18:00:20,810:INFO:Initializing Orthogonal Matching Pursuit
2025-09-10 18:00:20,810:INFO:Total runtime is 0.43099859952926634 minutes
2025-09-10 18:00:20,810:INFO:SubProcess create_model() called ==================================
2025-09-10 18:00:20,810:INFO:Initializing create_model()
2025-09-10 18:00:20,810:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023288562D90>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002328826F150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 18:00:20,810:INFO:Checking exceptions
2025-09-10 18:00:20,810:INFO:Importing libraries
2025-09-10 18:00:20,810:INFO:Copying training dataset
2025-09-10 18:00:20,828:INFO:Defining folds
2025-09-10 18:00:20,828:INFO:Declaring metric variables
2025-09-10 18:00:20,836:INFO:Importing untrained model
2025-09-10 18:00:20,844:INFO:Orthogonal Matching Pursuit Imported successfully
2025-09-10 18:00:20,856:INFO:Starting cross validation
2025-09-10 18:00:20,859:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 18:00:23,191:INFO:Calculating mean and std
2025-09-10 18:00:23,191:INFO:Creating metrics dataframe
2025-09-10 18:00:23,191:INFO:Uploading results into container
2025-09-10 18:00:23,191:INFO:Uploading model into container now
2025-09-10 18:00:23,191:INFO:_master_model_container: 7
2025-09-10 18:00:23,191:INFO:_display_container: 2
2025-09-10 18:00:23,191:INFO:OrthogonalMatchingPursuit()
2025-09-10 18:00:23,191:INFO:create_model() successfully completed......................................
2025-09-10 18:00:23,291:INFO:SubProcess create_model() end ==================================
2025-09-10 18:00:23,291:INFO:Creating metrics dataframe
2025-09-10 18:00:23,307:INFO:Initializing Bayesian Ridge
2025-09-10 18:00:23,307:INFO:Total runtime is 0.4726202885309855 minutes
2025-09-10 18:00:23,307:INFO:SubProcess create_model() called ==================================
2025-09-10 18:00:23,307:INFO:Initializing create_model()
2025-09-10 18:00:23,307:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023288562D90>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002328826F150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 18:00:23,307:INFO:Checking exceptions
2025-09-10 18:00:23,307:INFO:Importing libraries
2025-09-10 18:00:23,307:INFO:Copying training dataset
2025-09-10 18:00:23,307:INFO:Defining folds
2025-09-10 18:00:23,307:INFO:Declaring metric variables
2025-09-10 18:00:23,331:INFO:Importing untrained model
2025-09-10 18:00:23,331:INFO:Bayesian Ridge Imported successfully
2025-09-10 18:00:23,350:INFO:Starting cross validation
2025-09-10 18:00:23,351:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 18:00:25,828:INFO:Calculating mean and std
2025-09-10 18:00:25,828:INFO:Creating metrics dataframe
2025-09-10 18:00:25,828:INFO:Uploading results into container
2025-09-10 18:00:25,828:INFO:Uploading model into container now
2025-09-10 18:00:25,828:INFO:_master_model_container: 8
2025-09-10 18:00:25,828:INFO:_display_container: 2
2025-09-10 18:00:25,828:INFO:BayesianRidge()
2025-09-10 18:00:25,828:INFO:create_model() successfully completed......................................
2025-09-10 18:00:25,939:INFO:SubProcess create_model() end ==================================
2025-09-10 18:00:25,939:INFO:Creating metrics dataframe
2025-09-10 18:00:25,955:INFO:Initializing Passive Aggressive Regressor
2025-09-10 18:00:25,955:INFO:Total runtime is 0.5167415459950765 minutes
2025-09-10 18:00:25,955:INFO:SubProcess create_model() called ==================================
2025-09-10 18:00:25,955:INFO:Initializing create_model()
2025-09-10 18:00:25,955:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023288562D90>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002328826F150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 18:00:25,955:INFO:Checking exceptions
2025-09-10 18:00:25,955:INFO:Importing libraries
2025-09-10 18:00:25,955:INFO:Copying training dataset
2025-09-10 18:00:25,955:INFO:Defining folds
2025-09-10 18:00:25,955:INFO:Declaring metric variables
2025-09-10 18:00:25,974:INFO:Importing untrained model
2025-09-10 18:00:25,979:INFO:Passive Aggressive Regressor Imported successfully
2025-09-10 18:00:25,992:INFO:Starting cross validation
2025-09-10 18:00:25,996:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 18:00:28,374:INFO:Calculating mean and std
2025-09-10 18:00:28,375:INFO:Creating metrics dataframe
2025-09-10 18:00:28,378:INFO:Uploading results into container
2025-09-10 18:00:28,378:INFO:Uploading model into container now
2025-09-10 18:00:28,378:INFO:_master_model_container: 9
2025-09-10 18:00:28,379:INFO:_display_container: 2
2025-09-10 18:00:28,379:INFO:PassiveAggressiveRegressor(random_state=123)
2025-09-10 18:00:28,379:INFO:create_model() successfully completed......................................
2025-09-10 18:00:28,473:INFO:SubProcess create_model() end ==================================
2025-09-10 18:00:28,473:INFO:Creating metrics dataframe
2025-09-10 18:00:28,491:INFO:Initializing Huber Regressor
2025-09-10 18:00:28,491:INFO:Total runtime is 0.559014336268107 minutes
2025-09-10 18:00:28,491:INFO:SubProcess create_model() called ==================================
2025-09-10 18:00:28,491:INFO:Initializing create_model()
2025-09-10 18:00:28,491:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023288562D90>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002328826F150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 18:00:28,491:INFO:Checking exceptions
2025-09-10 18:00:28,491:INFO:Importing libraries
2025-09-10 18:00:28,491:INFO:Copying training dataset
2025-09-10 18:00:28,508:INFO:Defining folds
2025-09-10 18:00:28,508:INFO:Declaring metric variables
2025-09-10 18:00:28,509:INFO:Importing untrained model
2025-09-10 18:00:28,509:INFO:Huber Regressor Imported successfully
2025-09-10 18:00:28,532:INFO:Starting cross validation
2025-09-10 18:00:28,536:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 18:00:32,160:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-09-10 18:00:32,176:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-09-10 18:00:32,253:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-09-10 18:00:32,255:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-09-10 18:00:32,286:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-09-10 18:00:32,288:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-09-10 18:00:32,307:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-09-10 18:00:32,313:WARNING:c:\Users\sbm_mes240441\AppData\Local\miniconda3\envs\pbi_ml\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-09-10 18:00:32,443:INFO:Calculating mean and std
2025-09-10 18:00:32,443:INFO:Creating metrics dataframe
2025-09-10 18:00:32,445:INFO:Uploading results into container
2025-09-10 18:00:32,445:INFO:Uploading model into container now
2025-09-10 18:00:32,445:INFO:_master_model_container: 10
2025-09-10 18:00:32,445:INFO:_display_container: 2
2025-09-10 18:00:32,445:INFO:HuberRegressor()
2025-09-10 18:00:32,445:INFO:create_model() successfully completed......................................
2025-09-10 18:00:32,557:INFO:SubProcess create_model() end ==================================
2025-09-10 18:00:32,557:INFO:Creating metrics dataframe
2025-09-10 18:00:32,557:INFO:Initializing K Neighbors Regressor
2025-09-10 18:00:32,557:INFO:Total runtime is 0.6267780621846516 minutes
2025-09-10 18:00:32,573:INFO:SubProcess create_model() called ==================================
2025-09-10 18:00:32,573:INFO:Initializing create_model()
2025-09-10 18:00:32,573:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023288562D90>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002328826F150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 18:00:32,573:INFO:Checking exceptions
2025-09-10 18:00:32,573:INFO:Importing libraries
2025-09-10 18:00:32,573:INFO:Copying training dataset
2025-09-10 18:00:32,576:INFO:Defining folds
2025-09-10 18:00:32,576:INFO:Declaring metric variables
2025-09-10 18:00:32,585:INFO:Importing untrained model
2025-09-10 18:00:32,591:INFO:K Neighbors Regressor Imported successfully
2025-09-10 18:00:32,602:INFO:Starting cross validation
2025-09-10 18:00:32,608:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 18:00:35,080:INFO:Calculating mean and std
2025-09-10 18:00:35,080:INFO:Creating metrics dataframe
2025-09-10 18:00:35,080:INFO:Uploading results into container
2025-09-10 18:00:35,080:INFO:Uploading model into container now
2025-09-10 18:00:35,080:INFO:_master_model_container: 11
2025-09-10 18:00:35,080:INFO:_display_container: 2
2025-09-10 18:00:35,080:INFO:KNeighborsRegressor(n_jobs=-1)
2025-09-10 18:00:35,080:INFO:create_model() successfully completed......................................
2025-09-10 18:00:35,190:INFO:SubProcess create_model() end ==================================
2025-09-10 18:00:35,190:INFO:Creating metrics dataframe
2025-09-10 18:00:35,190:INFO:Initializing Decision Tree Regressor
2025-09-10 18:00:35,190:INFO:Total runtime is 0.6706592043240864 minutes
2025-09-10 18:00:35,206:INFO:SubProcess create_model() called ==================================
2025-09-10 18:00:35,206:INFO:Initializing create_model()
2025-09-10 18:00:35,206:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023288562D90>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002328826F150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 18:00:35,206:INFO:Checking exceptions
2025-09-10 18:00:35,206:INFO:Importing libraries
2025-09-10 18:00:35,206:INFO:Copying training dataset
2025-09-10 18:00:35,206:INFO:Defining folds
2025-09-10 18:00:35,206:INFO:Declaring metric variables
2025-09-10 18:00:35,216:INFO:Importing untrained model
2025-09-10 18:00:35,225:INFO:Decision Tree Regressor Imported successfully
2025-09-10 18:00:35,235:INFO:Starting cross validation
2025-09-10 18:00:35,241:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 18:00:37,599:INFO:Calculating mean and std
2025-09-10 18:00:37,599:INFO:Creating metrics dataframe
2025-09-10 18:00:37,599:INFO:Uploading results into container
2025-09-10 18:00:37,599:INFO:Uploading model into container now
2025-09-10 18:00:37,599:INFO:_master_model_container: 12
2025-09-10 18:00:37,599:INFO:_display_container: 2
2025-09-10 18:00:37,599:INFO:DecisionTreeRegressor(random_state=123)
2025-09-10 18:00:37,599:INFO:create_model() successfully completed......................................
2025-09-10 18:00:37,707:INFO:SubProcess create_model() end ==================================
2025-09-10 18:00:37,707:INFO:Creating metrics dataframe
2025-09-10 18:00:37,723:INFO:Initializing Random Forest Regressor
2025-09-10 18:00:37,723:INFO:Total runtime is 0.7128755489985147 minutes
2025-09-10 18:00:37,723:INFO:SubProcess create_model() called ==================================
2025-09-10 18:00:37,723:INFO:Initializing create_model()
2025-09-10 18:00:37,723:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023288562D90>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002328826F150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 18:00:37,723:INFO:Checking exceptions
2025-09-10 18:00:37,723:INFO:Importing libraries
2025-09-10 18:00:37,723:INFO:Copying training dataset
2025-09-10 18:00:37,723:INFO:Defining folds
2025-09-10 18:00:37,723:INFO:Declaring metric variables
2025-09-10 18:00:37,743:INFO:Importing untrained model
2025-09-10 18:00:37,750:INFO:Random Forest Regressor Imported successfully
2025-09-10 18:00:37,767:INFO:Starting cross validation
2025-09-10 18:00:37,767:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 18:00:41,583:INFO:Calculating mean and std
2025-09-10 18:00:41,583:INFO:Creating metrics dataframe
2025-09-10 18:00:41,583:INFO:Uploading results into container
2025-09-10 18:00:41,583:INFO:Uploading model into container now
2025-09-10 18:00:41,583:INFO:_master_model_container: 13
2025-09-10 18:00:41,583:INFO:_display_container: 2
2025-09-10 18:00:41,583:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-09-10 18:00:41,583:INFO:create_model() successfully completed......................................
2025-09-10 18:00:41,690:INFO:SubProcess create_model() end ==================================
2025-09-10 18:00:41,690:INFO:Creating metrics dataframe
2025-09-10 18:00:41,709:INFO:Initializing Extra Trees Regressor
2025-09-10 18:00:41,709:INFO:Total runtime is 0.7793120423952737 minutes
2025-09-10 18:00:41,709:INFO:SubProcess create_model() called ==================================
2025-09-10 18:00:41,709:INFO:Initializing create_model()
2025-09-10 18:00:41,709:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023288562D90>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002328826F150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 18:00:41,709:INFO:Checking exceptions
2025-09-10 18:00:41,709:INFO:Importing libraries
2025-09-10 18:00:41,709:INFO:Copying training dataset
2025-09-10 18:00:41,722:INFO:Defining folds
2025-09-10 18:00:41,722:INFO:Declaring metric variables
2025-09-10 18:00:41,729:INFO:Importing untrained model
2025-09-10 18:00:41,729:INFO:Extra Trees Regressor Imported successfully
2025-09-10 18:00:41,751:INFO:Starting cross validation
2025-09-10 18:00:41,754:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 18:00:45,333:INFO:Calculating mean and std
2025-09-10 18:00:45,333:INFO:Creating metrics dataframe
2025-09-10 18:00:45,333:INFO:Uploading results into container
2025-09-10 18:00:45,333:INFO:Uploading model into container now
2025-09-10 18:00:45,333:INFO:_master_model_container: 14
2025-09-10 18:00:45,333:INFO:_display_container: 2
2025-09-10 18:00:45,333:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-09-10 18:00:45,333:INFO:create_model() successfully completed......................................
2025-09-10 18:00:45,439:INFO:SubProcess create_model() end ==================================
2025-09-10 18:00:45,439:INFO:Creating metrics dataframe
2025-09-10 18:00:45,455:INFO:Initializing AdaBoost Regressor
2025-09-10 18:00:45,455:INFO:Total runtime is 0.8417467276255288 minutes
2025-09-10 18:00:45,460:INFO:SubProcess create_model() called ==================================
2025-09-10 18:00:45,460:INFO:Initializing create_model()
2025-09-10 18:00:45,460:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023288562D90>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002328826F150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 18:00:45,460:INFO:Checking exceptions
2025-09-10 18:00:45,460:INFO:Importing libraries
2025-09-10 18:00:45,460:INFO:Copying training dataset
2025-09-10 18:00:45,460:INFO:Defining folds
2025-09-10 18:00:45,460:INFO:Declaring metric variables
2025-09-10 18:00:45,474:INFO:Importing untrained model
2025-09-10 18:00:45,474:INFO:AdaBoost Regressor Imported successfully
2025-09-10 18:00:45,494:INFO:Starting cross validation
2025-09-10 18:00:45,498:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 18:00:48,659:INFO:Calculating mean and std
2025-09-10 18:00:48,660:INFO:Creating metrics dataframe
2025-09-10 18:00:48,664:INFO:Uploading results into container
2025-09-10 18:00:48,664:INFO:Uploading model into container now
2025-09-10 18:00:48,664:INFO:_master_model_container: 15
2025-09-10 18:00:48,664:INFO:_display_container: 2
2025-09-10 18:00:48,664:INFO:AdaBoostRegressor(random_state=123)
2025-09-10 18:00:48,664:INFO:create_model() successfully completed......................................
2025-09-10 18:00:48,774:INFO:SubProcess create_model() end ==================================
2025-09-10 18:00:48,774:INFO:Creating metrics dataframe
2025-09-10 18:00:48,774:INFO:Initializing Gradient Boosting Regressor
2025-09-10 18:00:48,774:INFO:Total runtime is 0.897070248921712 minutes
2025-09-10 18:00:48,774:INFO:SubProcess create_model() called ==================================
2025-09-10 18:00:48,774:INFO:Initializing create_model()
2025-09-10 18:00:48,774:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023288562D90>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002328826F150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 18:00:48,774:INFO:Checking exceptions
2025-09-10 18:00:48,774:INFO:Importing libraries
2025-09-10 18:00:48,774:INFO:Copying training dataset
2025-09-10 18:00:48,790:INFO:Defining folds
2025-09-10 18:00:48,790:INFO:Declaring metric variables
2025-09-10 18:00:48,798:INFO:Importing untrained model
2025-09-10 18:00:48,807:INFO:Gradient Boosting Regressor Imported successfully
2025-09-10 18:00:48,818:INFO:Starting cross validation
2025-09-10 18:00:48,825:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 18:00:52,571:INFO:Calculating mean and std
2025-09-10 18:00:52,572:INFO:Creating metrics dataframe
2025-09-10 18:00:52,575:INFO:Uploading results into container
2025-09-10 18:00:52,575:INFO:Uploading model into container now
2025-09-10 18:00:52,575:INFO:_master_model_container: 16
2025-09-10 18:00:52,575:INFO:_display_container: 2
2025-09-10 18:00:52,575:INFO:GradientBoostingRegressor(random_state=123)
2025-09-10 18:00:52,575:INFO:create_model() successfully completed......................................
2025-09-10 18:00:52,686:INFO:SubProcess create_model() end ==================================
2025-09-10 18:00:52,686:INFO:Creating metrics dataframe
2025-09-10 18:00:52,696:INFO:Initializing Extreme Gradient Boosting
2025-09-10 18:00:52,696:INFO:Total runtime is 0.962437836329142 minutes
2025-09-10 18:00:52,707:INFO:SubProcess create_model() called ==================================
2025-09-10 18:00:52,708:INFO:Initializing create_model()
2025-09-10 18:00:52,708:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023288562D90>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002328826F150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 18:00:52,708:INFO:Checking exceptions
2025-09-10 18:00:52,708:INFO:Importing libraries
2025-09-10 18:00:52,708:INFO:Copying training dataset
2025-09-10 18:00:52,714:INFO:Defining folds
2025-09-10 18:00:52,714:INFO:Declaring metric variables
2025-09-10 18:00:52,717:INFO:Importing untrained model
2025-09-10 18:00:52,725:INFO:Extreme Gradient Boosting Imported successfully
2025-09-10 18:00:52,727:INFO:Starting cross validation
2025-09-10 18:00:52,727:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 18:00:55,561:INFO:Calculating mean and std
2025-09-10 18:00:55,561:INFO:Creating metrics dataframe
2025-09-10 18:00:55,561:INFO:Uploading results into container
2025-09-10 18:00:55,561:INFO:Uploading model into container now
2025-09-10 18:00:55,561:INFO:_master_model_container: 17
2025-09-10 18:00:55,561:INFO:_display_container: 2
2025-09-10 18:00:55,561:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-09-10 18:00:55,561:INFO:create_model() successfully completed......................................
2025-09-10 18:00:55,674:INFO:SubProcess create_model() end ==================================
2025-09-10 18:00:55,674:INFO:Creating metrics dataframe
2025-09-10 18:00:55,681:INFO:Initializing Light Gradient Boosting Machine
2025-09-10 18:00:55,681:INFO:Total runtime is 1.0121879021326698 minutes
2025-09-10 18:00:55,690:INFO:SubProcess create_model() called ==================================
2025-09-10 18:00:55,690:INFO:Initializing create_model()
2025-09-10 18:00:55,690:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023288562D90>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002328826F150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 18:00:55,690:INFO:Checking exceptions
2025-09-10 18:00:55,690:INFO:Importing libraries
2025-09-10 18:00:55,690:INFO:Copying training dataset
2025-09-10 18:00:55,690:INFO:Defining folds
2025-09-10 18:00:55,690:INFO:Declaring metric variables
2025-09-10 18:00:55,690:INFO:Importing untrained model
2025-09-10 18:00:55,709:INFO:Light Gradient Boosting Machine Imported successfully
2025-09-10 18:00:55,718:INFO:Starting cross validation
2025-09-10 18:00:55,723:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 18:00:59,916:INFO:Calculating mean and std
2025-09-10 18:00:59,916:INFO:Creating metrics dataframe
2025-09-10 18:00:59,920:INFO:Uploading results into container
2025-09-10 18:00:59,920:INFO:Uploading model into container now
2025-09-10 18:00:59,920:INFO:_master_model_container: 18
2025-09-10 18:00:59,920:INFO:_display_container: 2
2025-09-10 18:00:59,923:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-09-10 18:00:59,924:INFO:create_model() successfully completed......................................
2025-09-10 18:01:00,057:INFO:SubProcess create_model() end ==================================
2025-09-10 18:01:00,057:INFO:Creating metrics dataframe
2025-09-10 18:01:00,057:INFO:Initializing CatBoost Regressor
2025-09-10 18:01:00,057:INFO:Total runtime is 1.0851156552632648 minutes
2025-09-10 18:01:00,073:INFO:SubProcess create_model() called ==================================
2025-09-10 18:01:00,073:INFO:Initializing create_model()
2025-09-10 18:01:00,073:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023288562D90>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002328826F150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 18:01:00,073:INFO:Checking exceptions
2025-09-10 18:01:00,073:INFO:Importing libraries
2025-09-10 18:01:00,073:INFO:Copying training dataset
2025-09-10 18:01:00,078:INFO:Defining folds
2025-09-10 18:01:00,078:INFO:Declaring metric variables
2025-09-10 18:01:00,084:INFO:Importing untrained model
2025-09-10 18:01:00,091:INFO:CatBoost Regressor Imported successfully
2025-09-10 18:01:00,106:INFO:Starting cross validation
2025-09-10 18:01:00,113:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 18:01:13,074:INFO:Calculating mean and std
2025-09-10 18:01:13,074:INFO:Creating metrics dataframe
2025-09-10 18:01:13,074:INFO:Uploading results into container
2025-09-10 18:01:13,074:INFO:Uploading model into container now
2025-09-10 18:01:13,074:INFO:_master_model_container: 19
2025-09-10 18:01:13,074:INFO:_display_container: 2
2025-09-10 18:01:13,074:INFO:<catboost.core.CatBoostRegressor object at 0x0000023288116890>
2025-09-10 18:01:13,074:INFO:create_model() successfully completed......................................
2025-09-10 18:01:13,190:INFO:SubProcess create_model() end ==================================
2025-09-10 18:01:13,190:INFO:Creating metrics dataframe
2025-09-10 18:01:13,206:INFO:Initializing Dummy Regressor
2025-09-10 18:01:13,206:INFO:Total runtime is 1.3042690475781757 minutes
2025-09-10 18:01:13,206:INFO:SubProcess create_model() called ==================================
2025-09-10 18:01:13,206:INFO:Initializing create_model()
2025-09-10 18:01:13,206:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023288562D90>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002328826F150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 18:01:13,206:INFO:Checking exceptions
2025-09-10 18:01:13,206:INFO:Importing libraries
2025-09-10 18:01:13,206:INFO:Copying training dataset
2025-09-10 18:01:13,206:INFO:Defining folds
2025-09-10 18:01:13,206:INFO:Declaring metric variables
2025-09-10 18:01:13,223:INFO:Importing untrained model
2025-09-10 18:01:13,232:INFO:Dummy Regressor Imported successfully
2025-09-10 18:01:13,249:INFO:Starting cross validation
2025-09-10 18:01:13,252:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 18:01:16,032:INFO:Calculating mean and std
2025-09-10 18:01:16,032:INFO:Creating metrics dataframe
2025-09-10 18:01:16,032:INFO:Uploading results into container
2025-09-10 18:01:16,032:INFO:Uploading model into container now
2025-09-10 18:01:16,032:INFO:_master_model_container: 20
2025-09-10 18:01:16,032:INFO:_display_container: 2
2025-09-10 18:01:16,032:INFO:DummyRegressor()
2025-09-10 18:01:16,032:INFO:create_model() successfully completed......................................
2025-09-10 18:01:16,177:INFO:SubProcess create_model() end ==================================
2025-09-10 18:01:16,177:INFO:Creating metrics dataframe
2025-09-10 18:01:16,193:INFO:Initializing create_model()
2025-09-10 18:01:16,193:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023288562D90>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 18:01:16,193:INFO:Checking exceptions
2025-09-10 18:01:16,193:INFO:Importing libraries
2025-09-10 18:01:16,193:INFO:Copying training dataset
2025-09-10 18:01:16,205:INFO:Defining folds
2025-09-10 18:01:16,205:INFO:Declaring metric variables
2025-09-10 18:01:16,205:INFO:Importing untrained model
2025-09-10 18:01:16,205:INFO:Declaring custom model
2025-09-10 18:01:16,205:INFO:K Neighbors Regressor Imported successfully
2025-09-10 18:01:16,206:INFO:Cross validation set to False
2025-09-10 18:01:16,206:INFO:Fitting Model
2025-09-10 18:01:17,155:INFO:KNeighborsRegressor(n_jobs=-1)
2025-09-10 18:01:17,155:INFO:create_model() successfully completed......................................
2025-09-10 18:01:17,309:INFO:_master_model_container: 20
2025-09-10 18:01:17,309:INFO:_display_container: 2
2025-09-10 18:01:17,309:INFO:KNeighborsRegressor(n_jobs=-1)
2025-09-10 18:01:17,309:INFO:compare_models() successfully completed......................................
2025-09-10 18:01:17,360:INFO:Initializing create_model()
2025-09-10 18:01:17,360:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023288562D90>, estimator=knn, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 18:01:17,360:INFO:Checking exceptions
2025-09-10 18:01:17,377:INFO:Importing libraries
2025-09-10 18:01:17,377:INFO:Copying training dataset
2025-09-10 18:01:17,385:INFO:Defining folds
2025-09-10 18:01:17,385:INFO:Declaring metric variables
2025-09-10 18:01:17,390:INFO:Importing untrained model
2025-09-10 18:01:17,397:INFO:K Neighbors Regressor Imported successfully
2025-09-10 18:01:17,411:INFO:Starting cross validation
2025-09-10 18:01:17,417:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 18:01:20,236:INFO:Calculating mean and std
2025-09-10 18:01:20,236:INFO:Creating metrics dataframe
2025-09-10 18:01:20,244:INFO:Finalizing model
2025-09-10 18:01:21,115:INFO:Uploading results into container
2025-09-10 18:01:21,115:INFO:Uploading model into container now
2025-09-10 18:01:21,124:INFO:_master_model_container: 21
2025-09-10 18:01:21,124:INFO:_display_container: 3
2025-09-10 18:01:21,124:INFO:KNeighborsRegressor(n_jobs=-1)
2025-09-10 18:01:21,124:INFO:create_model() successfully completed......................................
2025-09-10 18:01:21,440:INFO:Initializing tune_model()
2025-09-10 18:01:21,440:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023288562D90>, estimator=KNeighborsRegressor(n_jobs=-1), fold=None, round=4, n_iter=10, custom_grid=None, optimize=MAE, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-09-10 18:01:21,440:INFO:Checking exceptions
2025-09-10 18:01:21,440:INFO:Soft dependency imported: optuna: 4.3.0
2025-09-10 18:01:21,586:INFO:Copying training dataset
2025-09-10 18:01:21,590:INFO:Checking base model
2025-09-10 18:01:21,590:INFO:Base model : K Neighbors Regressor
2025-09-10 18:01:21,594:INFO:Declaring metric variables
2025-09-10 18:01:21,599:INFO:Defining Hyperparameters
2025-09-10 18:01:21,730:INFO:Tuning with n_jobs=-1
2025-09-10 18:01:21,731:INFO:Initializing optuna.integration.OptunaSearchCV
2025-09-10 18:03:13,894:INFO:best_params: {'actual_estimator__n_neighbors': 22, 'actual_estimator__weights': 'distance', 'actual_estimator__metric': 'manhattan'}
2025-09-10 18:03:13,897:INFO:Hyperparameter search completed
2025-09-10 18:03:13,897:INFO:SubProcess create_model() called ==================================
2025-09-10 18:03:13,897:INFO:Initializing create_model()
2025-09-10 18:03:13,897:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023288562D90>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000232885DA910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_neighbors': 22, 'weights': 'distance', 'metric': 'manhattan'})
2025-09-10 18:03:13,897:INFO:Checking exceptions
2025-09-10 18:03:13,897:INFO:Importing libraries
2025-09-10 18:03:13,898:INFO:Copying training dataset
2025-09-10 18:03:13,907:INFO:Defining folds
2025-09-10 18:03:13,908:INFO:Declaring metric variables
2025-09-10 18:03:13,913:INFO:Importing untrained model
2025-09-10 18:03:13,913:INFO:Declaring custom model
2025-09-10 18:03:13,918:INFO:K Neighbors Regressor Imported successfully
2025-09-10 18:03:13,927:INFO:Starting cross validation
2025-09-10 18:03:13,933:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 18:03:16,264:INFO:Calculating mean and std
2025-09-10 18:03:16,264:INFO:Creating metrics dataframe
2025-09-10 18:03:16,271:INFO:Finalizing model
2025-09-10 18:03:17,128:INFO:Uploading results into container
2025-09-10 18:03:17,130:INFO:Uploading model into container now
2025-09-10 18:03:17,130:INFO:_master_model_container: 22
2025-09-10 18:03:17,130:INFO:_display_container: 4
2025-09-10 18:03:17,130:INFO:KNeighborsRegressor(metric='manhattan', n_jobs=-1, n_neighbors=22,
                    weights='distance')
2025-09-10 18:03:17,130:INFO:create_model() successfully completed......................................
2025-09-10 18:03:17,261:INFO:SubProcess create_model() end ==================================
2025-09-10 18:03:17,261:INFO:choose_better activated
2025-09-10 18:03:17,267:INFO:SubProcess create_model() called ==================================
2025-09-10 18:03:17,268:INFO:Initializing create_model()
2025-09-10 18:03:17,268:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023288562D90>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-10 18:03:17,268:INFO:Checking exceptions
2025-09-10 18:03:17,270:INFO:Importing libraries
2025-09-10 18:03:17,270:INFO:Copying training dataset
2025-09-10 18:03:17,274:INFO:Defining folds
2025-09-10 18:03:17,274:INFO:Declaring metric variables
2025-09-10 18:03:17,274:INFO:Importing untrained model
2025-09-10 18:03:17,274:INFO:Declaring custom model
2025-09-10 18:03:17,275:INFO:K Neighbors Regressor Imported successfully
2025-09-10 18:03:17,275:INFO:Starting cross validation
2025-09-10 18:03:17,277:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-10 18:03:19,686:INFO:Calculating mean and std
2025-09-10 18:03:19,686:INFO:Creating metrics dataframe
2025-09-10 18:03:19,686:INFO:Finalizing model
2025-09-10 18:03:20,484:INFO:Uploading results into container
2025-09-10 18:03:20,484:INFO:Uploading model into container now
2025-09-10 18:03:20,484:INFO:_master_model_container: 23
2025-09-10 18:03:20,484:INFO:_display_container: 5
2025-09-10 18:03:20,484:INFO:KNeighborsRegressor(n_jobs=-1)
2025-09-10 18:03:20,484:INFO:create_model() successfully completed......................................
2025-09-10 18:03:20,604:INFO:SubProcess create_model() end ==================================
2025-09-10 18:03:20,604:INFO:KNeighborsRegressor(n_jobs=-1) result for MAE is 1.3782
2025-09-10 18:03:20,604:INFO:KNeighborsRegressor(metric='manhattan', n_jobs=-1, n_neighbors=22,
                    weights='distance') result for MAE is 1.1452
2025-09-10 18:03:20,604:INFO:KNeighborsRegressor(metric='manhattan', n_jobs=-1, n_neighbors=22,
                    weights='distance') is best model
2025-09-10 18:03:20,604:INFO:choose_better completed
2025-09-10 18:03:20,617:INFO:_master_model_container: 23
2025-09-10 18:03:20,617:INFO:_display_container: 4
2025-09-10 18:03:20,617:INFO:KNeighborsRegressor(metric='manhattan', n_jobs=-1, n_neighbors=22,
                    weights='distance')
2025-09-10 18:03:20,617:INFO:tune_model() successfully completed......................................
2025-09-10 18:07:46,741:INFO:Initializing plot_model()
2025-09-10 18:07:46,741:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023288562D90>, estimator=KNeighborsRegressor(metric='manhattan', n_jobs=-1, n_neighbors=22,
                    weights='distance'), plot=residuals, scale=5, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-09-10 18:07:46,741:INFO:Checking exceptions
2025-09-10 18:07:46,754:INFO:Preloading libraries
2025-09-10 18:07:46,756:INFO:Copying training dataset
2025-09-10 18:07:46,756:INFO:Plot type: residuals
2025-09-10 18:07:47,020:INFO:Fitting Model
2025-09-10 18:07:47,712:INFO:Scoring test/hold-out set
2025-09-10 18:07:48,653:INFO:Visual Rendered Successfully
2025-09-10 18:07:48,855:INFO:plot_model() successfully completed......................................
2025-09-10 18:08:06,769:INFO:Initializing plot_model()
2025-09-10 18:08:06,769:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000023288562D90>, estimator=KNeighborsRegressor(metric='manhattan', n_jobs=-1, n_neighbors=22,
                    weights='distance'), plot=residuals, scale=3, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-09-10 18:08:06,769:INFO:Checking exceptions
2025-09-10 18:08:06,775:INFO:Preloading libraries
2025-09-10 18:08:06,775:INFO:Copying training dataset
2025-09-10 18:08:06,775:INFO:Plot type: residuals
2025-09-10 18:08:07,004:INFO:Fitting Model
2025-09-10 18:08:07,586:INFO:Scoring test/hold-out set
2025-09-10 18:08:08,235:INFO:Visual Rendered Successfully
2025-09-10 18:08:08,410:INFO:plot_model() successfully completed......................................
